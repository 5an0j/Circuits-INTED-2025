{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44f8f5c9",
   "metadata": {},
   "source": [
    "Given a multiple choice question, we seek to determine which words are most important for the BERT-model's answer selection.\n",
    "\n",
    "Model: BERT adapted for Multiple Choice (non-causal attention). If you want to specialize your model, you can fine-tune it (eg. specifically for physics questions) as described [here](https://huggingface.co/docs/transformers/en/tasks/multiple_choice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c2e2157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, utils\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerConductance, LayerIntegratedGradients\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9b3b49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForMultipleChoice, RobertaTokenizer\n",
    "\n",
    "model_name = \"LIAMF-USP/roberta-large-finetuned-race\"\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "model = RobertaForMultipleChoice.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "model.zero_grad()\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c18a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inputs, token_type_ids=None, position_ids=None, attention_mask=None):\n",
    "    output = model(inputs, token_type_ids=token_type_ids,\n",
    "                 position_ids=position_ids, attention_mask=attention_mask, )\n",
    "    return output.start_logits, output.end_logits\n",
    "\n",
    "def squad_pos_forward_func(inputs, token_type_ids=None, position_ids=None, attention_mask=None, position=0):\n",
    "    pred = predict(inputs,\n",
    "                   token_type_ids=token_type_ids,\n",
    "                   position_ids=position_ids,\n",
    "                   attention_mask=attention_mask)\n",
    "    pred = pred[position]\n",
    "    return pred.max(1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af512e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_token_id = tokenizer.pad_token_id # A token used for generating token reference\n",
    "sep_token_id = tokenizer.sep_token_id # A token used as a separator between question and text and it is also added to the end of the text.\n",
    "cls_token_id = tokenizer.cls_token_id # A token used for prepending to the concatenated question-text word sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7698ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_input_ref_pair(question, text, ref_token_id, sep_token_id, cls_token_id):\n",
    "    question_ids = tokenizer.encode(question, add_special_tokens=False)\n",
    "    text_ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "\n",
    "    # construct input token ids\n",
    "    input_ids = [cls_token_id] + question_ids + [sep_token_id] + text_ids + [sep_token_id]\n",
    "\n",
    "    # construct reference token ids \n",
    "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(question_ids) + [sep_token_id] + \\\n",
    "        [ref_token_id] * len(text_ids) + [sep_token_id]\n",
    "\n",
    "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(question_ids)\n",
    "\n",
    "def construct_input_ref_token_type_pair(input_ids, sep_ind=0):\n",
    "    seq_len = input_ids.size(1)\n",
    "    token_type_ids = torch.tensor([[0 if i <= sep_ind else 1 for i in range(seq_len)]], device=device)\n",
    "    ref_token_type_ids = torch.zeros_like(token_type_ids, device=device)# * -1\n",
    "    return token_type_ids, ref_token_type_ids\n",
    "\n",
    "def construct_input_ref_pos_id_pair(input_ids):\n",
    "    seq_length = input_ids.size(1)\n",
    "    position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n",
    "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n",
    "\n",
    "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    return position_ids, ref_position_ids\n",
    "    \n",
    "def construct_attention_mask(input_ids):\n",
    "    return torch.ones_like(input_ids)\n",
    "\n",
    "def construct_whole_bert_embeddings(input_ids, ref_input_ids, \\\n",
    "                                    token_type_ids=None, ref_token_type_ids=None, \\\n",
    "                                    position_ids=None, ref_position_ids=None):\n",
    "    input_embeddings = model.bert.embeddings(input_ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "    ref_input_embeddings = model.bert.embeddings(ref_input_ids, token_type_ids=ref_token_type_ids, position_ids=ref_position_ids)\n",
    "    \n",
    "    return input_embeddings, ref_input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e08f8922",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the capital of France?\"\n",
    "alt1 = \"Oslo\"\n",
    "alt2 = \"Paris\"\n",
    "alt3 = \"Berlin\"\n",
    "alt4 = \"Madrid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd81f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, ref_input_ids, sep_id = construct_input_ref_pair(question, text, ref_token_id, sep_token_id, cls_token_id)\n",
    "token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, sep_id)\n",
    "position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
    "attention_mask = construct_attention_mask(input_ids)\n",
    "\n",
    "indices = input_ids[0].detach().tolist()\n",
    "all_tokens = tokenizer.convert_ids_to_tokens(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "215f0fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b06e64bd08c48fda2585c858f4184c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/4934 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import  RobertaForMultipleChoice\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\n",
    "\"LIAMF-USP/roberta-large-finetuned-race\")\n",
    "model = RobertaForMultipleChoice.from_pretrained(\n",
    "\"LIAMF-USP/roberta-large-finetuned-race\")\n",
    "dataset = datasets.load_dataset(\n",
    "    \"race\",\n",
    "    \"all\",\n",
    "    split=[\"train\", \"validation\", \"test\"],\n",
    ")\n",
    "training_examples = dataset[0]\n",
    "evaluation_examples = dataset[1]\n",
    "test_examples = dataset[2]\n",
    "\n",
    "example=training_examples[0] \n",
    "example_id = example[\"example_id\"]\n",
    "question = example[\"question\"]\n",
    "context = example[\"article\"]\n",
    "options = example[\"options\"]\n",
    "label_example = example[\"answer\"]\n",
    "label_map = {label: i \n",
    "    for i, label in enumerate([\"A\", \"B\", \"C\", \"D\"])}\n",
    "choices_inputs = []\n",
    "for ending_idx, (_, ending) in enumerate(\n",
    "                                zip(context, options)):\n",
    "    if question.find(\"_\") != -1:\n",
    "        # fill in the banks questions\n",
    "        question_option = question.replace(\"_\", ending)\n",
    "    else:\n",
    "        question_option = question + \" \" + ending\n",
    "    inputs = tokenizer(\n",
    "        context,\n",
    "        question_option,\n",
    "        add_special_tokens=True,\n",
    "        max_length=MAX_SEQ_LENGTH,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_overflowing_tokens=False,\n",
    "    )    \n",
    "label = label_map[label_example]\n",
    "input_ids = [x[\"input_ids\"] for x in choices_inputs]\n",
    "attention_mask = (\n",
    "    [x[\"attention_mask\"] for x in choices_inputs]\n",
    "     # as the senteces follow the same structure, \n",
    "     #just one of them is necessary to check\n",
    "    if \"attention_mask\" in choices_inputs[0]\n",
    "    else None\n",
    ")\n",
    "example_encoded = {\n",
    "    \"example_id\": example_id,\n",
    "    \"input_ids\": input_ids,\n",
    "    \"attention_mask\": attention_mask,\n",
    "    \"label\": label,\n",
    "}\n",
    "output = model(**example_encoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
