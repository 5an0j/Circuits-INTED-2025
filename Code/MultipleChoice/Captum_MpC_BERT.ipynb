{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6026db04",
   "metadata": {},
   "source": [
    "This is loosely based on the Captum BERT-interpretation demo notebook, adapted for multiple choice models, and hopefully more instructive by indicating clearly the expected tensor shapes for the catum methods. Overall, Captum is neither wonderful nor horrible to work with, but I suspect transformer lens / more specific libraries could make for a more enjoyable coding experience.\n",
    "\n",
    "### Finding Physical Misunderstandings in BERT-Style Models Fine-Tuned for Multiple Choice\n",
    "\n",
    "We use Integrated Gradients from Captum to compute word attributions on the FCI for a BERT-model fine-tuned for answering mulitple choice questions. Specifically, we want to see whether the emphasised words indicate that the model exhibits the same common misconceptions as humans. In the example question below, even if the model gives a common wrong answer (eg. that the pushing car exerts a larger force, or that the heavier object exerts a larger force) we can perhaps use attribution to see precisely which words throw the model off, and then modify the prompt to determine by causal experiments what the model's misconception is. Alas, I cannot compute the gradients for large models with long inputs on my laptop, and our MpC-models are not trained for long physics questions, so the models used here are not sufficiently good to get particualrily interesting results - but the code should be applicable to any appropriate model (potentially self fine-tuned for the purpose) with minimal adjustments, and we show as an example how to (very slighlty) modify it for a slighly different architechture (RoBERTa).\n",
    "\n",
    "Example question: *A large truck breaks down out on the road and receives a push back into town by a small compact car. After the car reaches the constant cruising speed at which its driver wishes to push the truck:*\n",
    "\n",
    "0) *The amount of force with which the car pushes on the truck is equal to that with which the truck pushes back on the car.*\n",
    "1) *The amount of force with which the car pushes on the truck is smaller than that with which the truck pushes back on the car.*\n",
    "2) *The amount of force with which the car pushes on the truck is greater than that with which the truck pushes back on the car.*\n",
    "3) *The car's engine is running so the car pushes against the truck, but the truck's engine is not running so the truck cannot push back against the car. The truck is pushed forward simply because it is in the way of the car.*\n",
    "4) *Neither the car nor the truck exert any force on the other. The truck is pushed forward simply because it is in the way of the car.*\n",
    "\n",
    "We begin with layer attributions, and move on to layer conductance which can be used to find which layers seem to store certain facts. The specific nodes in the layer coding for a concrete feature can then be isolated by patching techniques, see the interventions notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ee078050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideally, we would make a reference file with all FCI questions and choices which one can simply import, but for now:\n",
    "\n",
    "# Test question\n",
    "question = \"What is the capital of France?\"\n",
    "choices = [\"Berlin\", \"Madrid\", \"Paris\"]\n",
    "ground_truth_idx = 2\n",
    "\n",
    "# # Question and choices (early for easy changes)\n",
    "# question = \"Two metal balls are the same size but one weighs twice as much as the other. The balls \\\n",
    "# are dropped from the roof of a single story building at the same instant of time. The time it takes \\\n",
    "# the balls to reach the ground below will be:\"\n",
    "\n",
    "# choices = [\n",
    "#     \"About half as long for the heavier ball as for the lighter one\",\n",
    "#     \"About half as long for the lighter ball as for the heavier one\",\n",
    "#     \"About the same for both balls\",\n",
    "#     \"Considerably less for the heavier ball, but not necessarily half as long\",\n",
    "#     \"Considerably less for the lighter ball, but not necessarily half as long\"\n",
    "# ]\n",
    "\n",
    "# ground_truth_idx = 2 # Correct answer index, just for reference in the final plot\n",
    "\n",
    "# # Question and choices (overwrites the above if uncommented)\n",
    "# question = \"A large truck breaks down out on the road and receives a push back into town by a small compact car. \\\n",
    "# After the car reaches the constant cruising speed at which its driver wishes to push the truck:\"\n",
    "\n",
    "# choices = [\n",
    "#     \"The amount of force with which the car pushes on the truck is equal to that with which the truck pushes back on the car.\",\n",
    "#     \"The amount of force with which the car pushes on the truck is smaller than that with which the truck pushes back on the car.\",\n",
    "#     \"The amount of force with which the car pushes on the truck is greater than that with which the truck pushes back on the car.\",\n",
    "#     \"The car's engine is running so the car pushes against the truck, but the truck's engine is not running so the truck cannot \\\n",
    "#     push back against the car. The truck is pushed forward simply because it is in the way of the car.\",\n",
    "#     \"Neither the car nor the truck exert any force on the other. The truck is pushed forward simply because it is in the way of the car.\"\n",
    "# ]\n",
    "\n",
    "# ground_truth_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "60f07e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForMultipleChoice\n",
    "from captum.attr import LayerIntegratedGradients\n",
    "from captum.attr import visualization as viz\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Settings\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Config (only for debug atm)\n",
    "@dataclass\n",
    "class Config:\n",
    "    debug: bool = True\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5e778438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "model_name = 'jonastokoliu/multi_choice_bert-base-uncased_swag_finetune' # Pretrained (bad) MpC model\n",
    "model = BertForMultipleChoice.from_pretrained(model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Set to evaluation mode\n",
    "model.to(device)\n",
    "model.eval()\n",
    "model.zero_grad()\n",
    "# model # Uncomment to print architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "18a4da9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_func(input_ids, attention_mask, token_type_ids=None): \n",
    "    \"\"\"Custom forward pass for Captum Integrated Gradients. Captum wants [batch size, seq_len] while mulitple choice/classification\n",
    "    models expect [batch size, num_choices, seq_len]. We return the logits for each choice.\n",
    "    Some models (eg. RoBERTa) do not use token_type_ids, hence the optional parameter.\"\"\"\n",
    "\n",
    "    input_ids = input_ids.unsqueeze(0)\n",
    "    attention_mask = attention_mask.unsqueeze(0)\n",
    "    if token_type_ids is not None: token_type_ids = token_type_ids.unsqueeze(0)\n",
    "\n",
    "    logits = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        token_type_ids=token_type_ids\n",
    "    ).logits\n",
    "\n",
    "    if cfg.debug: print(\"Logits from forward pass:\", logits.shape)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5f699a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits from forward pass: torch.Size([1, 3])\n",
      "Question: What is the capital of France?\n",
      "Predicted Answer: 2) Paris\n",
      "Logits: tensor([[2.8368, 2.7233, 5.5524]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Get input ids, attn masks, token type ids and baseline for Captum attribution methods.\n",
    "def get_encoding_and_predict(question, choices, tokenizer, token_types=True, print_output=True):\n",
    "    \"\"\"Tokenizes the question and choices and makes prediction, returning input_ids, attention_masks, and token_type_ids, \n",
    "    logits and choice index. token_type_ids is None if token_types is False. The input ids are shaped as [num_choices, seq_len].\"\"\"\n",
    "    \n",
    "    # Tokenize for multiple choice and get input ids, attention masks, and token type ids\n",
    "    encoding = tokenizer(\n",
    "        [question] * len(choices),\n",
    "        choices,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    input_ids = encoding[\"input_ids\"]               # shape: [choices, seq_len]\n",
    "    attention_masks = encoding[\"attention_mask\"]    # -\"-\n",
    "    if token_types:\n",
    "        token_type_ids = encoding[\"token_type_ids\"] # -\"-\n",
    "    else:\n",
    "        token_type_ids = None\n",
    "\n",
    "\n",
    "    # Compute model prediction and get choice index\n",
    "    logits = forward_func(input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids)\n",
    "    choice_idx = torch.argmax(logits).item()\n",
    "\n",
    "    if print_output:\n",
    "        print('Question:', question)\n",
    "        print('Predicted Answer:', f'{choice_idx})', choices[choice_idx])\n",
    "    if cfg.debug: print('Logits:', logits) # To gauge model confidence\n",
    "\n",
    "    return input_ids, attention_masks, token_type_ids, logits, choice_idx\n",
    "\n",
    "\n",
    "# Baseline input for Integrated Gradients\n",
    "def get_baseline(tokenizer, input_ids, choice_idx):\n",
    "    ref_token_id = tokenizer.pad_token_id   # padding\n",
    "    sep_token_id = tokenizer.sep_token_id   # sepatator\n",
    "    cls_token_id = tokenizer.cls_token_id   # start of sequence\n",
    "\n",
    "    # Create baseline input: [CLS] [PAD] ... [SEP] ... [PAD] [SEP] for choice index expanded as input_ids\n",
    "    ref_tokens = [cls_token_id]\n",
    "    for i, token in enumerate(input_ids[choice_idx, 1:]):\n",
    "        if token == sep_token_id: # We keep only the separators, else we use padding\n",
    "            ref_tokens += [sep_token_id]\n",
    "        else:\n",
    "            ref_tokens += [ref_token_id]\n",
    "        \n",
    "    return torch.tensor(ref_tokens, dtype=torch.long).expand_as(input_ids)\n",
    "\n",
    "\n",
    "# Compute\n",
    "input_ids, attention_masks, token_type_ids, logits, choice_idx = get_encoding_and_predict(question, choices, tokenizer)\n",
    "ref_input_ids = get_baseline(tokenizer, input_ids, choice_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3aee7f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_attributions_for_layer(layer, forward_func, choice_idx, input_ids, ref_input_ids, attention_mask, token_type_ids=None, n_steps=50):\n",
    "\n",
    "    if cfg.debug: print(input_ids.shape)\n",
    "    \n",
    "    # LayerIntegratedGradients for attribution\n",
    "    lig = LayerIntegratedGradients(forward_func, layer)\n",
    "\n",
    "    # Compute attributions for chosen index (Captum wants [choices, seq_len] and gives attr shape [choices, seq_len, layer_output_dim])\n",
    "    attributions, delta = lig.attribute(\n",
    "        inputs=input_ids,\n",
    "        baselines=ref_input_ids,\n",
    "        additional_forward_args=(attention_mask, token_type_ids),\n",
    "        target=choice_idx,  # Target the chosen answer, uses [0,target]\n",
    "        n_steps=n_steps,  # Number of steps for approximation\n",
    "        return_convergence_delta=True\n",
    "    )\n",
    "\n",
    "    # Sum across embedding dimensions to get token-level importance\n",
    "    token_attributions = attributions.sum(dim=-1).squeeze(0)  # shape: [num_choices, seq_len]\n",
    "    token_attributions = token_attributions / torch.norm(token_attributions)  # Normalize\n",
    "\n",
    "    if cfg.debug: \n",
    "        print('Token attributions:', token_attributions.shape)\n",
    "        print('Attributions per token at choice_idx:', token_attributions[choice_idx])\n",
    "    \n",
    "    return token_attributions, delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7028056f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 66])\n",
      "Logits from forward pass: torch.Size([1, 5])\n",
      "Logits from forward pass: torch.Size([1, 5])\n",
      "Logits from forward pass: torch.Size([1, 250])\n",
      "Logits from forward pass: torch.Size([1, 5])\n",
      "Logits from forward pass: torch.Size([1, 5])\n",
      "Token attributions: torch.Size([5, 66])\n",
      "Attributions per token at choice_idx: tensor([ 0.0000,  0.0124, -0.0009,  0.0494, -0.0439, -0.0926,  0.0074, -0.0237,\n",
      "        -0.0528,  0.0644, -0.0680,  0.0891,  0.0068, -0.0209, -0.0266, -0.0459,\n",
      "         0.0318, -0.1101, -0.0830,  0.0442,  0.0059, -0.0506, -0.0858, -0.0056,\n",
      "        -0.1056,  0.0064, -0.0730,  0.0778,  0.0030,  0.0269, -0.0234, -0.0425,\n",
      "        -0.0047,  0.0586, -0.0753,  0.0644, -0.0306, -0.0354,  0.0554,  0.0559,\n",
      "        -0.0163,  0.0141,  0.0425, -0.0919, -0.0123, -0.0568, -0.0327, -0.0351,\n",
      "        -0.0523, -0.1341,  0.2006,  0.0000, -0.1768, -0.0929,  0.1968,  0.1010,\n",
      "        -0.1696, -0.2514, -0.3831, -0.0369, -0.1994, -0.3325, -0.4731, -0.2818,\n",
      "        -0.1562,  0.0000])\n"
     ]
    }
   ],
   "source": [
    "# Main computation block, can take several minutes depending on the model, input length and number of steps.\n",
    "# If cfg.debug is True, it will print intermediate results to indicate progress.\n",
    "\n",
    "layer = model.bert.embeddings # Compute for embedding layer\n",
    "token_attributions, delta = get_token_attributions_for_layer(\n",
    "    layer, forward_func, choice_idx, input_ids, ref_input_ids, attention_masks, token_type_ids\n",
    ")\n",
    "\n",
    "# Get the attributions for the chosen answer and convert input ids to readable tokens\n",
    "choice_attributions = token_attributions[choice_idx]\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[choice_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "702aba61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>2</b></text></td><td><text style=\"padding-right:2em\"><b>1 (0.38)</b></text></td><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>-2.87</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> two                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> metal                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> balls                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> same                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> size                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> but                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> one                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> weighs                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> twice                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> much                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> other                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> balls                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> dropped                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> from                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> roof                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> single                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> story                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> building                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> at                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> same                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> instant                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> time                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> time                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> takes                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> balls                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> reach                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ground                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> below                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> will                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> be                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> :                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> about                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> half                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> long                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> lighter                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ball                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(0, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for                    </font></mark><mark style=\"background-color: hsl(0, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> heavier                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> one                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualise\n",
    "vis = viz.VisualizationDataRecord(\n",
    "                        choice_attributions,                        # word attributions\n",
    "                        torch.max(torch.softmax(logits, dim=1)),    # prediction probability\n",
    "                        torch.argmax(logits),                       # predicted class\n",
    "                        ground_truth_idx,                           # ground truth class\n",
    "                        str(choice_idx),                            # attributing to this class\n",
    "                        token_attributions.sum(),                   # summed attribution score\n",
    "                        tokens,                                     # tokens for the question and choice\n",
    "                        delta,                                      # convergence delta\n",
    ")\n",
    "\n",
    "visualisation = viz.visualize_text([vis]) # Save return object to avoid passing the vis object to the ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0ea568",
   "metadata": {},
   "source": [
    "Note the small attribution score (the model is not good enough to answer, so the words hardly matter, and partcularily the embedding layer is useless here), though the foci make sense. Also, the attribution takes ages (with no gpu for the differentiation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5517a5f8",
   "metadata": {},
   "source": [
    "Let's do the same with RoBERTa. The only real modification is that it does not use type_token_ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "759937e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing new here, just importing the RoBERTa model\n",
    "\n",
    "# Question and choices, shorter for larger model to reduce computation time\n",
    "question = \"What is the capital of France?\"\n",
    "choices = [\"Berlin\", \"Madrid\", \"Paris\"]\n",
    "ground_truth_idx = 2\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaForMultipleChoice\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"LIAMF-USP/roberta-large-finetuned-race\"\n",
    "model = RobertaForMultipleChoice.from_pretrained(model_name)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Set to evaluation mode\n",
    "model.to(device)\n",
    "model.eval()\n",
    "model.zero_grad()\n",
    "# model # Uncomment to print architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "563bb772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_everything(forward_func, layer, question=question, choices=choices, ground_truth_idx=ground_truth_idx, model=model, tokenizer=tokenizer, token_types=False, n_steps=50):\n",
    "    \"\"\"A quick function to do everything we have implemented so far: tokenize, make prediction, compute attributions and visualize.\"\"\"\n",
    "    # Tokenize for multiple choice and get input ids, attention masks, WITHOUT token type ids (token_types=False), \n",
    "    # and make prediction to get logits and choice index\n",
    "    input_ids, attention_masks, token_type_ids, logits, choice_idx = get_encoding_and_predict(question, choices, tokenizer, token_types=token_types)\n",
    "    ref_input_ids = get_baseline(tokenizer, input_ids, choice_idx)\n",
    "\n",
    "    # Compute attributition for embedding layer\n",
    "    token_attributions, delta = get_token_attributions_for_layer(\n",
    "        layer, forward_func, choice_idx, input_ids, ref_input_ids, attention_masks, token_type_ids, n_steps=n_steps, \n",
    "    )\n",
    "\n",
    "    # Get the attributions for the chosen answer and convert input ids to readable tokens\n",
    "    choice_attributions = token_attributions[choice_idx]\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[choice_idx])\n",
    "\n",
    "\n",
    "    # Visualize\n",
    "    choice_attributions = token_attributions[choice_idx]\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[choice_idx])\n",
    "\n",
    "    vis = viz.VisualizationDataRecord(\n",
    "                            choice_attributions,                        # word attributions\n",
    "                            torch.max(torch.softmax(logits, dim=1)),    # prediction probability\n",
    "                            torch.argmax(logits),                       # predicted class\n",
    "                            ground_truth_idx,                           # ground truth class\n",
    "                            str(choice_idx),                            # attributing to this class\n",
    "                            token_attributions.sum(),                   # summed attribution score\n",
    "                            tokens,                                     # tokens for the question and choice\n",
    "                            delta,                                      # convergence delta\n",
    "    )\n",
    "\n",
    "    viz.visualize_text([vis])\n",
    "\n",
    "    return choice_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0678691a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits from forward pass: torch.Size([1, 3])\n",
      "Question: What is the capital of France?\n",
      "Predicted Answer: 2) Paris\n",
      "Logits: tensor([[-0.4239, -2.1472,  4.5936]], grad_fn=<ViewBackward0>)\n",
      "torch.Size([3, 13])\n",
      "Logits from forward pass: torch.Size([1, 3])\n",
      "Logits from forward pass: torch.Size([1, 3])\n",
      "Logits from forward pass: torch.Size([1, 150])\n",
      "Logits from forward pass: torch.Size([1, 3])\n",
      "Logits from forward pass: torch.Size([1, 3])\n",
      "Token attributions: torch.Size([3, 13])\n",
      "Attributions per token at choice_idx: tensor([ 0.0000, -0.0511,  0.1184,  0.0214,  0.5090, -0.0007,  0.2750,  0.6631,\n",
      "        -0.3209, -0.2486, -0.0994, -0.1841,  0.0000])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>2</b></text></td><td><text style=\"padding-right:2em\"><b>2 (0.99)</b></text></td><td><text style=\"padding-right:2em\"><b>2</b></text></td><td><text style=\"padding-right:2em\"><b>0.68</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> What                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġis                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġthe                    </font></mark><mark style=\"background-color: hsl(120, 75%, 75%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġcapital                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġof                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ĠFrance                    </font></mark><mark style=\"background-color: hsl(120, 75%, 67%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Paris                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #pad                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute attributions wrt's RoBERTa embedding layer\n",
    "layer = model.roberta.embeddings\n",
    "do_everything(forward_func, layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cf97a0",
   "metadata": {},
   "source": [
    "As expected, 'capital' and 'France' (and also the question mark...) are most important for the model choice wrt. this layer. Note that it has very strong convivtion here, as opposed to the difficult FCI questions BERT faced. The RoBERTa model is better, but slightly too large for running comfortably with long inputs on my laptop, hence I don't use the FCI (which it does not do very well on - it does not seem to know to neglect air resistance in the metal ball question, and does not understand Newtons third law (nor forces in general) at all - which it is not trained for, so no surprises here)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c9ac4c",
   "metadata": {},
   "source": [
    "Since a change in input can increase ALL logits, we might want to use the softmaxed output to get at the words most inmportant for *differentiating* the choices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2da94c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits from forward pass: torch.Size([1, 3])\n",
      "Question: What is the capital of France?\n",
      "Predicted Answer: 2) Paris\n",
      "Logits: tensor([[-0.4239, -2.1472,  4.5936]], grad_fn=<ViewBackward0>)\n",
      "torch.Size([3, 13])\n",
      "Logits from forward pass: torch.Size([1, 3])\n",
      "Logits from forward pass: torch.Size([1, 3])\n",
      "Logits from forward pass: torch.Size([1, 150])\n",
      "Logits from forward pass: torch.Size([1, 3])\n",
      "Logits from forward pass: torch.Size([1, 3])\n",
      "Token attributions: torch.Size([3, 13])\n",
      "Attributions per token at choice_idx: tensor([ 0.0000, -0.0667, -0.2955, -0.2296,  0.2589,  0.0310,  0.4667,  0.3114,\n",
      "        -0.1623, -0.2125, -0.3267, -0.2078,  0.0000])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>2</b></text></td><td><text style=\"padding-right:2em\"><b>2 (0.99)</b></text></td><td><text style=\"padding-right:2em\"><b>2</b></text></td><td><text style=\"padding-right:2em\"><b>-0.53</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> What                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġis                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġthe                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġcapital                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġof                    </font></mark><mark style=\"background-color: hsl(120, 75%, 77%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ĠFrance                    </font></mark><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark><mark style=\"background-color: hsl(0, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Paris                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #pad                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward_func_softmax(input_ids, attention_mask, token_type_ids): # softmax wrapper\n",
    "    return forward_func(input_ids, attention_mask, token_type_ids).softmax(dim=1)\n",
    "\n",
    "do_everything(forward_func_softmax, layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e93adda",
   "metadata": {},
   "source": [
    "Note the negative overall attribution score; this indicates that the initial embedding layer did not prefer Paris to the other capitals, and that only later layers corrected for this. That aligns with the general view that facts are mostly contained in MPC-layers. In this way we can try to use LIG to indicate what layer has stored the fact \"Paris is the capital of France\" (alas, there are 24 (!) layers in this model, so we can only do this for a toy model - even here, all layers will by random chance prefer some alternative, so without tracing the full information path thorough the model it is nontrivial to do this in practice). \n",
    "\n",
    "The naive approach to find the imporant MLP-layers is given below (not nearly enough steps to get very accurate attributions; the delta-s should be examined if making a through analysis). We see that certain layers (Mainly MLP output-layer 0) give a strong push towards the correct answer, while the later layers are hardly involved or pushes in the opposite direction, and one could try to find a Paris node/feature in the eary layers of the model with patching.\n",
    "\n",
    "However, there is a much better way to do this with LayerConductance in Captum, which will follow below.\n",
    "\n",
    "<details>\n",
    "  <summary> Obvious application [click to expand]  </summary>\n",
    "\n",
    "Take a toy BERT model which can answer very easy MpCs (like capitals, or easier) and find the \"Paris in France\" **layer**, then use patching from Frederik to find specific **nodes**. I will not pursue this unless I have time in the end, since it is a straightforward (though not very likely to be successful) application of the tools in this notebook and the patching-notebook.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "92e4518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(model.roberta.encoder.layer)):\n",
    "#     print(i)\n",
    "#     layer = model.roberta.encoder.layer[i].output # or should i use the hidden mlp layer .intermediate? Can use .dense to do pre-(layerNorm/activation)\n",
    "#     do_everything(forward_func_softmax, layer, n_steps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62a2cda",
   "metadata": {},
   "source": [
    "### Muli-layer attribution\n",
    "As a final step with IG-attribution from captum, let's look at how to attribute the whole model rather than only a layer. The only difference is that we provide embeddings instead of ids to the IG attribution method (which is also an option with LIG, but ids are easier), since the ids are discrete/not diffable. So we need to tokenize *and* word/position/type-embed before inputting, and get the attribution for the layers that are not the embedding layers (which are essentially look-up-tables anyway/not the most interesting part of a transformer).\n",
    "\n",
    "We can also do LayerConductance to see attr-scores for each token across layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0143be43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# From here on down, I have not been too careful / reviewed yet - there might be errors (but the code runs).\n",
    "\n",
    "from captum.attr import LayerConductance\n",
    "\n",
    "# For plotting heatmaps\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Returning to smaller BERT-model\n",
    "model_name = 'jonastokoliu/multi_choice_bert-base-uncased_swag_finetune' # Pretrained (bad) MpC model\n",
    "model = BertForMultipleChoice.from_pretrained(model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "# Set to evaluation mode\n",
    "model.to(device)\n",
    "model.eval()\n",
    "model.zero_grad()\n",
    "\n",
    "# Absurd way to get choice idx for testing only\n",
    "# layer = model.bert.embeddings\n",
    "# choice_idx = do_everything(forward_func_softmax, layer, model=model, tokenizer=tokenizer, token_types=True)\n",
    "\n",
    "# Forward func taking embeds\n",
    "def forward_func_softmax_embed(input_emb, attention_mask=None):\n",
    "    \n",
    "    input_emb = input_emb.unsqueeze(0)\n",
    "    attention_mask = attention_mask.unsqueeze(0)\n",
    "\n",
    "    logits = model(\n",
    "        inputs_embeds=input_emb,\n",
    "        attention_mask=attention_mask,\n",
    "    ).logits\n",
    "\n",
    "    if cfg.debug: print(\"Logits from forward pass:\", logits.shape)\n",
    "    return logits.softmax(dim=1)\n",
    "\n",
    "# From demo, to get input_embs and ref_input_embs (running ids through emb layer)\n",
    "def construct_whole_bert_embeddings(input_ids, ref_input_ids, \\\n",
    "                                    token_type_ids=None, ref_token_type_ids=None, \\\n",
    "                                    position_ids=None, ref_position_ids=None):\n",
    "    input_embeddings = model.bert.embeddings(input_ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "    ref_input_embeddings = model.bert.embeddings(ref_input_ids, token_type_ids=ref_token_type_ids, position_ids=ref_position_ids)\n",
    "    \n",
    "    return input_embeddings, ref_input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "edb582b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 11, 768]) torch.Size([3, 11, 768])\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "\n",
    "ref_token_type_ids = torch.zeros_like(token_type_ids)  # Reference token type ids, all zeros for BERT\n",
    "position_ids = torch.arange(input_ids.size(1), dtype=torch.long, device=device)  # Position ids for the input sequence\n",
    "ref_position_ids = torch.zeros_like(position_ids)  # Reference position ids, all zeros for BERT\n",
    "\n",
    "input_embs, ref_input_embs = construct_whole_bert_embeddings(\n",
    "    input_ids, ref_input_ids, token_type_ids=token_type_ids, \n",
    "    ref_token_type_ids=ref_token_type_ids, position_ids=position_ids, ref_position_ids=ref_position_ids\n",
    ")\n",
    "\n",
    "if cfg.debug: print(input_embs.shape, ref_input_embs.shape)\n",
    "\n",
    "def summarize_attributions(attributions):\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    return attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7dad3e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits from forward pass: torch.Size([1, 153])\n",
      "Layer 1: -1.2461051386781037\n",
      "Logits from forward pass: torch.Size([1, 153])\n",
      "Layer 2: -1.2421367736533284\n",
      "Logits from forward pass: torch.Size([1, 153])\n",
      "Layer 3: -1.315762855578214\n",
      "Logits from forward pass: torch.Size([1, 153])\n",
      "Layer 4: -1.0917498202761635\n",
      "Logits from forward pass: torch.Size([1, 153])\n",
      "Layer 5: -1.1474649207666516\n",
      "Logits from forward pass: torch.Size([1, 153])\n",
      "Layer 6: -1.0865842448547482\n",
      "Logits from forward pass: torch.Size([1, 153])\n",
      "Layer 7: -1.0264790678629652\n",
      "Logits from forward pass: torch.Size([1, 153])\n",
      "Layer 8: -1.032434618100524\n",
      "Logits from forward pass: torch.Size([1, 153])\n",
      "Layer 9: -1.0169967371039093\n",
      "Logits from forward pass: torch.Size([1, 153])\n",
      "Layer 10: -1.081912085879594\n",
      "Logits from forward pass: torch.Size([1, 153])\n",
      "Layer 11: -1.2508521545678377\n",
      "Logits from forward pass: torch.Size([1, 153])\n",
      "Layer 12: -0.9224346876144409\n"
     ]
    }
   ],
   "source": [
    "layer_attrs = [] # Empty list to store attributions for each layer\n",
    "\n",
    "for i in range(model.config.num_hidden_layers): # attrubuting tokenwise for each layer\n",
    "    lc = LayerConductance(forward_func_softmax_embed, model.bert.encoder.layer[i])\n",
    "    layer_attributions = lc.attribute(inputs=input_embs, baselines=ref_input_embs, additional_forward_args=(attention_masks,), \\\n",
    "                                      target=choice_idx, n_steps=50, ) # reduced steps to speed up, sacrificing acc, though the trend holds up\n",
    "    layer_attrs.append(summarize_attributions(layer_attributions).cpu().detach().tolist())\n",
    "    print(f\"Layer {i+1}:\", np.sum(layer_attrs[i][choice_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b73e1ba",
   "metadata": {},
   "source": [
    "These results make no sense, crap. In fact, they seem to be inverted by the plot below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "36170947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 3, 11)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if cfg.debug: print(np.array(layer_attrs).shape)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "\n",
    "xticklabels=tokenizer.convert_ids_to_tokens(input_ids[choice_idx])\n",
    "yticklabels=list(range(1, model.config.num_hidden_layers+1))\n",
    "ax = sns.heatmap(np.array(layer_attrs)[:,choice_idx,:], xticklabels=xticklabels, yticklabels=yticklabels, linewidth=0.2) #, annot=True\n",
    "plt.xlabel('Tokens')\n",
    "plt.ylabel('Layers')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e86339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27af172f",
   "metadata": {},
   "source": [
    "It is also possible to look closely at specific tokens and how they are processed by each layer, see the very end of the [first Captum BERT demo](https://captum.ai/tutorials/Bert_SQUAD_Interpret) (This should be pretty much similar for our case when treating only the choice idx and using only one attribution rather than start and end). Attn interp can be seen in the attention notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
