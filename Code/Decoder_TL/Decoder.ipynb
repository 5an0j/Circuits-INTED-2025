{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c8d16db",
   "metadata": {},
   "source": [
    "## Overview of decoder style models and methods for interpretability\n",
    "\n",
    "# Summary\n",
    "\n",
    "- Circuit_Tracer: No success\n",
    "    environment crashes, does not support gpt2 and colab does not have enough memory. \n",
    "    Virtual environment with degraded transformer_lens?\n",
    "\n",
    "- TransformerLens: Except for some documentation lacking in proper input/output descriptions, this is a very suitable library for decoder style models. \n",
    "- CircuitsVis: Works well with TL. Has nice (and easy to use) visualizations for attention patterns\n",
    "        -> Can be used for finding induction heads.\n",
    "\n",
    "\n",
    "# Methods:\n",
    "\n",
    "-Induction heads:\n",
    "- More general, but also incomplete, ie it does not explain all of the decision process in a model\n",
    "\n",
    "Induction heads are one of the simplest circuits found in transformer models. They contribute to locating repeated tokens, helping in completions of \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
