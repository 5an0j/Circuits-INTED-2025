{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af0ea2b7",
   "metadata": {},
   "source": [
    "# Computational essay - Decoders and TransformerLens "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dde9e3",
   "metadata": {},
   "source": [
    "## Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfbcb07",
   "metadata": {},
   "source": [
    "1. [Introduction](#introduction)\n",
    "    - [Imports and setup](#imports-and-setup)\n",
    "    - [Helper functions](#helper-function)\n",
    "2. [Applications](#applications)\n",
    "    - [Preliminary exploration](#preliminary-exploration)\n",
    "    - [Attention patterns](#attention-patterns)\n",
    "    - [Induction heads](#induction-heads)\n",
    "    - [Activation patching](#activation-patching)\n",
    "    - [Logit Lens](#logit-lens)\n",
    "    - [Causal scrubbing](#causal-scrubbing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c939f810",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0497bdc",
   "metadata": {},
   "source": [
    "This computational essay on decoders and the TransformerLens library corresponds to the similarly titled sections of the report. In general, this run-through uses simple examples and a small model to clearly demonstrate the methods used and what type of results one may expect. We note that since the model is small, it does not perform the same as larger models, so the predictions are less accurate and thus, the effects of the interventions smaller. Moreover, it is according to the universality claim that these methods generalize to large scale models. As this is a postulate, we can not be sure of the validity of this assumption. This notebook does, however, show simple applications of some core methods for decoder interpretability research, which proves to be useful at smaller scales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261794e",
   "metadata": {},
   "source": [
    "The structure of this section of the essay is as follows: \n",
    "- First, we do all necessary setup, including imports, loading our model (in our case GPT2-small) and defining some helper functions.\n",
    "- Then, we go through the methods outlined in the corresponding paper. We explain our methods and choices, illustrate these methods with simple examples and suggest some relevant uses for these in later work. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8338e65",
   "metadata": {},
   "source": [
    "### Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f85980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some necessary imports\n",
    "import circuitsvis as cv\n",
    "import torch\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import tqdm.auto as tqdm\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens import HookedTransformer\n",
    "import numpy as np\n",
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9e8038e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# Loading the model used in this notebook\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544c7bad",
   "metadata": {},
   "source": [
    "We also disable automatic gradient computations as they are irrelevant to our work and quite time expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f83aa031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disabled automatic differentiation\n"
     ]
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "print(\"Disabled automatic differentiation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae125310",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda0be88",
   "metadata": {},
   "source": [
    "We define some helper functions for the visualizations. In the first function we use the CircuitsVis library with the \"attention_patterns\" and \"attention_heads\" methods to define a function which can visualize the attention patterns of chosen layers in the model.\n",
    "\n",
    "For the second function, we visualize the results of an activation patching in terms of the logit difference to the corrupted prompt (see section on Activation Patching)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af3b884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_attn_patterns(model, text, layers, compact=True):\n",
    "    ''' \n",
    "    Visualize attention patterns for a chosen number of layers.\n",
    "    '''\n",
    "    str_tokens = model.to_str_tokens(text)\n",
    "    logits, cache = model.run_with_cache(text, remove_batch_dim=True)\n",
    "\n",
    "    if compact:\n",
    "        for layer in layers:\n",
    "            print(\"Attention pattern for layer\", layer)\n",
    "            attention_pattern = cache[\"pattern\", layer]\n",
    "            display(cv.attention.attention_patterns(tokens=str_tokens, attention=attention_pattern))\n",
    "    \n",
    "    else:\n",
    "        for layer in layers:\n",
    "            print(\"Attention pattern for layer\", layer)\n",
    "            attention_pattern = cache[\"pattern\", layer]\n",
    "            display(cv.attention.attention_heads(tokens=str_tokens, attention=attention_pattern))\n",
    "\n",
    "def imshow_patching_result(model, patching_results, corrupted_prompt, corrupted_answer):\n",
    "    '''\n",
    "    Visualizes the logit differences caused by activation patching in a heat map. If the answer has more than one token, \"patching_results\" must be a list of results.\n",
    "    '''\n",
    "    if isinstance(patching_results, list):\n",
    "        len_ans = len(patching_results)\n",
    "        for i in range(len_ans):\n",
    "            tokens = model.to_str_tokens(corrupted_prompt+corrupted_answer)\n",
    "            labels = [f'{token}_{index}' for index, token in enumerate(tokens)][:-len(patching_results)+i]\n",
    "            if not torch.all(patching_results[i] == 0):\n",
    "                px.imshow(patching_results[i].detach(), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", x=labels, labels={\"x\": \"Position\", \"y\": \"Layer\"}, title=\"Patching Results\").show()\n",
    "    else:\n",
    "        tokens = model.to_str_tokens(corrupted_prompt)\n",
    "        labels = [f'{token}_{index}' for index, token in enumerate(tokens)]\n",
    "        px.imshow(patching_results[0].detach(), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", x=labels, labels={\"x\": \"Position\", \"y\": \"Layer\"}, title=\"Patching Results\").show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6631862a",
   "metadata": {},
   "source": [
    "## Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea695002",
   "metadata": {},
   "source": [
    "### Preliminary exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acb8f4c",
   "metadata": {},
   "source": [
    "We first want to check if the chosen model is suitable for the behavior we are interested in, that is, if it can perform the task at hand. The TransformerLens library has some convenient methods for this exact use. We choose a simple promt that we will use in the following sections as well: \"The capital of France is called\" with corresponding answer \" Paris\". We note the space in front of \"Paris\". That is to adhere to the tokenization of the name as being a single token. Inconsistency of spaces and tokenization is a common source of errors in implementations of interpretability research. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2aba45d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>', 'The', ' capital', ' city', ' of', ' France', ' is', ' called']\n",
      "['<|endoftext|>', ' Paris']\n"
     ]
    }
   ],
   "source": [
    "prompt = \"The capital city of France is called\"\n",
    "answer = \" Paris\"\n",
    "\n",
    "# We print the string tokens to examine the tokenization\n",
    "print(model.to_str_tokens(prompt))\n",
    "print(model.to_str_tokens(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333882ed",
   "metadata": {},
   "source": [
    "We now see what the model predicts as its top tokens. We note that the following function does not return anything, but is primarily intended for exploratory analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7aca8bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', 'The', ' capital', ' city', ' of', ' France', ' is', ' called']\n",
      "Tokenized answer: [' Paris']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.32</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.26</span><span style=\"font-weight: bold\">% Token: | Paris|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m14.32\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m8.26\u001b[0m\u001b[1m% Token: | Paris|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 14.32 Prob:  8.26% Token: | Paris|\n",
      "Top 1th token. Logit: 13.79 Prob:  4.86% Token: | Marse|\n",
      "Top 2th token. Logit: 13.78 Prob:  4.81% Token: | the|\n",
      "Top 3th token. Logit: 13.71 Prob:  4.49% Token: | \"|\n",
      "Top 4th token. Logit: 12.99 Prob:  2.17% Token: | La|\n",
      "Top 5th token. Logit: 12.68 Prob:  1.61% Token: | '|\n",
      "Top 6th token. Logit: 12.66 Prob:  1.57% Token: | Mont|\n",
      "Top 7th token. Logit: 12.60 Prob:  1.48% Token: | St|\n",
      "Top 8th token. Logit: 12.59 Prob:  1.46% Token: | Saint|\n",
      "Top 9th token. Logit: 12.30 Prob:  1.09% Token: | V|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Paris'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' Paris'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.test_prompt(prompt, answer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff15455",
   "metadata": {},
   "source": [
    "We see that even though our chosen model is small, it still predicts the correct next token. However, the probabilities are low, indicating that the model is not sure in its prediction. To solve this issue, one could choose a larger model, but for effiency's sake, we continue with the smaller model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6470bba2",
   "metadata": {},
   "source": [
    "### Attention patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0a61f6",
   "metadata": {},
   "source": [
    "We now want to visualize the attention patterns of our model. We use the same prompt as above, but this time use the visualization tools in the CircuitsVis library. The number of layers (and heads) of a model can be found as attributes for the defined model.\n",
    "\n",
    "We first perform a single forward pass through the model, caching the intermediate results. Then we find all attention patterns from the key \"attn\". Lastly, we visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fbad5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 - Head Attention Patterns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-3e766a68-075e\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-3e766a68-075e\",\n",
       "      AttentionPatterns,\n",
       "      {\"tokens\": [\"<|endoftext|>\", \"The\", \" capital\", \" city\", \" of\", \" France\", \" is\", \" called\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9330379366874695, 0.06696204841136932, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7481917142868042, 0.15690255165100098, 0.09490570425987244, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6830142736434937, 0.17506012320518494, 0.0756121277809143, 0.06631346046924591, 0.0, 0.0, 0.0, 0.0], [0.6278766393661499, 0.1569468230009079, 0.11491646617650986, 0.06450341641902924, 0.035756662487983704, 0.0, 0.0, 0.0], [0.5420671105384827, 0.1728079915046692, 0.10880528390407562, 0.03487572818994522, 0.08993120491504669, 0.051512643694877625, 0.0, 0.0], [0.638913094997406, 0.15001702308654785, 0.0646982342004776, 0.037338025867938995, 0.024072468280792236, 0.04598190635442734, 0.03897940367460251, 0.0], [0.46543052792549133, 0.13460391759872437, 0.042426545172929764, 0.07478994131088257, 0.04993065446615219, 0.03528960049152374, 0.08848980814218521, 0.10903900116682053]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0013863482745364308, 0.9986135959625244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.428290074225515e-05, 0.00111431407276541, 0.9988514184951782, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002673919952940196, 0.004994214046746492, 0.017230218276381493, 0.9775082468986511, 0.0, 0.0, 0.0, 0.0], [0.0009970695246011019, 0.010548763908445835, 0.0003620860807131976, 0.00025853124679997563, 0.9878334999084473, 0.0, 0.0, 0.0], [0.00015725829871371388, 0.002689819550141692, 0.0014392506564036012, 0.0007259707781486213, 0.000810127763543278, 0.9941775798797607, 0.0, 0.0], [0.0011828497517853975, 0.005403953138738871, 0.0011594609823077917, 0.000481531023979187, 0.007938828319311142, 0.0005526021705009043, 0.9832807779312134, 0.0], [0.0001529250730527565, 0.0029631478246301413, 0.0004530877631623298, 0.00021981554164085537, 0.0007025093073025346, 0.00014135705714579672, 0.0002864688285626471, 0.9950807094573975]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9405120015144348, 0.05948803201317787, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8763945698738098, 0.07620296627283096, 0.047402456402778625, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7891925573348999, 0.08365944027900696, 0.03841212019324303, 0.08873582631349564, 0.0, 0.0, 0.0, 0.0], [0.6685565114021301, 0.11871708184480667, 0.07388640195131302, 0.03278600797057152, 0.10605402290821075, 0.0, 0.0, 0.0], [0.5113228559494019, 0.0966620072722435, 0.10638955235481262, 0.10043805837631226, 0.05070377513766289, 0.1344837099313736, 0.0, 0.0], [0.5076478123664856, 0.1238265112042427, 0.040289025753736496, 0.03430921956896782, 0.11996437609195709, 0.04655833914875984, 0.12740468978881836, 0.0], [0.5171942710876465, 0.13578671216964722, 0.04452580586075783, 0.03178329020738602, 0.09382332116365433, 0.026384152472019196, 0.11741794645786285, 0.03308449313044548]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4126836955547333, 0.5873163938522339, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07617979496717453, 0.005782557651400566, 0.9180377125740051, 0.0, 0.0, 0.0, 0.0, 0.0], [0.013560423627495766, 0.0021578765008598566, 0.16520698368549347, 0.8190747499465942, 0.0, 0.0, 0.0, 0.0], [0.03695852309465408, 0.06098167970776558, 0.029992790892720222, 0.1481316089630127, 0.7239354252815247, 0.0, 0.0, 0.0], [0.00633814325556159, 0.0005466820439323783, 0.007027189247310162, 0.0035358017776161432, 0.000816629093606025, 0.9817355275154114, 0.0, 0.0], [0.031162330880761147, 0.016101641580462456, 0.003150481265038252, 0.003982285503298044, 0.053673818707466125, 0.01303448062390089, 0.8788949847221375, 0.0], [0.003378575434908271, 0.0002759516064543277, 0.0007279930869117379, 0.001048434991389513, 0.0017744344659149647, 0.0011163566960021853, 0.012481783516705036, 0.9791964888572693]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8783947229385376, 0.1216052770614624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1749310940504074, 0.05496065318584442, 0.7701082825660706, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17071403563022614, 0.03410600125789642, 0.23699156939983368, 0.5581884384155273, 0.0, 0.0, 0.0, 0.0], [0.19993740320205688, 0.0920334979891777, 0.2904568910598755, 0.31232526898384094, 0.10524697601795197, 0.0, 0.0, 0.0], [0.027803407981991768, 0.009697743691504002, 0.010611413046717644, 0.014678516425192356, 0.013436540961265564, 0.923772394657135, 0.0, 0.0], [0.16716288030147552, 0.09619127959012985, 0.09831851720809937, 0.07028263807296753, 0.13572438061237335, 0.11567413061857224, 0.31664612889289856, 0.0], [0.07918575406074524, 0.030657369643449783, 0.029794324189424515, 0.044173214584589005, 0.06524267047643661, 0.042183905839920044, 0.06214729696512222, 0.6466155648231506]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23076651990413666, 0.7692334651947021, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018988648429512978, 2.8098724214942195e-05, 0.980983316898346, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0400814488530159, 2.1764300981885754e-05, 0.005189917981624603, 0.9547068476676941, 0.0, 0.0, 0.0, 0.0], [0.24755269289016724, 0.14379985630512238, 0.01697460748255253, 0.007231441792100668, 0.5844414234161377, 0.0, 0.0, 0.0], [0.03932628780603409, 2.6109020836884156e-05, 6.277508509811014e-05, 5.044593308412004e-06, 2.229083293059375e-06, 0.9605774879455566, 0.0, 0.0], [0.0946461409330368, 0.005572891794145107, 0.0052385488525033, 0.0007637781673111022, 0.0038749221712350845, 0.0005767837865278125, 0.8893268704414368, 0.0], [0.013299561105668545, 0.0032040495425462723, 0.00015916152915451676, 0.00022376893321052194, 0.0002797463966999203, 8.111340866889805e-05, 0.00012352368503343314, 0.9826290607452393]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9734153151512146, 0.02658473514020443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7268739342689514, 0.06959218531847, 0.2035338282585144, 0.0, 0.0, 0.0, 0.0, 0.0], [0.582089900970459, 0.05652893707156181, 0.24662698805332184, 0.11475425958633423, 0.0, 0.0, 0.0, 0.0], [0.3764425218105316, 0.06864595413208008, 0.3212553560733795, 0.21035900712013245, 0.02329719066619873, 0.0, 0.0, 0.0], [0.3909589648246765, 0.12254078686237335, 0.1943785399198532, 0.08781001716852188, 0.023631270974874496, 0.18068039417266846, 0.0, 0.0], [0.22126303613185883, 0.03662170097231865, 0.22865478694438934, 0.1968827098608017, 0.018527522683143616, 0.26472288370132446, 0.03332734853029251, 0.0], [0.22688819468021393, 0.03772936761379242, 0.19526799023151398, 0.20311777293682098, 0.02736939862370491, 0.2385156750679016, 0.02605249732732773, 0.045058973133563995]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9788066744804382, 0.0211933683604002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5100209712982178, 0.4115009009838104, 0.07847811281681061, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20438022911548615, 0.15309682488441467, 0.5606700778007507, 0.08185280114412308, 0.0, 0.0, 0.0, 0.0], [0.19916965067386627, 0.15665294229984283, 0.1549345999956131, 0.31149640679359436, 0.17774641513824463, 0.0, 0.0, 0.0], [0.18963144719600677, 0.14901670813560486, 0.05141741782426834, 0.16834348440170288, 0.2960304021835327, 0.14556050300598145, 0.0, 0.0], [0.13856296241283417, 0.0844811201095581, 0.0498352125287056, 0.07742035388946533, 0.15113595128059387, 0.14152094721794128, 0.35704347491264343, 0.0], [0.13216321170330048, 0.06301167607307434, 0.0428890660405159, 0.059078920632600784, 0.11921756714582443, 0.07879626750946045, 0.3699660301208496, 0.1348773092031479]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.799264132976532, 0.2007359117269516, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8051559329032898, 0.1376953423023224, 0.05714874342083931, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6279124021530151, 0.21951599419116974, 0.10876128077507019, 0.043810345232486725, 0.0, 0.0, 0.0, 0.0], [0.21231505274772644, 0.211748406291008, 0.08216049522161484, 0.0864497572183609, 0.40732625126838684, 0.0, 0.0, 0.0], [0.5032027363777161, 0.1866861879825592, 0.07291809469461441, 0.07257822155952454, 0.10223522037267685, 0.06237954646348953, 0.0, 0.0], [0.1363116055727005, 0.12827084958553314, 0.031890686601400375, 0.03658344969153404, 0.18690451979637146, 0.030651576817035675, 0.4493873715400696, 0.0], [0.1946474015712738, 0.12259548902511597, 0.10359290987253189, 0.03182654827833176, 0.17268149554729462, 0.03285432606935501, 0.2901928424835205, 0.051608990877866745]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8372090458869934, 0.16279096901416779, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8304312825202942, 0.1559387594461441, 0.013629939407110214, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7696604132652283, 0.16533422470092773, 0.051520444452762604, 0.01348490733653307, 0.0, 0.0, 0.0, 0.0], [0.557019054889679, 0.16448649764060974, 0.06010318920016289, 0.07528780400753021, 0.1431034803390503, 0.0, 0.0, 0.0], [0.5664286017417908, 0.14023397862911224, 0.06993290781974792, 0.1197643056511879, 0.08510815352201462, 0.01853201352059841, 0.0, 0.0], [0.41469892859458923, 0.14410358667373657, 0.06867869198322296, 0.07643033564090729, 0.1288139671087265, 0.054848480969667435, 0.1124260202050209, 0.0], [0.4351959526538849, 0.12246433645486832, 0.06744185835123062, 0.057996708899736404, 0.09774971753358841, 0.0693112313747406, 0.09667292982339859, 0.05316726118326187]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7383899688720703, 0.2616100013256073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5780839920043945, 0.17437955737113953, 0.24753648042678833, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4657759368419647, 0.17604807019233704, 0.09680507332086563, 0.2613708972930908, 0.0, 0.0, 0.0, 0.0], [0.46263980865478516, 0.18417946994304657, 0.06231260672211647, 0.04503336921334267, 0.2458348125219345, 0.0, 0.0, 0.0], [0.38173672556877136, 0.18905800580978394, 0.06374610960483551, 0.06317949295043945, 0.08864232897758484, 0.21363729238510132, 0.0, 0.0], [0.3022780120372772, 0.18831950426101685, 0.06708964705467224, 0.044427935034036636, 0.12951365113258362, 0.028462281450629234, 0.23990894854068756, 0.0], [0.3024858236312866, 0.151759073138237, 0.055951278656721115, 0.051312632858753204, 0.11047982424497604, 0.021824683994054794, 0.07907751202583313, 0.2271091789007187]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7672996520996094, 0.23270036280155182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5225909352302551, 0.39523473381996155, 0.08217435330152512, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5423195958137512, 0.23801514506340027, 0.11296598613262177, 0.10669925063848495, 0.0, 0.0, 0.0, 0.0], [0.5874335169792175, 0.15096217393875122, 0.11297937482595444, 0.08180059492588043, 0.06682438403367996, 0.0, 0.0, 0.0], [0.4170355796813965, 0.14011657238006592, 0.13787011802196503, 0.11726886034011841, 0.0877065658569336, 0.10000230371952057, 0.0, 0.0], [0.5307919979095459, 0.11297823488712311, 0.06686341762542725, 0.05415917560458183, 0.05730989947915077, 0.0703386664390564, 0.10755853354930878, 0.0], [0.48080694675445557, 0.1423693597316742, 0.05005333200097084, 0.05185586214065552, 0.06408051401376724, 0.06907548010349274, 0.05175667628645897, 0.09000186622142792]]]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x1b60b63c410>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We decide to show the first layer (index 0)\n",
    "\n",
    "model_tokens = model.to_tokens(prompt)\n",
    "model_logits, model_cache = model.run_with_cache(model_tokens, remove_batch_dim=True)\n",
    "\n",
    "attention_patterns = model_cache[\"pattern\", 0, \"attn\"]\n",
    "str_tokens = model.to_str_tokens(prompt)\n",
    "\n",
    "print(\"Layer 0 - Head Attention Patterns\")\n",
    "cv.attention.attention_patterns(tokens=str_tokens, attention=attention_patterns)\n",
    "#plt.savefig(\"attention_L0.png\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba587955",
   "metadata": {},
   "source": [
    "From these patterns, we can see a few things. First, we see that for many of the heads (i.e. 0, 2 and 9) the first column is the most strongly colored. This indicates that the tokens all attend to the first token. This token is a \"Beginning of Sentence\" (BOS) token and thus does not inherently contain any information. This then acts as an available place to store information. \n",
    "\n",
    "Secondly, we see that some heads (i.e. 1 and mostly 5) does not act. The tokens only attend to themselves, and we see this clearly with the diagonal in the figure. \n",
    "\n",
    "Lastly, some of the head (i.e. 8 and 10) have more interesting patterns. While there is still some column 1 dominance, they also seem to act significantly on other token pairs. This could provide an interesting starting point for further investingation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c6e447",
   "metadata": {},
   "source": [
    "### Induction heads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7522f7b",
   "metadata": {},
   "source": [
    "We now turn to induction heads, one of the simplest circuits found in smaller models. These are one-off attention heads, responsible for detecting repetition in sequences. By visualizing the attention patterns, we can clearly see these induction heads. \n",
    "\n",
    "The following approach is based on the one found in Neel Nanda's colab notebook \"Transformer Lens Main Demo Notebook\" found [here](https://colab.research.google.com/github/neelnanda-io/TransformerLens/blob/main/demos/Main_Demo.ipynb). We first choose a repeating sequence. To compare to the previous example, we use \"The capital of France is called Paris. The capital of France is called\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfb64189",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_prompt = (prompt+answer+\".\")*2\n",
    "repeated_tokens = model.to_tokens(repeated_prompt)\n",
    "\n",
    "sequence_len = len(model.to_str_tokens(repeated_prompt))//2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd9b8d5",
   "metadata": {},
   "source": [
    "Then, we define an induction score which we will use to measure how much each attention head acts as an induction head. We do this by averaging all attention scores starting from the beginning of the second repetition. To access the intermediate values of the model, we must use the hook functionaly provided by TransformerLens. By defining a hook function, and later calling it with the \"run_with_hooks\" method, we can calculate the average attention scores during the forward pass and save them to an induction_score_store tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7553d9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "induction_score_store = torch.zeros((model.cfg.n_layers, model.cfg.n_heads), device=model.cfg.device)\n",
    "\n",
    "def induction_score_hook(activation_pattern, hook):\n",
    "    # We take the diagonal for all tokens with index>=sequence_len\n",
    "    induction_stripe = activation_pattern.diagonal(dim1=-2, dim2=-1, offset=1-sequence_len)\n",
    "    # We get the average score for each head\n",
    "    induction_score = einops.reduce(induction_stripe, \"batch head_index position -> head_index\", \"mean\")\n",
    "    # We store the results\n",
    "    induction_score_store[hook.layer(), :] = induction_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497a7092",
   "metadata": {},
   "source": [
    "We now write to the \"induction_score_store\" tensor by running a forward pass of the model with the given prompt with the hook function. The way this works is that the model has preset hooks at all important (for instance attention head or tokens in the residual stream) points in the network. These all have corresponding keywords, and we want to include all hook points regarding attention patterns. Then, when using the \"run_with_hooks\" method, the model will stop at all given hook points and call the hook function we have defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc09f4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make a boolean filter on activation names\n",
    "pattern_hook_names_filter = lambda name: name.endswith(\"pattern\")\n",
    "\n",
    "# Run with hooks (this is where we write to the `induction_score_store` tensor`)\n",
    "model.run_with_hooks(repeated_tokens,\n",
    "    return_type=None, # For efficiency, we don't need to calculate the logits\n",
    "    fwd_hooks=[(\n",
    "        pattern_hook_names_filter,\n",
    "        induction_score_hook\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83a229c",
   "metadata": {},
   "source": [
    "Having run a forward pass on the model with the hook function, we can now plot the induction scores for each head in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0026bb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Head: %{x}<br>Layer: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{z:.2f}",
         "type": "heatmap",
         "xaxis": "x",
         "yaxis": "y",
         "z": {
          "bdata": "ZNG4PQAm0Dm/R9c9muzOOs+qSjwcvvg8wjqnPT0g3jw4nZg9zEzJPcIWkj3viJM9878cPWYLfj25MIs9h7WTPRnfrD3E4NE9FuHDPVGywD0RfcY9Zt/UPYN1az2xPwo9BvmHPSE86z2gBNo8vmgvPdEqiT3BScY8XSTOPUSTUj0hzQs9P5zFPKQ9bz0OSpw9oteIPcpTgj02lwQ9KqqwPeHpxT1Ay9o92ptwPVdAYz3dETs9+UG+Pa8tlz2zjjw9ivtzPYmRAz3sNt49tQyHPeGOvD1nDQ49YyiiPc/ERT3KQtM9bISFPaQlVD2CW443sEq3PvOIFT/Lp7Q9HY6nPRRfXj05hMY+Ua6oPWuwoz0Pi2o+XOUOPkwXcD0n05c9wmGxPC8ZJz5Ulr49MX/RPZlw7j0xWbc9OV0PPmzLyD0KMqM9DPS7PtTg7z3rboo9AnkcPfYyGj629gk/xzn8PXC8hD2FvbE9M4XjPf2oHj59/cg9IT7qPRrv/j4ZmwU+kMu6PXMM+j4UfdE9+V/pPZQovD2s7YM99MWZPnjjCD055/E9t/XWPc0sMT7MBMI9PfYIPsx0XD7TTs09H/YuPXC87j0aB8I9p1lGPkOYzT1huNw9gdqXPiTsFj33X/Q9c2smPloVWT76RP89YeIuPmfpET407o49+gMePtMNgD4b/Qw+lxh0PdL8KD6HkSQ+SnjSPbdW+j2PYt09bZmePXGXwz1aRRo+V5PlPWf07z0galg9+fsPPkxsOT5aXfk9",
          "dtype": "f4",
          "shape": "12, 12"
         }
        }
       ],
       "layout": {
        "coloraxis": {
         "cmid": 0,
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Induction Score by Head"
        },
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "title": {
          "text": "Head"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Layer"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.imshow(induction_score_store, color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", labels={\"x\":\"Head\", \"y\":\"Layer\"}, title=\"Induction Score by Head\", text_auto=\".2f\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47280afd",
   "metadata": {},
   "source": [
    "We see that some of the heads are more strongly activated. To see how this shows on the attention patterns, we visualize the attention patterns for the 5th and 7th layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a02e9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention pattern for layer 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-74c7a8fc-9d87\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-74c7a8fc-9d87\",\n",
       "      AttentionPatterns,\n",
       "      {\"tokens\": [\"<|endoftext|>\", \"The\", \" capital\", \" city\", \" of\", \" France\", \" is\", \" called\", \" Paris\", \".\", \"The\", \" capital\", \" city\", \" of\", \" France\", \" is\", \" called\", \" Paris\", \".\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9971821308135986, 0.0028179490473121405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9861010909080505, 0.0013596408534795046, 0.012539324350655079, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9728667736053467, 0.0004368768131826073, 0.0047807348892092705, 0.02191566303372383, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9962651133537292, 0.0003160590713378042, 0.0010199749376624823, 0.0003064342890866101, 0.0020924853160977364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9880207180976868, 0.0005679122405126691, 0.0004637227102648467, 0.00021411718626040965, 0.000921010272577405, 0.00981250312179327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9723876118659973, 0.0002752735454123467, 0.0001390653633279726, 0.0003909788792952895, 0.0009332814952358603, 0.0038056587800383568, 0.022067999467253685, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9736549258232117, 0.0001950909208972007, 0.000380160054191947, 0.0006748350569978356, 0.0008998834528028965, 0.0008452413021586835, 0.006370783317834139, 0.01697910949587822, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9496392607688904, 0.00015538734442088753, 0.0029155698139220476, 0.0011152001097798347, 0.0019109261920675635, 0.0019439466996118426, 0.011632992886006832, 0.0015695025213062763, 0.02911711484193802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9658393263816833, 0.0001706530892988667, 0.0009068250074051321, 0.0012523593613877892, 0.006874054670333862, 0.0009455386898480356, 0.0013671289198100567, 0.007216799072921276, 0.0070981914177536964, 0.008329215459525585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7813329100608826, 0.00034750765189528465, 0.11300928890705109, 0.009291671216487885, 0.027301186695694923, 0.0026062254328280687, 0.0078555503860116, 0.0106881782412529, 0.007720679976046085, 0.004296410828828812, 0.035550590604543686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6744756698608398, 0.0004324686888139695, 0.006852859631180763, 0.02472595125436783, 0.20372894406318665, 0.02274143137037754, 0.016231974586844444, 0.02421501651406288, 0.01714167557656765, 0.003165810601785779, 0.00282593397423625, 0.003462322521954775, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5748763084411621, 0.00012420251732692122, 0.002741225529462099, 0.003228423884138465, 0.29314351081848145, 0.036564458161592484, 0.04157567396759987, 0.02191607840359211, 0.00796527974307537, 0.006062706466764212, 0.0038958494551479816, 0.0013553701573982835, 0.006550949066877365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7558809518814087, 0.00014462046965491027, 0.001388978329487145, 0.00027002074057236314, 0.0005030790925957263, 0.09341675788164139, 0.13544972240924835, 0.003151616081595421, 0.004599214531481266, 0.0026669208891689777, 0.0014216755516827106, 0.00043620154610835016, 0.00021242329967208207, 0.0004578049702104181, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7572906613349915, 0.0002647037908900529, 0.00046684895642101765, 0.00013402107288129628, 0.0001867334358394146, 0.005986281670629978, 0.196519136428833, 0.005414169281721115, 0.004792705178260803, 0.012431059032678604, 0.01313561387360096, 0.0003432195808272809, 0.00024874755763448775, 0.00023153584334068, 0.0025545605458319187, 0.0, 0.0, 0.0, 0.0], [0.6392036080360413, 0.00012354810314718634, 0.00019237531523685902, 0.0003350182087160647, 0.00020670454250648618, 0.002434481168165803, 0.011774789541959763, 0.13250192999839783, 0.0965966284275055, 0.05886436626315117, 0.031363122165203094, 0.00037647609133273363, 0.00029174695373512805, 0.00025529571576043963, 0.002598404884338379, 0.022881576791405678, 0.0, 0.0, 0.0], [0.24269936978816986, 5.64405600016471e-05, 0.000348317640600726, 0.00034856953425332904, 0.00016585957200732082, 0.00039724892121739686, 0.0034529371187090874, 0.006158644333481789, 0.6526834964752197, 0.061433032155036926, 0.01191390585154295, 0.0007946922560222447, 0.0007783525506965816, 0.00048814713954925537, 0.0005066104931756854, 0.010582379065454006, 0.007191963028162718, 0.0, 0.0], [0.23890461027622223, 2.178177237510681e-05, 0.0008681030594743788, 0.00027040272834710777, 0.00012932879326399416, 0.0002892966440413147, 0.0016461012419313192, 0.0002574336249381304, 0.01405461598187685, 0.7185104489326477, 0.004201741423457861, 0.0016821172321215272, 0.00037666590651497245, 0.00020855387265328318, 0.00025763650774024427, 0.005082739982753992, 0.00021252833539620042, 0.013025924563407898, 0.0], [0.17774324119091034, 0.0001137449944508262, 0.0009938629809767008, 0.000562880770303309, 0.00035943102557212114, 0.0002479266549926251, 0.0005081325653009117, 0.0008203350589610636, 0.0018020309507846832, 0.0021576343569904566, 0.7635881900787354, 0.01769406907260418, 0.004781040363013744, 0.004969700705260038, 0.0007835070719011128, 0.009089430794119835, 0.0030473044607788324, 0.0013346194755285978, 0.009402892552316189]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9998077750205994, 0.00019227554730605334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.999184787273407, 8.13897349871695e-06, 0.000807129021268338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9962804913520813, 6.925356956344331e-06, 7.882966201577801e-06, 0.0037048179656267166, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9999644756317139, 6.198775736265816e-06, 1.1057196388719603e-05, 7.325886031139817e-07, 1.757071186148096e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.999092698097229, 7.991684469743632e-06, 3.6437959352042526e-06, 5.233265483184368e-07, 1.9478386548144044e-06, 0.0008932951604947448, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9983091354370117, 1.3489143384504132e-05, 2.5125709726125933e-05, 8.77095430951158e-07, 1.7421912161807995e-06, 0.0002567401679698378, 0.0013929948909208179, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9971711039543152, 4.810179234482348e-06, 1.1143511983391363e-05, 4.1780996440365925e-08, 3.9078624780586324e-08, 1.8025402823695913e-05, 3.87378349842038e-05, 0.002756121102720499, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9963711500167847, 2.5534354790579528e-06, 1.929071731865406e-05, 2.4324640435224865e-07, 3.199062348357984e-06, 7.152646048780298e-06, 0.0005832077586092055, 0.0011370301945134997, 0.0018762832041829824, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9944207072257996, 2.842025969584938e-05, 0.00011343931691953912, 3.4343631796218688e-06, 8.467573024972808e-06, 6.640891660936177e-05, 0.00016937196778599173, 0.001999863190576434, 0.0005904861609451473, 0.0025994330644607544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8057953119277954, 0.00021486601326614618, 0.19041064381599426, 6.431611109292135e-05, 1.5660900771763409e-06, 2.176664929720573e-05, 1.3997027053846978e-05, 0.0001488536363467574, 0.00041658547706902027, 1.187198722618632e-05, 0.0029001159127801657, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24585072696208954, 6.717106589348987e-05, 0.0021744307596236467, 0.7458240985870361, 0.005352115258574486, 0.00018273292516823858, 5.596745540970005e-05, 0.0002825231058523059, 4.001152774435468e-05, 1.9346880435477942e-06, 3.043780270672869e-05, 0.00013788050273433328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3292516767978668, 2.1155736249056645e-05, 4.3409745558165014e-05, 0.0035116991493850946, 0.6541413068771362, 0.0030932568479329348, 0.0005045827128924429, 0.0025352274533361197, 1.8785551219480112e-05, 8.159647222782951e-06, 5.898800372960977e-05, 3.7841264202143066e-06, 0.006807982921600342, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4431045353412628, 1.357325254502939e-05, 3.024920260941144e-05, 1.6139979379659053e-06, 1.122122284868965e-05, 0.555946946144104, 0.00012394865916576236, 0.00025422402541153133, 0.0002474729553796351, 1.5840464584471192e-07, 0.00024385358847212046, 8.289839570352342e-06, 9.039532073984446e-07, 1.3049959306954406e-05, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5763136744499207, 1.1869266927533317e-05, 1.0555437256698497e-05, 1.5853408967814175e-06, 6.577180556632811e-06, 0.0049664853140711784, 0.41245830059051514, 0.0027617320884019136, 0.0002569650241639465, 0.0004898712504655123, 0.0016750656068325043, 5.076909019408049e-06, 4.849935521633597e-06, 4.356430963525781e-06, 0.0010331127559766173, 0.0, 0.0, 0.0, 0.0], [0.5233758687973022, 1.122635330830235e-05, 2.830226549122017e-05, 9.265955895898514e-07, 6.438970672206779e-07, 0.0007022720528766513, 0.0032938774675130844, 0.4317667782306671, 0.020160488784313202, 0.0003583994694054127, 0.01765599474310875, 3.127923991996795e-05, 1.0766538025563932e-06, 1.0068004030472366e-06, 0.00023632335069123656, 0.002375546144321561, 0.0, 0.0, 0.0], [0.16143590211868286, 4.055957106174901e-06, 1.9087723558186553e-05, 1.0085869206477582e-07, 2.6996271884627276e-08, 4.3411546357674524e-05, 8.257980516646057e-05, 0.004435522016137838, 0.8279320001602173, 0.00024691305588930845, 0.004193310625851154, 4.7627130697946995e-05, 1.5222603622078168e-07, 1.0954269669127825e-07, 1.327722657151753e-05, 3.638249836512841e-05, 0.001509505556896329, 0.0, 0.0], [0.34278714656829834, 1.053262622008333e-06, 1.3228340321802534e-05, 1.126860098565885e-07, 1.0827254754985915e-06, 4.933791842631763e-06, 0.0006049760268069804, 0.001397448591887951, 0.003760921536013484, 0.646203875541687, 0.0010695966193452477, 2.6160585548495874e-05, 3.8975514371486497e-07, 1.2808667406716268e-06, 1.241670588569832e-06, 0.0002497284731362015, 0.0003188671835232526, 0.0035578564275056124, 0.0], [0.032813623547554016, 6.598936010959733e-07, 9.020342986332253e-06, 1.3482545568876958e-07, 1.7300642696227442e-07, 1.4576648936781567e-05, 7.357272988883778e-05, 0.0004926490364596248, 0.00023747167142573744, 0.00035324780037626624, 0.9642460346221924, 0.0004426460654940456, 3.8563066482311115e-06, 4.757876922667492e-06, 2.314245284651406e-05, 0.00020448819850571454, 0.0004076641343999654, 0.0001142683468060568, 0.000558080559130758]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9880749583244324, 0.011925098486244678, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9026990532875061, 0.07394490391016006, 0.023355990648269653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6728752255439758, 0.0717083215713501, 0.24520589411258698, 0.010210554115474224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2985161542892456, 0.06331134587526321, 0.4658466577529907, 0.164971262216568, 0.007354562170803547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.40992969274520874, 0.04003918543457985, 0.15307337045669556, 0.08771427720785141, 0.2863697111606598, 0.022873729467391968, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3669815957546234, 0.09998606890439987, 0.19262202084064484, 0.036543749272823334, 0.1933436095714569, 0.05958787351846695, 0.05093510076403618, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7382330894470215, 0.052071429789066315, 0.05607401579618454, 0.005255437456071377, 0.0363704189658165, 0.026414448395371437, 0.07582059502601624, 0.009760669432580471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7121425867080688, 0.02674800716340542, 0.014556237496435642, 0.00402591610327363, 0.05197673663496971, 0.009305617772042751, 0.08502040058374405, 0.08525919169187546, 0.010965215973556042, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.36122941970825195, 0.08335039019584656, 0.026311306282877922, 0.004618643783032894, 0.015930665656924248, 0.017363347113132477, 0.1376895159482956, 0.12932875752449036, 0.1715211570262909, 0.05265689268708229, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4471933841705322, 0.0023146250750869513, 0.005159256048500538, 0.0007692622602917254, 0.006119086407124996, 0.0074973939917981625, 0.042728815227746964, 0.070735402405262, 0.05376981198787689, 0.35099485516548157, 0.012718087993562222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7799720764160156, 0.005498147569596767, 0.0008879447705112398, 0.0004135837370995432, 0.0016645664582028985, 0.003976647276431322, 0.006867018062621355, 0.01733260042965412, 0.008533225394785404, 0.03748789802193642, 0.12844863533973694, 0.008917776867747307, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4876331686973572, 0.004024610389024019, 0.006963426247239113, 0.0005423010443337262, 0.0013401319738477468, 0.0034496814478188753, 0.00837535411119461, 0.004699815064668655, 0.007308444939553738, 0.0411764532327652, 0.3158763349056244, 0.10088994354009628, 0.01772036775946617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4646010100841522, 0.0039292615838348866, 0.011765495873987675, 0.007494176272302866, 0.0002153671666746959, 0.001581842778250575, 0.0012287129648029804, 0.0014847400598227978, 0.0027350890450179577, 0.010327467694878578, 0.0855817198753357, 0.20500050485134125, 0.19744691252708435, 0.006607541814446449, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24690264463424683, 0.0029600991401821375, 0.009615161456167698, 0.006370777264237404, 0.010096060112118721, 0.0005937530659139156, 0.00151918176561594, 0.002197103574872017, 0.0019490149570629, 0.004391705617308617, 0.07412631064653397, 0.22510306537151337, 0.18952110409736633, 0.2130642831325531, 0.01158976461738348, 0.0, 0.0, 0.0, 0.0], [0.4225437045097351, 0.004425057675689459, 0.006931913550943136, 0.0017951136687770486, 0.0037593571469187737, 0.001920213340781629, 0.002201075665652752, 0.0016546535771340132, 0.006527212914079428, 0.009592119604349136, 0.0869913324713707, 0.15476810932159424, 0.05169881880283356, 0.1406082808971405, 0.053374312818050385, 0.051208846271038055, 0.0, 0.0, 0.0], [0.6744588017463684, 0.00409829244017601, 0.0016205699648708105, 0.0002081481070490554, 0.0006771995685994625, 0.0005811149021610618, 0.0047449395060539246, 0.00048617651918902993, 0.0033293995074927807, 0.03054571896791458, 0.12975868582725525, 0.027174636721611023, 0.006183446850627661, 0.01807415299117565, 0.011506744660437107, 0.07860592752695084, 0.007945955730974674, 0.0, 0.0], [0.6362035870552063, 0.0024765559937804937, 0.0008452165056951344, 0.000305437104543671, 0.002168484730646014, 0.000392989837564528, 0.009128600358963013, 0.005640080198645592, 0.0007715883548371494, 0.01179051585495472, 0.04025563970208168, 0.008621244691312313, 0.0056505571119487286, 0.030484747141599655, 0.005988018121570349, 0.14659824967384338, 0.08437854051589966, 0.008299874141812325, 0.0], [0.4831320345401764, 0.006051389500498772, 0.0007301095756702125, 0.000285125250229612, 0.0003021409793291241, 0.0005638856091536582, 0.008710261434316635, 0.003777486737817526, 0.007854199036955833, 0.0031637679785490036, 0.14803577959537506, 0.017465921118855476, 0.004292524419724941, 0.0045972359366714954, 0.008627882227301598, 0.1291985809803009, 0.07106609642505646, 0.0827021598815918, 0.01944338157773018]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9433165788650513, 0.05668340623378754, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8033984899520874, 0.14574937522411346, 0.05085214972496033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5795931220054626, 0.2708004117012024, 0.09896372258663177, 0.05064263939857483, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6047605872154236, 0.20460651814937592, 0.0794750228524208, 0.06839852035045624, 0.04275934025645256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6211153268814087, 0.10096362233161926, 0.10636993497610092, 0.0839838758111, 0.06048647314310074, 0.02708081156015396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5438742637634277, 0.17299281060695648, 0.0787290558218956, 0.05785723403096199, 0.029703205451369286, 0.04709453880786896, 0.06974902004003525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3737963140010834, 0.12936075031757355, 0.08131084591150284, 0.08164802938699722, 0.024784864857792854, 0.05173707753419876, 0.16358034312725067, 0.0937817394733429, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3299984037876129, 0.07550618797540665, 0.058075737208127975, 0.04845009371638298, 0.03752480447292328, 0.02237076498568058, 0.16151979565620422, 0.21610921621322632, 0.05044499784708023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33597761392593384, 0.1784301996231079, 0.048397261649370193, 0.024034198373556137, 0.009916716255247593, 0.019039224833250046, 0.13193140923976898, 0.16997577250003815, 0.01901722140610218, 0.0632803663611412, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3465334177017212, 0.03081129863858223, 0.08996733278036118, 0.053254902362823486, 0.015257223509252071, 0.030284224078059196, 0.05428251996636391, 0.06608226150274277, 0.039239443838596344, 0.16707904636859894, 0.10720837861299515, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.481527179479599, 0.022496316581964493, 0.006382493302226067, 0.006791123189032078, 0.00584634393453598, 0.013061034493148327, 0.020744021981954575, 0.03506944328546524, 0.024291863664984703, 0.09350959956645966, 0.2669476866722107, 0.02333276905119419, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2848055958747864, 0.020601484924554825, 0.009590283036231995, 0.003753373632207513, 0.005839117337018251, 0.008248432539403439, 0.031123334541916847, 0.06061694771051407, 0.017454829066991806, 0.11582710593938828, 0.3683568835258484, 0.05711887776851654, 0.016663819551467896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4201015830039978, 0.00813231524080038, 0.004391378257423639, 0.00292900949716568, 0.0019736706744879484, 0.004730104003101587, 0.01644490472972393, 0.0515253059566021, 0.006744245998561382, 0.08108396083116531, 0.3323027491569519, 0.034499391913414, 0.014759017154574394, 0.02038227766752243, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3495219349861145, 0.009326739236712456, 0.010115872137248516, 0.0059685478918254375, 0.0053548067808151245, 0.0041206395253539085, 0.01532577071338892, 0.031066015362739563, 0.012600930407643318, 0.0624491311609745, 0.2974579632282257, 0.09181371331214905, 0.034398242831230164, 0.04915245994925499, 0.0213273037225008, 0.0, 0.0, 0.0, 0.0], [0.2617485523223877, 0.01050353329628706, 0.009882405400276184, 0.004783309064805508, 0.0024185648653656244, 0.0073418705724179745, 0.0039193835109472275, 0.01636199653148651, 0.018503336235880852, 0.12159138172864914, 0.3558640778064728, 0.07543481141328812, 0.027780620381236076, 0.021628497168421745, 0.03617784008383751, 0.026059910655021667, 0.0, 0.0, 0.0], [0.2330704927444458, 0.010903132148087025, 0.011165578849613667, 0.007780362386256456, 0.002909858711063862, 0.011160632595419884, 0.01205039769411087, 0.020023394376039505, 0.020990952849388123, 0.06002923846244812, 0.23054122924804688, 0.07311230897903442, 0.04077591374516487, 0.022604970261454582, 0.0557786226272583, 0.07934451848268509, 0.10775837302207947, 0.0, 0.0], [0.2142704427242279, 0.008714179508388042, 0.008973231539130211, 0.005043505225330591, 0.003911903593689203, 0.005923487711697817, 0.014341475442051888, 0.05133362486958504, 0.01710246130824089, 0.03741512447595596, 0.18928082287311554, 0.062368959188461304, 0.02460629679262638, 0.0272282212972641, 0.02707217074930668, 0.07871504127979279, 0.18513241410255432, 0.03856661170721054, 0.0], [0.40564441680908203, 0.01619563437998295, 0.011905485764145851, 0.0024714244063943624, 0.001454539131373167, 0.009384267963469028, 0.007252938114106655, 0.03837592899799347, 0.011070498265326023, 0.015041313134133816, 0.19410422444343567, 0.06688360124826431, 0.012196164578199387, 0.0071441736072301865, 0.02181180566549301, 0.02617580257356167, 0.11714424192905426, 0.01634657010436058, 0.01939692161977291]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9652450680732727, 0.03475493565201759, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8894073367118835, 0.08532913029193878, 0.025263585150241852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8334532976150513, 0.10624168068170547, 0.027473416179418564, 0.03283163160085678, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5016822218894958, 0.03058091551065445, 0.10967829078435898, 0.28805607557296753, 0.07000258564949036, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5993452668190002, 0.02877415530383587, 0.06698204576969147, 0.08579523861408234, 0.1793401539325714, 0.03976311907172203, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6820553541183472, 0.022089622914791107, 0.050811879336833954, 0.11248879879713058, 0.036175068467855453, 0.034365978091955185, 0.062013205140829086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5497751832008362, 0.03378567472100258, 0.01281808689236641, 0.07959152013063431, 0.015507139265537262, 0.10760919004678726, 0.15416792035102844, 0.046745240688323975, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.48340046405792236, 0.007016110233962536, 0.003678349545225501, 0.004782408941537142, 0.007793722674250603, 0.0022509759292006493, 0.19874903559684753, 0.25713667273521423, 0.03519221022725105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.35993051528930664, 0.009212322533130646, 0.013468693941831589, 0.031006384640932083, 0.009596817195415497, 0.012393128126859665, 0.12563616037368774, 0.22567977011203766, 0.06795036047697067, 0.14512573182582855, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.659996747970581, 0.0029760540928691626, 0.01731717586517334, 0.05167970806360245, 0.01699756272137165, 0.007850686088204384, 0.02986053004860878, 0.061651427298784256, 0.025494204834103584, 0.056641701608896255, 0.06953422725200653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8035327792167664, 0.0042632995173335075, 0.0014526935992762446, 0.0021845377050340176, 0.0036285421811044216, 0.0014726257650181651, 0.01184778567403555, 0.015969624742865562, 0.011699184775352478, 0.056154076009988785, 0.05024266988039017, 0.037552252411842346, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5851073265075684, 0.003987399395555258, 0.0013648823369294405, 0.001718313549645245, 0.00649000471457839, 0.0005997884436510503, 0.017681386321783066, 0.015388533473014832, 0.002493980573490262, 0.1002647802233696, 0.1574232280254364, 0.06639169901609421, 0.04108873009681702, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.45376360416412354, 0.0010203849524259567, 0.0030251885764300823, 0.008673571981489658, 0.0012285687262192369, 0.002726870123296976, 0.013007250614464283, 0.017355648800730705, 0.007895564660429955, 0.05478917434811592, 0.035608578473329544, 0.13946080207824707, 0.19080916047096252, 0.0706356018781662, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3490546643733978, 0.0013902076752856374, 0.002490743063390255, 0.004562708083540201, 0.005379315000027418, 0.0012863512383773923, 0.029622379690408707, 0.03435736149549484, 0.005211462266743183, 0.039719242602586746, 0.05359123274683952, 0.09440673142671585, 0.090045265853405, 0.23382419347763062, 0.05505819618701935, 0.0, 0.0, 0.0, 0.0], [0.5846137404441833, 0.0005869762389920652, 0.0014100729022175074, 0.004268641117960215, 0.0008134111994877458, 0.0012631594436243176, 0.0021307331044226885, 0.010984458960592747, 0.00368660781532526, 0.016260042786598206, 0.027032412588596344, 0.06684915721416473, 0.08704959601163864, 0.049224600195884705, 0.0460471473634243, 0.0977792888879776, 0.0, 0.0, 0.0], [0.6154677867889404, 0.0016106658149510622, 0.0006177935283631086, 0.0030499391723424196, 0.00026265339693054557, 0.001541965059004724, 0.0071973348967731, 0.0027570161037147045, 0.0041159652173519135, 0.015899457037448883, 0.031344395130872726, 0.019030461087822914, 0.029772885143756866, 0.006525499280542135, 0.0367429293692112, 0.15067027509212494, 0.07339297980070114, 0.0, 0.0], [0.2956549823284149, 0.0002770502178464085, 0.00012284962576813996, 0.00020719294843729585, 0.00015975099813658744, 6.408748595276847e-05, 0.010508830659091473, 0.015116071328520775, 0.0011544831795617938, 0.019592590630054474, 0.014471087604761124, 0.003722904250025749, 0.002681543119251728, 0.005080608185380697, 0.0014155226526781917, 0.23448841273784637, 0.3693603277206421, 0.02592177875339985, 0.0], [0.40444183349609375, 0.0002592832315713167, 0.0004530734149739146, 0.0008034852216951549, 0.0001598286908119917, 0.0004494485619943589, 0.004832759965211153, 0.009642022661864758, 0.0027332736644893885, 0.004269284661859274, 0.01154209766536951, 0.01036904752254486, 0.00978953018784523, 0.0053875865414738655, 0.009016409516334534, 0.11220892518758774, 0.2720615863800049, 0.05363011360168457, 0.08795037120580673]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9901108145713806, 0.009889231063425541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9953932762145996, 0.002303664106875658, 0.002303091110661626, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9896852970123291, 0.002195162931457162, 0.001926533179357648, 0.006193102803081274, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9930612444877625, 0.0007570190937258303, 0.004406497348099947, 0.00042038271203637123, 0.001354785286821425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9890241622924805, 0.007656464818865061, 0.0016539935022592545, 9.589982073521242e-05, 1.4942856068955734e-05, 0.001554527203552425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9602317810058594, 0.003450802993029356, 0.0048531340435147285, 0.0008072835626080632, 0.011094207875430584, 0.002636246383190155, 0.016926635056734085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9683724641799927, 0.0032892804592847824, 0.012446414679288864, 4.565515700960532e-05, 0.00014939728134777397, 0.0017658815486356616, 0.004210774786770344, 0.009720155969262123, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9109984636306763, 0.0034469179809093475, 0.004166354425251484, 6.188463885337114e-06, 0.00022101809736341238, 0.0007612202316522598, 0.03402383625507355, 0.04272598773241043, 0.00365018961019814, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8906504511833191, 0.007612696848809719, 0.005345049314200878, 0.0005836714990437031, 0.003051523584872484, 0.003978341352194548, 0.024138497188687325, 0.024364927783608437, 0.007723846007138491, 0.03255109861493111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6919527053833008, 0.009555072523653507, 0.11693930625915527, 0.002276497893035412, 0.0010180643294006586, 0.002020507585257292, 0.006614550948143005, 0.01474078744649887, 0.016483601182699203, 0.058115534484386444, 0.08028333634138107, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4376192092895508, 0.0031009437516331673, 0.002033069496974349, 0.2997317314147949, 0.07819371670484543, 0.029583649709820747, 0.012564782984554768, 0.11499892175197601, 0.002677159383893013, 0.004529209807515144, 0.01442965678870678, 0.0005379613139666617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24636447429656982, 0.0009970245882868767, 0.0007867904496379197, 0.0011080328840762377, 0.5021128058433533, 0.03831182420253754, 0.013030365109443665, 0.1498187929391861, 0.002461452269926667, 0.024525411427021027, 0.016449660062789917, 0.00048353520105592906, 0.003549800720065832, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7346024513244629, 0.00235349009744823, 0.010693336836993694, 0.0009438235429115593, 0.0011207530042156577, 0.15214800834655762, 0.0219100471585989, 0.028297754004597664, 0.010125995613634586, 0.004360813647508621, 0.02415408566594124, 0.007124187890440226, 0.0012552065309137106, 0.0009101457544602454, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5663295388221741, 0.007530851289629936, 0.00242844526655972, 6.73316462780349e-05, 2.2444321075454354e-05, 0.0020602629519999027, 0.29444852471351624, 0.04687986522912979, 0.006021180190145969, 0.013817824423313141, 0.0574839785695076, 0.0022644009441137314, 0.0001698410778772086, 4.947540674038464e-06, 0.00047055905451998115, 0.0, 0.0, 0.0, 0.0], [0.410645991563797, 0.004568744450807571, 0.005549734923988581, 0.0007556115742772818, 0.0057444083504378796, 0.0022520830389112234, 0.01370322611182928, 0.24816679954528809, 0.015941016376018524, 0.15764307975769043, 0.11563555896282196, 0.005100984126329422, 0.0009495419217273593, 0.002351227216422558, 0.0011996068060398102, 0.009792345575988293, 0.0, 0.0, 0.0], [0.31301164627075195, 0.007131975144147873, 0.017675980925559998, 4.0898772567743436e-05, 2.929422407760285e-05, 0.0012514875270426273, 0.004729215055704117, 0.013687990605831146, 0.5433970093727112, 0.021223703399300575, 0.05147218331694603, 0.014240805990993977, 8.991755748866126e-05, 4.189565879642032e-05, 0.0010708863846957684, 0.004731905646622181, 0.006173273082822561, 0.0, 0.0], [0.31944164633750916, 0.0023819596972316504, 0.002667807973921299, 1.240626374965359e-06, 3.191888390574604e-05, 0.00022800796432420611, 0.012245137244462967, 0.024448420852422714, 0.004585993010550737, 0.54709392786026, 0.07265418767929077, 0.004620445426553488, 7.206458576547448e-06, 1.3928791304351762e-05, 0.00010076846956508234, 0.002113910624757409, 0.004075697623193264, 0.0032878564670681953, 0.0], [0.18081560730934143, 0.014453831128776073, 0.008491800166666508, 0.0003580382908694446, 0.001228432054631412, 0.004440597258508205, 0.030252406373620033, 0.014811230823397636, 0.016691209748387337, 0.025395438075065613, 0.6423535943031311, 0.018699465319514275, 0.0008410912123508751, 0.0010559315560385585, 0.002523876493796706, 0.014452424831688404, 0.004680268466472626, 0.010330647230148315, 0.008124183863401413]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9599452018737793, 0.040054801851511, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8806532621383667, 0.11355246603488922, 0.005794222000986338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9276391863822937, 0.0049173529259860516, 0.053782232105731964, 0.013661268167197704, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9675076007843018, 0.0004817028238903731, 0.0071913935244083405, 0.02267812192440033, 0.0021410523913800716, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.914806604385376, 0.00105986965354532, 0.006531757302582264, 0.0056938109919428825, 0.04871077463030815, 0.023197198286652565, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9403766393661499, 0.00035490607842803, 0.0008058523526415229, 0.0008377672638744116, 0.0009511697571724653, 0.03736042603850365, 0.01931321993470192, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6920268535614014, 0.0006658314960077405, 0.010693520307540894, 0.009491750039160252, 0.00910342950373888, 0.033821940422058105, 0.23217010498046875, 0.012026564218103886, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.880340576171875, 0.0006191532593220472, 0.0005560406134463847, 0.00013662340643350035, 0.0004917357000522316, 0.0031965309754014015, 0.005824052728712559, 0.028065204620361328, 0.08077014237642288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8151074051856995, 5.066447556600906e-05, 5.5576267186552286e-05, 6.644678069278598e-05, 8.699631871422753e-05, 0.0032056928612291813, 0.010401081293821335, 0.005634078290313482, 0.14481821656227112, 0.02057376503944397, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.514685332775116, 0.005033354740589857, 0.0014379526255652308, 0.000592283031437546, 0.0023909981828182936, 0.015830373391509056, 0.01326268445700407, 0.002402654616162181, 0.07478680461645126, 0.3551429212093353, 0.014434578828513622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7329118251800537, 0.012791195884346962, 0.0002776186156552285, 3.916052446584217e-05, 0.001452973228879273, 0.0004866441886406392, 0.0024443059228360653, 0.00370883964933455, 0.00470771174877882, 0.029941407963633537, 0.2052488774061203, 0.005989346653223038, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.780945360660553, 0.0012646217364817858, 0.021304460242390633, 0.011160504072904587, 0.0017077864613384008, 0.0008655742276459932, 0.0010019262554123998, 0.0003230179427191615, 0.001360054244287312, 0.0019598763901740313, 0.004838389344513416, 0.1434219479560852, 0.02984653227031231, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.838173508644104, 5.41668341611512e-05, 0.0007334579713642597, 0.003600343829020858, 0.0002671440888661891, 0.001128621632233262, 0.0023355172015726566, 0.0007297353004105389, 0.0004707074840553105, 0.0020102199632674456, 0.0010500855278223753, 0.021813958883285522, 0.12251871079206467, 0.0051140026189386845, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8550260066986084, 0.00012974379933439195, 0.001008115941658616, 0.0009714715997688472, 0.006144192535430193, 0.001410443102940917, 0.0027519778814166784, 0.0008504681172780693, 0.0021539817098528147, 0.003317219903692603, 0.0017067338339984417, 0.01245641428977251, 0.007140426430851221, 0.08740836381912231, 0.017524344846606255, 0.0, 0.0, 0.0, 0.0], [0.8840286731719971, 1.3716861758439336e-05, 6.75962000968866e-05, 9.728952136356384e-05, 7.933696906547993e-05, 0.005409612320363522, 0.0018719946965575218, 0.0001686048781266436, 0.008993147872388363, 0.0028326413594186306, 0.0005602919845841825, 0.001453828881494701, 0.0012436039978638291, 0.0013239390682429075, 0.0695217102766037, 0.02233402617275715, 0.0, 0.0, 0.0], [0.7456375956535339, 3.2575204386375844e-05, 0.00042286815005354583, 0.0002739531046245247, 0.0004651993222068995, 0.0013519971398636699, 0.020693330094218254, 0.0004493391897995025, 0.01705925352871418, 0.007836065255105495, 0.001482417806982994, 0.006828417535871267, 0.0027791913598775864, 0.006015983410179615, 0.014838761650025845, 0.16711664199829102, 0.006716387812048197, 0.0, 0.0], [0.7839845418930054, 3.406744872336276e-05, 5.3534160542767495e-05, 1.7747854144545272e-05, 4.332295065978542e-05, 0.00023004553804639727, 0.0005228185327723622, 0.005179963074624538, 0.019147081300616264, 0.0011901797261089087, 0.0009938360890373588, 0.0017414875328540802, 9.339961980003864e-05, 0.0010642698034644127, 0.002761814510449767, 0.006432308815419674, 0.07532425969839096, 0.10118535906076431, 0.0], [0.7707509398460388, 8.010521241885726e-07, 8.128322974698676e-07, 1.3271078387333546e-06, 4.944893134961603e-06, 0.0002277228340972215, 0.00045065523590892553, 0.00011148692283313721, 0.018491927534341812, 0.0013526615221053362, 0.00012621466885320842, 4.9900518206413835e-05, 1.9602526663220488e-05, 9.432338265469298e-05, 0.0029662868473678827, 0.005036917515099049, 0.0017305127112194896, 0.1780892014503479, 0.020493708550930023]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9629899263381958, 0.037010084837675095, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9843436479568481, 0.0070749628357589245, 0.008581372909247875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.92918860912323, 0.020536547526717186, 0.029480984434485435, 0.020793771371245384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4116274118423462, 0.015094663947820663, 0.4051736891269684, 0.14549316465854645, 0.022611116990447044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7019044160842896, 0.016165338456630707, 0.15929728746414185, 0.08416339010000229, 0.03081669844686985, 0.007652988191694021, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6904014348983765, 0.023050852119922638, 0.0788286104798317, 0.15188413858413696, 0.028827404603362083, 0.008018452674150467, 0.018989013507962227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6236814856529236, 0.006017595063894987, 0.23920154571533203, 0.058288875967264175, 0.009791168384253979, 0.010590573772788048, 0.03883567824959755, 0.013592944480478764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7851909399032593, 0.007244984619319439, 0.06827434152364731, 0.08860713243484497, 0.011340982280671597, 0.0025754417292773724, 0.015312345698475838, 0.014030666090548038, 0.007423060480505228, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8587300777435303, 0.05640453100204468, 0.006034396588802338, 0.00805064756423235, 0.003165140515193343, 0.0017725881189107895, 0.023563290014863014, 0.016913186758756638, 0.005293000489473343, 0.020073024556040764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.922278106212616, 0.010296883061528206, 0.0061875018291175365, 0.004293669015169144, 0.006264546886086464, 0.0008807570557110012, 0.0049980441108345985, 0.006509552244096994, 0.0022553487215191126, 0.00891681108623743, 0.027118712663650513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9833481907844543, 0.0035238866694271564, 0.0005843283142894506, 0.00047763518523424864, 0.0002047463203780353, 0.00013777830463368446, 0.0002565376926213503, 0.0011992279905825853, 0.0001703772140899673, 0.0011057492811232805, 0.006241480819880962, 0.002750120125710964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9514502882957458, 0.006141876336187124, 0.0033685900270938873, 0.002072131261229515, 0.001331028062850237, 9.239297651220113e-05, 0.0005454241181723773, 0.002443506382405758, 0.00017909513553604484, 0.0012426972389221191, 0.012926062569022179, 0.013735768385231495, 0.004471051041036844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.711645245552063, 0.003915872424840927, 0.020824817940592766, 0.009176120162010193, 0.0016505670500919223, 0.0006503270124085248, 0.006803338415920734, 0.0013377066934481263, 0.0025336998514831066, 0.007972845807671547, 0.03948918730020523, 0.11963961273431778, 0.05837800353765488, 0.015982724726200104, 0.0, 0.0, 0.0, 0.0, 0.0], [0.696149468421936, 0.0042190589010715485, 0.020114218816161156, 0.011170894838869572, 0.0025241514667868614, 0.000477736524771899, 0.011206249706447124, 0.0007526828558184206, 0.0018885477911680937, 0.006096095312386751, 0.031701602041721344, 0.12104866653680801, 0.05895448848605156, 0.02874416671693325, 0.004952013026922941, 0.0, 0.0, 0.0, 0.0], [0.7452486753463745, 0.0043213097378611565, 0.007391110062599182, 0.00949607603251934, 0.0010449036490172148, 0.00044588654418475926, 0.0018511753296479583, 0.0005237988661974669, 0.0005446438444778323, 0.013954841531813145, 0.03339403122663498, 0.05778279900550842, 0.07665527611970901, 0.02072201669216156, 0.004906263668090105, 0.021717125549912453, 0.0, 0.0, 0.0], [0.8488973379135132, 0.001321334857493639, 0.007722865324467421, 0.002594366203993559, 0.00046734788338653743, 0.0005376387271098793, 0.0044656977988779545, 0.0012541431933641434, 0.00036491939681582153, 0.015851423144340515, 0.009082857519388199, 0.0356481708586216, 0.017690202221274376, 0.0059356470592319965, 0.004193722736090422, 0.02820303663611412, 0.01576932705938816, 0.0, 0.0], [0.7331209182739258, 0.0013595987111330032, 0.008060854859650135, 0.007838734425604343, 0.0006745071732439101, 0.0002885139547288418, 0.0023261334281414747, 0.002317233709618449, 0.001027263468131423, 0.005206652916967869, 0.006991873495280743, 0.08149494230747223, 0.06491375714540482, 0.013034246861934662, 0.003412510035559535, 0.02104887180030346, 0.03969428688287735, 0.007189211435616016, 0.0], [0.9359124898910522, 0.006190653890371323, 0.00010126644338015467, 0.0001385306240990758, 8.805685502011329e-05, 9.517775470158085e-05, 0.001180701656267047, 0.0005145663162693381, 0.0003498658479657024, 0.0012690185103565454, 0.011646074242889881, 0.0008700216421857476, 0.0007012970163486898, 0.00149452721234411, 0.0011118962429463863, 0.012794534675776958, 0.008409904316067696, 0.003433672711253166, 0.013697593472898006]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9638538360595703, 0.03614610433578491, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9717195630073547, 0.012856291607022285, 0.015424194745719433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9724985361099243, 0.013638002797961235, 0.010449537076056004, 0.003413880243897438, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9621158242225647, 0.02335098199546337, 0.007629977539181709, 0.0005673043779097497, 0.006336030084639788, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9385297298431396, 0.01686973124742508, 0.0061734397895634174, 0.0013856408186256886, 0.0036165707278996706, 0.03342490270733833, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9511937499046326, 0.004906782414764166, 0.0050001065246760845, 0.0007502835360355675, 0.0025331273209303617, 0.009778685867786407, 0.025837158784270287, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9095008969306946, 0.00911762285977602, 0.006509468890726566, 0.00025534353335388005, 0.001756019308231771, 0.010384438559412956, 0.027975918725132942, 0.03450022265315056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5139949321746826, 0.0025141211226582527, 0.007835554890334606, 0.0007674121297895908, 0.017013398930430412, 0.008486554957926273, 0.3205266296863556, 0.09292113035917282, 0.035940319299697876, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7617191672325134, 0.02000489830970764, 0.023635849356651306, 0.0024558419827371836, 0.004187264479696751, 0.005327765364199877, 0.055556897073984146, 0.053203046321868896, 0.052081700414419174, 0.021827619522809982, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.42916181683540344, 0.004309101030230522, 0.22723525762557983, 0.01493686530739069, 0.005832735449075699, 0.006203061435371637, 0.013165418058633804, 0.021025951951742172, 0.031385406851768494, 0.0393357090651989, 0.20740854740142822, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5201102495193481, 0.00278815277852118, 0.0017322794301435351, 0.03905083239078522, 0.06612850725650787, 0.021115077659487724, 0.06383518129587173, 0.10787586867809296, 0.009429613128304482, 0.05641110986471176, 0.10581620037555695, 0.005706905387341976, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4155313968658447, 0.0007439317414537072, 0.0007363120093941689, 0.0002818147768266499, 0.04955717921257019, 0.008489686995744705, 0.07182493805885315, 0.12784184515476227, 0.010400581173598766, 0.17173649370670319, 0.12933379411697388, 0.004066551569849253, 0.009455516003072262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5649060606956482, 0.0013533844612538815, 0.000631095259450376, 6.76302588544786e-05, 0.00011687599908327684, 0.0629936084151268, 0.048220012336969376, 0.010249192826449871, 0.01686394214630127, 0.017309412360191345, 0.2716660499572754, 0.003135895589366555, 0.0009365036385133862, 0.0015503206523135304, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5736814141273499, 0.0016106439288705587, 0.0009103285265155137, 0.00019332888768985868, 0.0002243173075839877, 0.0031058560125529766, 0.17782798409461975, 0.018777763471007347, 0.014025188982486725, 0.024815069511532784, 0.15307806432247162, 0.006830805446952581, 0.005155303981155157, 0.0026813633739948273, 0.01708264835178852, 0.0, 0.0, 0.0, 0.0], [0.6349947452545166, 0.0004630325420293957, 0.0004341975727584213, 0.00011646360508166254, 9.920429874910042e-05, 0.0008233302505686879, 0.001401303568854928, 0.07711897790431976, 0.055921148508787155, 0.0362531803548336, 0.16852621734142303, 0.0034765268210321665, 0.0010836833389475942, 0.0014400084037333727, 0.008147858083248138, 0.00970009621232748, 0.0, 0.0, 0.0], [0.5026711225509644, 0.0009485905757173896, 0.0006145990919321775, 3.845345418085344e-05, 4.3910953536396846e-05, 0.0007550640148110688, 0.0011127794859930873, 0.0025254422798752785, 0.30256348848342896, 0.04245718941092491, 0.10517584532499313, 0.005852683447301388, 0.0008243097108788788, 0.0013307800982147455, 0.008022238500416279, 0.011463331989943981, 0.013600122183561325, 0.0, 0.0], [0.41516828536987305, 0.0002633957483340055, 0.0009910507360473275, 8.739021723158658e-05, 0.0006560845649801195, 0.0006599703337997198, 0.02179298922419548, 0.01123255118727684, 0.007772647310048342, 0.2816935181617737, 0.06952201575040817, 0.011097781360149384, 0.0024916166439652443, 0.007513325195759535, 0.003952849190682173, 0.09461665898561478, 0.033149104565382004, 0.0373387411236763, 0.0], [0.1403682976961136, 0.0006542089977301657, 0.0009164301445707679, 0.0001041217619786039, 2.9515120331780054e-05, 0.0001941493828780949, 0.0010951238218694925, 0.0009722798713482916, 0.0029726054053753614, 0.0002589768555480987, 0.7674661874771118, 0.03401157259941101, 0.0026750476099550724, 0.0009897105628624558, 0.0020965824369341135, 0.011490165255963802, 0.011544116772711277, 0.019247407093644142, 0.002913406351581216]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9809226393699646, 0.019077375531196594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9760815501213074, 0.022666672244668007, 0.0012517408467829227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9645016193389893, 0.022532951086759567, 0.007983289659023285, 0.004982233513146639, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9597846269607544, 0.011908559128642082, 0.01354070845991373, 0.009811612777411938, 0.0049545797519385815, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9260736107826233, 0.02513997070491314, 0.014832679182291031, 0.01802389696240425, 0.00612016674131155, 0.009809755720198154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.871453583240509, 0.013799506239593029, 0.04267078638076782, 0.02812194637954235, 0.010329943150281906, 0.01727370172739029, 0.016350388526916504, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8891112208366394, 0.01918903924524784, 0.016827547922730446, 0.02116319350898266, 0.013968300074338913, 0.02077896147966385, 0.01676524616777897, 0.0021965811029076576, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8832957744598389, 0.01642397977411747, 0.02186805009841919, 0.016907161101698875, 0.007834702730178833, 0.00938637275248766, 0.02079855278134346, 0.004381273407489061, 0.01910395361483097, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8269095420837402, 0.026315933093428612, 0.026389168575406075, 0.015346376225352287, 0.007885810919106007, 0.007471755146980286, 0.019416768103837967, 0.006577559281140566, 0.015415037050843239, 0.048272065818309784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6698270440101624, 0.05043458938598633, 0.06112737953662872, 0.030114933848381042, 0.016381772235035896, 0.00771790836006403, 0.022077662870287895, 0.016238337382674217, 0.02468966320157051, 0.08826733380556107, 0.013123215176165104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6197341680526733, 0.022650234401226044, 0.006302780471742153, 0.014917663298547268, 0.05267943814396858, 0.025484401732683182, 0.04580029845237732, 0.010582071729004383, 0.022776169702410698, 0.07684995979070663, 0.09467339515686035, 0.00754947867244482, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5730481743812561, 0.020678464323282242, 0.029296739026904106, 0.013297372497618198, 0.029190732166171074, 0.027012672275304794, 0.048869431018829346, 0.010542979463934898, 0.037440452724695206, 0.1064990907907486, 0.07033932209014893, 0.021727824583649635, 0.012056765146553516, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7081554532051086, 0.024180246517062187, 0.03581015393137932, 0.01742645353078842, 0.011042575351893902, 0.021583015099167824, 0.019259879365563393, 0.008475231938064098, 0.05007794871926308, 0.051888301968574524, 0.02521626092493534, 0.013637750409543514, 0.007608198560774326, 0.005638570059090853, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6750068068504333, 0.034873899072408676, 0.038840606808662415, 0.031687282025814056, 0.011268120259046555, 0.016322800889611244, 0.04109811782836914, 0.00814244244247675, 0.03678257763385773, 0.058113355189561844, 0.011749227531254292, 0.012812493368983269, 0.012234601192176342, 0.0037297718226909637, 0.007337936665862799, 0.0, 0.0, 0.0, 0.0], [0.5070163011550903, 0.024595292285084724, 0.07065680623054504, 0.03672463446855545, 0.02486463263630867, 0.022775711491703987, 0.03802455589175224, 0.02270280197262764, 0.03358190506696701, 0.09510809928178787, 0.02510903775691986, 0.032798219472169876, 0.018401822075247765, 0.012220385484397411, 0.013596165925264359, 0.021823640912771225, 0.0, 0.0, 0.0], [0.4363391101360321, 0.06463500112295151, 0.03408714011311531, 0.028152402490377426, 0.031154204159975052, 0.02525794506072998, 0.03403286263346672, 0.009645775891840458, 0.047535914927721024, 0.06422793865203857, 0.09000861644744873, 0.023127099499106407, 0.025186769664287567, 0.02646254003047943, 0.019752444699406624, 0.03188684955239296, 0.008507298305630684, 0.0, 0.0], [0.6327357888221741, 0.024308212101459503, 0.031794410198926926, 0.01956048421561718, 0.012891434133052826, 0.01194516196846962, 0.030167363584041595, 0.00690352963283658, 0.032229386270046234, 0.08625001460313797, 0.0157383494079113, 0.014515822753310204, 0.01510354969650507, 0.009931951761245728, 0.00949495192617178, 0.026155581697821617, 0.0036953394301235676, 0.01657862588763237, 0.0], [0.291032999753952, 0.06536628305912018, 0.022310253232717514, 0.009091145358979702, 0.009775092825293541, 0.01249179057776928, 0.05205263942480087, 0.011300688609480858, 0.022450489923357964, 0.06464731693267822, 0.30099761486053467, 0.014476023614406586, 0.007902943529188633, 0.008510319516062737, 0.01020987331867218, 0.04149164259433746, 0.007604449521750212, 0.014537311159074306, 0.03375106677412987]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9919179081916809, 0.008082081563770771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8911195993423462, 0.05641566589474678, 0.05246473848819733, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8210300803184509, 0.03417230024933815, 0.045874547213315964, 0.09892317652702332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5980534553527832, 0.009532740339636803, 0.031288061290979385, 0.27281978726387024, 0.08830594271421432, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.893884003162384, 0.005386475473642349, 0.01936897076666355, 0.02609480731189251, 0.019546708092093468, 0.035719145089387894, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3998592495918274, 0.00838323961943388, 0.07139120995998383, 0.17191484570503235, 0.10109573602676392, 0.16213494539260864, 0.08522073924541473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3936539888381958, 0.027638129889965057, 0.10186611115932465, 0.20101647078990936, 0.12038247287273407, 0.01749558560550213, 0.10360036045312881, 0.03434697538614273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3913845419883728, 0.007464520167559385, 0.13103321194648743, 0.305751770734787, 0.11930792778730392, 0.001413157326169312, 0.020503107458353043, 0.005055689252912998, 0.01808611862361431, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3743571937084198, 0.022861691191792488, 0.08966552466154099, 0.10581127554178238, 0.05928393080830574, 0.016266971826553345, 0.049916062504053116, 0.06833918392658234, 0.06478838622570038, 0.14870989322662354, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5213038325309753, 0.03555355593562126, 0.02727442979812622, 0.024252718314528465, 0.027200328186154366, 0.01957009732723236, 0.051537588238716125, 0.022781670093536377, 0.06937727332115173, 0.16373777389526367, 0.0374106802046299, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11869999021291733, 0.013887118548154831, 0.0033646721858531237, 0.01153911929577589, 0.004757744260132313, 0.007477402221411467, 0.016743283718824387, 0.021177897229790688, 0.6223727464675903, 0.16459697484970093, 0.012838134542107582, 0.002544850343838334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19584587216377258, 0.01656411401927471, 0.01077798381447792, 0.02325202338397503, 0.019500290974974632, 0.009338733740150928, 0.0559699572622776, 0.021985026076436043, 0.4476941227912903, 0.1358952522277832, 0.022305401042103767, 0.007179515901952982, 0.033691588789224625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.32370659708976746, 0.012479770928621292, 0.010195267386734486, 0.09967157244682312, 0.03373343124985695, 0.024314893409609795, 0.06818022578954697, 0.0365922786295414, 0.1445852518081665, 0.1273297667503357, 0.009221205487847328, 0.009506061673164368, 0.0766867846250534, 0.02379695139825344, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6494259834289551, 0.005928318947553635, 0.02416553907096386, 0.05123933032155037, 0.03137624263763428, 0.04223912954330444, 0.01833266392350197, 0.007525222841650248, 0.04088708013296127, 0.021826015785336494, 0.0079689621925354, 0.012001408264040947, 0.03070065937936306, 0.024014053866267204, 0.03236927464604378, 0.0, 0.0, 0.0, 0.0], [0.2259071171283722, 0.012115434743463993, 0.02252376452088356, 0.0501861535012722, 0.039648961275815964, 0.07372653484344482, 0.04715126380324364, 0.016745297238230705, 0.1412467211484909, 0.10264166444540024, 0.015711728483438492, 0.014011074788868427, 0.04235759377479553, 0.03539006784558296, 0.10972554236650467, 0.05091108754277229, 0.0, 0.0, 0.0], [0.24462445080280304, 0.03313664346933365, 0.026818599551916122, 0.041358832269907, 0.030948953703045845, 0.007878598757088184, 0.05911041796207428, 0.047960929572582245, 0.040434908121824265, 0.301813006401062, 0.026634573936462402, 0.009465212002396584, 0.033534519374370575, 0.024890078231692314, 0.010137471370398998, 0.04173055663704872, 0.019522225484251976, 0.0, 0.0], [0.24573075771331787, 0.005411139223724604, 0.0624970868229866, 0.172561377286911, 0.07088445872068405, 0.0008612939273007214, 0.012646020390093327, 0.006340526044368744, 0.012926548719406128, 0.030730746686458588, 0.018237058073282242, 0.07275505363941193, 0.1964663416147232, 0.06349613517522812, 0.0014991330681368709, 0.009807824157178402, 0.005215215031057596, 0.011933179572224617, 0.0], [0.34731540083885193, 0.035277109593153, 0.01890622079372406, 0.02029765583574772, 0.022044183686375618, 0.008305820636451244, 0.028874782845377922, 0.07981237769126892, 0.02577914483845234, 0.11156865209341049, 0.04165702313184738, 0.012253392487764359, 0.01924833282828331, 0.02318737283349037, 0.010740252211689949, 0.0313708521425724, 0.06295930594205856, 0.02019842155277729, 0.08020369708538055]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8252440094947815, 0.17475596070289612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9248567819595337, 0.034504834562540054, 0.04063833877444267, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7735209465026855, 0.037222474813461304, 0.07027890533208847, 0.11897769570350647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8041488528251648, 0.011387718841433525, 0.033163122832775116, 0.04073090851306915, 0.11056945472955704, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6505077481269836, 0.02842838503420353, 0.12348881363868713, 0.05359220504760742, 0.05158400535583496, 0.09239891171455383, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4776607155799866, 0.03416988253593445, 0.06445828080177307, 0.06361757218837738, 0.03912024199962616, 0.05456080287694931, 0.2664124667644501, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7224504947662354, 0.011232377961277962, 0.0639842301607132, 0.03155215084552765, 0.030340872704982758, 0.019294671714305878, 0.08555559813976288, 0.0355895534157753, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5496776103973389, 0.00821186788380146, 0.10657201707363129, 0.08092604577541351, 0.02892262116074562, 0.08253080397844315, 0.06002490222454071, 0.029987452551722527, 0.05314673110842705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5874462723731995, 0.02027798257768154, 0.06475193798542023, 0.051383160054683685, 0.04640546813607216, 0.020114930346608162, 0.03698769211769104, 0.005543686915189028, 0.04331817477941513, 0.12377062439918518, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6266947388648987, 0.07793228328227997, 0.02064744383096695, 0.01541423611342907, 0.0069040171802043915, 0.0217819195240736, 0.015969455242156982, 0.002349231159314513, 0.027956124395132065, 0.034464091062545776, 0.14988639950752258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6346642971038818, 0.01204564981162548, 0.025728734210133553, 0.0364779531955719, 0.017039543017745018, 0.030334873124957085, 0.016702424734830856, 0.006022853311151266, 0.09775659441947937, 0.028417635709047318, 0.07216992974281311, 0.022639604285359383, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6117154955863953, 0.01494078990072012, 0.03222150728106499, 0.04919476434588432, 0.015777401626110077, 0.026821069419384003, 0.025172611698508263, 0.0070470222271978855, 0.07818368077278137, 0.03425423055887222, 0.0394032783806324, 0.022730398923158646, 0.04253772646188736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6400364637374878, 0.007423218339681625, 0.014897863380610943, 0.022415973246097565, 0.08167773485183716, 0.012242313474416733, 0.020084835588932037, 0.004855838604271412, 0.024057166650891304, 0.02547350525856018, 0.010370840318500996, 0.010958298109471798, 0.024778442457318306, 0.10072753578424454, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3681116998195648, 0.011867391876876354, 0.09023109823465347, 0.05927159637212753, 0.03252771869301796, 0.06938876956701279, 0.07811710983514786, 0.019156675785779953, 0.017646871507167816, 0.04193539172410965, 0.01644616387784481, 0.0544537678360939, 0.05577540025115013, 0.028617581352591515, 0.05645276978611946, 0.0, 0.0, 0.0, 0.0], [0.3291270136833191, 0.011525805108249187, 0.030908478423953056, 0.026841020211577415, 0.022644979879260063, 0.018849771469831467, 0.15463030338287354, 0.009989217855036259, 0.0219412874430418, 0.0387895442545414, 0.02217874303460121, 0.028406864032149315, 0.0421421080827713, 0.018454939126968384, 0.0284656323492527, 0.19510430097579956, 0.0, 0.0, 0.0], [0.5180489420890808, 0.007028566207736731, 0.022150317206978798, 0.013711873441934586, 0.01209881342947483, 0.008390887640416622, 0.04792362079024315, 0.021069517359137535, 0.03526786342263222, 0.02119300700724125, 0.016965823248028755, 0.02868584170937538, 0.04111950099468231, 0.02422511577606201, 0.016814187169075012, 0.1215202584862709, 0.04378584399819374, 0.0, 0.0], [0.3526320457458496, 0.003403294365853071, 0.0498339980840683, 0.06411883234977722, 0.015722347423434258, 0.04774123430252075, 0.0598042868077755, 0.01478973776102066, 0.04611954465508461, 0.019845101982355118, 0.013178881257772446, 0.04329213872551918, 0.06947033852338791, 0.018838772550225258, 0.053325146436691284, 0.07045063376426697, 0.017206141725182533, 0.04022745043039322, 0.0], [0.412745863199234, 0.011185511946678162, 0.011098559945821762, 0.01317414827644825, 0.018845561891794205, 0.007186736911535263, 0.022695135325193405, 0.0021335503552109003, 0.019759485498070717, 0.09787198156118393, 0.017145290970802307, 0.04390469938516617, 0.07900960743427277, 0.03411104530096054, 0.018047073855996132, 0.053140997886657715, 0.00540576409548521, 0.031490884721279144, 0.10104822367429733]]]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x1b619b1baa0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention pattern for layer 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-a40b6b07-274b\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-a40b6b07-274b\",\n",
       "      AttentionPatterns,\n",
       "      {\"tokens\": [\"<|endoftext|>\", \"The\", \" capital\", \" city\", \" of\", \" France\", \" is\", \" called\", \" Paris\", \".\", \"The\", \" capital\", \" city\", \" of\", \" France\", \" is\", \" called\", \" Paris\", \".\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9771727919578552, 0.022827209904789925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6909472942352295, 0.27470648288726807, 0.03434629738330841, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7707874178886414, 0.10979752242565155, 0.052322592586278915, 0.06709249317646027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8386030197143555, 0.020750487223267555, 0.019039597362279892, 0.09059344232082367, 0.031013336032629013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6937552094459534, 0.012056899257004261, 0.015516243875026703, 0.03850565478205681, 0.2185635268688202, 0.021602481603622437, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9394855499267578, 0.0023769878316670656, 0.001769069000147283, 0.012977498583495617, 0.008732199668884277, 0.014263048768043518, 0.020395735278725624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8337375521659851, 0.001049809972755611, 0.000648406392429024, 0.0022220280952751637, 0.0014989180490374565, 0.004210243467241526, 0.11490054428577423, 0.04173244163393974, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3656042218208313, 0.0013316896511241794, 0.0010473511647433043, 0.0014393437886610627, 0.004944127053022385, 0.0022834751289337873, 0.1418229192495346, 0.4648384153842926, 0.016688497737050056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9464644193649292, 0.0005796834593638778, 0.0006406648317351937, 0.002033231547102332, 0.0006164404912851751, 0.004167558159679174, 0.006013695616275072, 0.017663339152932167, 0.020790845155715942, 0.0010301312431693077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7659293413162231, 0.0019651311449706554, 0.007683263160288334, 0.02879136987030506, 0.01182970218360424, 0.019624313339591026, 0.014006107114255428, 0.0489068329334259, 0.029805952683091164, 0.04916210100054741, 0.02229589968919754, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.40282705426216125, 0.02088271640241146, 0.0009402016294188797, 0.002519254107028246, 0.0012927119387313724, 0.0020820023491978645, 0.0071437060832977295, 0.003788533853366971, 0.004009776748716831, 0.0584220327436924, 0.4852941334247589, 0.010797801427543163, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1354888379573822, 0.00917633343487978, 0.0064615835435688496, 0.005533923860639334, 0.0007114405161701143, 0.0016688801115378737, 0.005570766981691122, 0.0029230224899947643, 0.004299080930650234, 0.12307184934616089, 0.4964233338832855, 0.1626749038696289, 0.045996084809303284, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4785163998603821, 0.0028611146844923496, 0.004389480222016573, 0.013616896234452724, 0.0014995909295976162, 0.0027398536913096905, 0.007736965082585812, 0.008934966288506985, 0.005139041226357222, 0.09620390832424164, 0.14439085125923157, 0.09231583774089813, 0.13210748136043549, 0.009547554887831211, 0.0, 0.0, 0.0, 0.0, 0.0], [0.509502112865448, 0.0026580803096294403, 0.0026620998978614807, 0.004260475281625986, 0.009726698510348797, 0.001852813409641385, 0.021116163581609726, 0.011440010741353035, 0.0032989406026899815, 0.05658932030200958, 0.08326657116413116, 0.10381107777357101, 0.06968057155609131, 0.09937164187431335, 0.020763453096151352, 0.0, 0.0, 0.0, 0.0], [0.7384198904037476, 0.0010858882451429963, 0.0005859187804162502, 0.0034154378809034824, 0.0013219645479694009, 0.006914880592375994, 0.002834131708368659, 0.004713545087724924, 0.0069479551166296005, 0.010704707354307175, 0.007536955177783966, 0.012627610936760902, 0.024009978398680687, 0.013055437244474888, 0.12286229431629181, 0.04296349734067917, 0.0, 0.0, 0.0], [0.42999354004859924, 0.0009037796407938004, 0.00028561949147842824, 0.001273870118893683, 0.0002816838677972555, 0.0025738307740539312, 0.047304850071668625, 0.020962171256542206, 0.008973544463515282, 0.059377994388341904, 0.02893294207751751, 0.005714144557714462, 0.006475974805653095, 0.0012401670683175325, 0.013413282111287117, 0.3448619544506073, 0.027430595830082893, 0.0, 0.0], [0.7819775342941284, 0.00023553037317469716, 0.00014296447625383735, 0.00014021560491528362, 0.00015730608720332384, 0.0002714803267735988, 0.010126481764018536, 0.04396654665470123, 0.0022473556455224752, 0.003954344429075718, 0.004438740201294422, 0.0030315022449940443, 0.0006339822430163622, 0.0011192067759111524, 0.0010176431387662888, 0.0496869832277298, 0.08760349452495575, 0.009248818270862103, 0.0], [0.8270671367645264, 0.00046242281678132713, 0.0001422093773726374, 0.0005997928092256188, 0.00022538774646818638, 0.0022073520813137293, 0.004385801963508129, 0.023966925218701363, 0.0100405840203166, 0.0009625227539800107, 0.0016194554045796394, 0.0024552217219024897, 0.001894662738777697, 0.0006103815394453704, 0.00981051940470934, 0.022922033444046974, 0.02975931204855442, 0.057907357811927795, 0.0029607382602989674]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9968811273574829, 0.0031189261935651302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9736651182174683, 0.0023782162461429834, 0.023956619203090668, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9529179334640503, 0.005129736848175526, 0.007954598404467106, 0.03399781882762909, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.990770161151886, 0.002215634100139141, 0.002321680309250951, 0.0036133104003965855, 0.0010793053079396486, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9544283151626587, 0.0029375224839895964, 0.0022655492648482323, 0.0069746533408761024, 0.0030946736223995686, 0.030299309641122818, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9493190050125122, 0.005833552684634924, 0.0034766874741762877, 0.011019956320524216, 0.007773071527481079, 0.01586832106113434, 0.006709333974868059, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9245178699493408, 0.01212532352656126, 0.013956434093415737, 0.01619759202003479, 0.006974471732974052, 0.021011853590607643, 0.0035809518303722143, 0.0016354690305888653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9395216107368469, 0.007844331674277782, 0.006680780556052923, 0.00934579223394394, 0.006101136561483145, 0.011552125215530396, 0.006818064954131842, 0.0010062287328764796, 0.011129841208457947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8921775221824646, 0.005792142823338509, 0.00672073382884264, 0.017673559486865997, 0.009163277223706245, 0.016244420781731606, 0.002060157246887684, 0.0078201312571764, 0.02273165062069893, 0.019616395235061646, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6189867854118347, 0.023445619270205498, 0.01668158359825611, 0.0381944477558136, 0.051194287836551666, 0.06850879639387131, 0.03180493414402008, 0.03472244367003441, 0.0413651280105114, 0.050584468990564346, 0.024511490017175674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2871529459953308, 0.00426028436049819, 0.006201163399964571, 0.02010965161025524, 0.03656740486621857, 0.056262630969285965, 0.16121740639209747, 0.015577856451272964, 0.018485723063349724, 0.1624133437871933, 0.22611770033836365, 0.005634020548313856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18753325939178467, 0.00190437282435596, 0.0033482457511126995, 0.00902468990534544, 0.013255959376692772, 0.07537727057933807, 0.17532089352607727, 0.022787882015109062, 0.04375099018216133, 0.19929654896259308, 0.25633031129837036, 0.00628447812050581, 0.005785040091723204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3253845274448395, 0.004861143883317709, 0.0030227687675505877, 0.006711046677082777, 0.003462682943791151, 0.19402913749217987, 0.1223742887377739, 0.005812470335513353, 0.0169238168746233, 0.019194483757019043, 0.2844967246055603, 0.004602102562785149, 0.0034257913939654827, 0.00569909019395709, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3722662925720215, 0.006906517315655947, 0.0037580765783786774, 0.013729525730013847, 0.00899916049093008, 0.09580616652965546, 0.17443552613258362, 0.018312277272343636, 0.019637461751699448, 0.024772292003035545, 0.14351719617843628, 0.0065680393017828465, 0.00602259486913681, 0.01094779558479786, 0.09432104229927063, 0.0, 0.0, 0.0, 0.0], [0.22097423672676086, 0.006749893072992563, 0.0016247264575213194, 0.0028242480475455523, 0.005597683135420084, 0.012753208167850971, 0.013379775919020176, 0.02161521464586258, 0.033228907734155655, 0.1842067539691925, 0.4144085943698883, 0.006727743428200483, 0.0048410771414637566, 0.013525729067623615, 0.018771378323435783, 0.03877083957195282, 0.0, 0.0, 0.0], [0.31884416937828064, 0.024501830339431763, 0.005828011780977249, 0.007992874830961227, 0.004529662895947695, 0.01504585612565279, 0.007530138362199068, 0.0016981554217636585, 0.04258086159825325, 0.06069943308830261, 0.45881497859954834, 0.00790413748472929, 0.005248240660876036, 0.008102895691990852, 0.011333424597978592, 0.012939754873514175, 0.006405508611351252, 0.0, 0.0], [0.44480109214782715, 0.02121046558022499, 0.005534640979021788, 0.005023736506700516, 0.003041581716388464, 0.00758452620357275, 0.004140904173254967, 0.0017402536468580365, 0.009280238300561905, 0.06639833003282547, 0.37808847427368164, 0.0076080309227108955, 0.0029781206976622343, 0.009056533686816692, 0.005787120200693607, 0.012583022005856037, 0.009718351066112518, 0.005424579605460167, 0.0], [0.5396348237991333, 0.03243331238627434, 0.006498749367892742, 0.009796380065381527, 0.0065738745033741, 0.015730293467640877, 0.007489172276109457, 0.01128440722823143, 0.014956209808588028, 0.03338741511106491, 0.16201533377170563, 0.02840246446430683, 0.010260652750730515, 0.012179647572338581, 0.014824253506958485, 0.029946256428956985, 0.01577683724462986, 0.00540950009599328, 0.043400511145591736]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9991610050201416, 0.0008389472495764494, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9974614381790161, 0.00010141773236682639, 0.0024371310137212276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9885725975036621, 4.4876676838612184e-05, 0.0010054095182567835, 0.010377119295299053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9988707900047302, 8.482877456117421e-05, 0.0003046169877052307, 0.000271397439064458, 0.00046848083729855716, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9987367987632751, 8.471844193991274e-05, 3.4784894523909315e-05, 1.749995499267243e-05, 0.00013755659165326506, 0.0009886791231110692, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9969180822372437, 5.1035574870184064e-05, 0.00017204035248141736, 0.00013362697791308165, 0.0001901872019516304, 0.0019961504731327295, 0.0005389220896176994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9875391721725464, 4.145782804698683e-05, 0.00016314018284901977, 1.5586783774779178e-05, 9.69574466580525e-06, 0.002037521218881011, 7.71357081248425e-05, 0.010116398334503174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9942353367805481, 3.790195478359237e-05, 8.290439291158691e-05, 4.64162185380701e-05, 0.00012681027874350548, 0.0003525195934344083, 0.0004988933796994388, 0.0034247543662786484, 0.0011945338919758797, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9888743162155151, 0.00035685228067450225, 0.0007802399923093617, 0.0007374151609838009, 0.0003898715367540717, 0.002125723520293832, 0.0003549937391653657, 0.003896306734532118, 0.0013953868765383959, 0.0010890632402151823, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7894319891929626, 0.001509205438196659, 0.16348256170749664, 0.0062849633395671844, 0.0028121659997850657, 0.015522475354373455, 0.0016915546730160713, 0.008356471545994282, 0.00783937145024538, 0.0016386598581448197, 0.0014305156655609608, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.46929827332496643, 0.0011147124459967017, 0.020790614187717438, 0.3899279832839966, 0.058124836534261703, 0.014915297739207745, 0.009103750810027122, 0.03056894615292549, 0.0035026511177420616, 0.001486689317971468, 0.0006993410061113536, 0.000466891418909654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2696766257286072, 0.00021988448861520737, 0.0034376096446067095, 0.041112758219242096, 0.3863718807697296, 0.027849247679114342, 0.034168608486652374, 0.22126023471355438, 0.002926182933151722, 0.00647020572796464, 0.0007105526747182012, 9.126213990384713e-05, 0.005704947747290134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0827968418598175, 0.0017507715383544564, 0.007906589657068253, 0.005012329667806625, 0.010211985558271408, 0.8012995719909668, 0.011547205038368702, 0.05805790051817894, 0.0163497906178236, 0.0028911104891449213, 0.0013742245500907302, 0.00021772335458081216, 0.00018007792823482305, 0.0004038585175294429, 0.0, 0.0, 0.0, 0.0, 0.0], [0.074992835521698, 0.0012592781567946076, 0.0005213448312133551, 0.00036465635639615357, 0.011708605103194714, 0.03862875699996948, 0.7111102938652039, 0.10890902578830719, 0.007459140382707119, 0.04004134610295296, 0.0020194060634821653, 1.2959668310941197e-05, 2.0548093743855134e-05, 0.0002304062945768237, 0.002721367869526148, 0.0, 0.0, 0.0, 0.0], [0.0024121860042214394, 7.344725599978119e-05, 0.00010210375330643728, 9.565789514454082e-05, 0.00027868145843967795, 0.003791730385273695, 0.0027581085450947285, 0.9749780893325806, 0.009714785031974316, 0.0048597389832139015, 0.0007506223628297448, 8.783759767538868e-06, 2.94471738016e-06, 1.936116632350604e-06, 0.00010902388748945668, 6.222820957191288e-05, 0.0, 0.0, 0.0], [0.11726879328489304, 0.0025178135838359594, 0.005559162702411413, 0.000586792069952935, 0.0004511350707616657, 0.04527038708329201, 0.00502276374027133, 0.308409720659256, 0.46397343277931213, 0.014292596839368343, 0.0023281751200556755, 0.00021732343884650618, 2.3225575205287896e-05, 1.2899935427412856e-05, 0.0017127875471487641, 0.0001355334825348109, 0.03221755847334862, 0.0, 0.0], [0.301014244556427, 0.0010546519188210368, 0.0008542729774489999, 0.0006288824952207506, 0.003776129800826311, 0.005815544165670872, 0.050402432680130005, 0.13283082842826843, 0.024653149768710136, 0.42187830805778503, 0.010435276664793491, 0.00014789857959840447, 0.00016960882931016386, 0.0005704562645405531, 0.000533613667357713, 0.009532712399959564, 0.031194116920232773, 0.004507867619395256, 0.0], [0.2256748229265213, 0.01989753730595112, 0.0040941862389445305, 0.0022740273270756006, 0.0009855538373813033, 0.015663208439946175, 0.008494175039231777, 0.026766369119286537, 0.008601492270827293, 0.011198925785720348, 0.6205134987831116, 0.006348391063511372, 0.001737309736199677, 0.00039661061600781977, 0.010404075495898724, 0.007756211329251528, 0.018831701949238777, 0.0022086340468376875, 0.008153198286890984]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9908252358436584, 0.009174744598567486, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9462660551071167, 0.014449233189225197, 0.03928466513752937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8378666639328003, 0.0229047704488039, 0.06339243799448013, 0.07583609223365784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8307172656059265, 0.019090967252850533, 0.04442797973752022, 0.08282306045293808, 0.022940699011087418, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8413587212562561, 0.013421602547168732, 0.022148843854665756, 0.027565350756049156, 0.040276676416397095, 0.05522876977920532, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8527243137359619, 0.019621292129158974, 0.028850920498371124, 0.023296384140849113, 0.014851692132651806, 0.035720568150281906, 0.024934934452176094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8558955192565918, 0.012268440797924995, 0.021461399272084236, 0.026170676574110985, 0.011571096256375313, 0.02491304650902748, 0.02185218594968319, 0.02586754783987999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8397089242935181, 0.005874990485608578, 0.021456340327858925, 0.019426077604293823, 0.011471189558506012, 0.016495680436491966, 0.020310183987021446, 0.014560932293534279, 0.05069561302661896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.783070981502533, 0.020365672186017036, 0.01858390122652054, 0.02268257737159729, 0.009889427572488785, 0.027420157566666603, 0.034087494015693665, 0.05826661363244057, 0.018577083945274353, 0.0070560951717197895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6986401081085205, 0.006058386992663145, 0.014905517920851707, 0.05283358693122864, 0.011671806685626507, 0.024554893374443054, 0.03492945432662964, 0.048059701919555664, 0.027724096551537514, 0.029022928327322006, 0.05159948021173477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7349923253059387, 0.004440058954060078, 0.007947764359414577, 0.014647609554231167, 0.008073936216533184, 0.02047068253159523, 0.022635485976934433, 0.01822337880730629, 0.01849502883851528, 0.053991347551345825, 0.017685718834400177, 0.07839667052030563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6649149656295776, 0.006626515183597803, 0.007658917456865311, 0.008834806270897388, 0.006758403964340687, 0.01932395063340664, 0.015348158776760101, 0.02185986563563347, 0.02586100995540619, 0.04875485226511955, 0.025257892906665802, 0.10590583086013794, 0.042894795536994934, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5457157492637634, 0.006424668710678816, 0.005772708915174007, 0.008018326945602894, 0.003324591787531972, 0.04255768656730652, 0.008975318633019924, 0.007143338676542044, 0.05988147482275963, 0.050239600241184235, 0.03152846544981003, 0.11532742530107498, 0.06682441383600235, 0.048266343772411346, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4666994512081146, 0.005522897467017174, 0.005307551473379135, 0.005698558408766985, 0.00893136765807867, 0.01359986700117588, 0.02335389517247677, 0.011020129546523094, 0.008684802800416946, 0.026558803394436836, 0.032172225415706635, 0.05865492671728134, 0.03541967272758484, 0.10015178471803665, 0.19822408258914948, 0.0, 0.0, 0.0, 0.0], [0.5835136771202087, 0.008854691870510578, 0.00505897356197238, 0.004422780126333237, 0.00453326478600502, 0.01174991950392723, 0.007084618788212538, 0.023409545421600342, 0.010982259176671505, 0.03657972812652588, 0.048490338027477264, 0.058018945157527924, 0.022632066160440445, 0.02476867474615574, 0.1009041965007782, 0.04899631440639496, 0.0, 0.0, 0.0], [0.515941858291626, 0.005024909973144531, 0.005033463705331087, 0.004704639315605164, 0.0022880733013153076, 0.008635148406028748, 0.007712775841355324, 0.009928029030561447, 0.06445474922657013, 0.09377798438072205, 0.04629036411643028, 0.04829689487814903, 0.023685963824391365, 0.014257588423788548, 0.04725692421197891, 0.04162565991282463, 0.0610850565135479, 0.0, 0.0], [0.5339521765708923, 0.002943899715319276, 0.004860620945692062, 0.004123267717659473, 0.0024494207464158535, 0.006677731405943632, 0.008639620617032051, 0.007391493767499924, 0.01755036599934101, 0.06609126925468445, 0.017561310902237892, 0.047359175980091095, 0.021510008722543716, 0.01570822484791279, 0.04456208273768425, 0.0517871119081974, 0.05040259659290314, 0.09642961621284485, 0.0], [0.3406409025192261, 0.03503483161330223, 0.004110442008823156, 0.003498414997011423, 0.0014296909794211388, 0.009587634354829788, 0.012905743904411793, 0.01033142488449812, 0.015135787427425385, 0.0135154714807868, 0.23847457766532898, 0.07386795431375504, 0.017588187009096146, 0.0055952249094843864, 0.04705984145402908, 0.09355244040489197, 0.02889159880578518, 0.02190803922712803, 0.026871778070926666]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9961661100387573, 0.003833869006484747, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9724605679512024, 0.021363524720072746, 0.006176014430820942, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9024822115898132, 0.06929849833250046, 0.012897124513983727, 0.015322251245379448, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.970562219619751, 0.017319971695542336, 0.004283711779862642, 0.0038887702394276857, 0.003945420030504465, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.47562727332115173, 0.04823457449674606, 0.05035112425684929, 0.07772999256849289, 0.3073531985282898, 0.040703803300857544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8497439026832581, 0.01416688971221447, 0.01578950509428978, 0.02260642871260643, 0.06364557892084122, 0.01863057352602482, 0.015417131595313549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8679795861244202, 0.03693198785185814, 0.008219871670007706, 0.010418262332677841, 0.01228050235658884, 0.011746063828468323, 0.036813247948884964, 0.015610525384545326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3899315297603607, 0.017910849303007126, 0.01209334097802639, 0.014975200407207012, 0.08709941804409027, 0.01147476863116026, 0.08362961560487747, 0.36614537239074707, 0.016739873215556145, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5528183579444885, 0.17108197510242462, 0.009898871183395386, 0.00926470011472702, 0.010633962228894234, 0.028567669913172722, 0.1151888370513916, 0.052351657301187515, 0.010765989311039448, 0.039428021758794785, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9293726086616516, 0.0021067403722554445, 0.0021943014580756426, 0.0029178927652537823, 0.00419467082247138, 0.0066002230159938335, 0.00841071829199791, 0.017955444753170013, 0.011440601199865341, 0.008926001377403736, 0.005880757234990597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9243060350418091, 0.0015556899597868323, 0.0004088429850526154, 0.00042935178498737514, 0.0025356882251799107, 0.0009598038741387427, 0.0017180410213768482, 0.002332158852368593, 0.0031713927164673805, 0.01900838315486908, 0.032448358833789825, 0.011126198805868626, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8697665929794312, 0.001457702717743814, 0.0004536389315035194, 0.0005051055341027677, 0.0019330348586663604, 0.0007350629894062877, 0.0017932734917849302, 0.0036966735497117043, 0.0018385117873549461, 0.035469140857458115, 0.05456513166427612, 0.019191812723875046, 0.008594375103712082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8798952698707581, 0.0012620738707482815, 0.0005760505446232855, 0.0006394295487552881, 0.0004584951384458691, 0.0010589816374704242, 0.0021757064387202263, 0.002336820587515831, 0.002403982449322939, 0.05837124213576317, 0.02389681152999401, 0.01654193177819252, 0.007457051891833544, 0.00292616686783731, 0.0, 0.0, 0.0, 0.0, 0.0], [0.46435612440109253, 0.007044681813567877, 0.005029177293181419, 0.006867975927889347, 0.026549404487013817, 0.005678297486156225, 0.007044739089906216, 0.01983364298939705, 0.00975560862571001, 0.038113582879304886, 0.11954677850008011, 0.07230380922555923, 0.0445951409637928, 0.1295241266489029, 0.04375692456960678, 0.0, 0.0, 0.0, 0.0], [0.8519890904426575, 0.0011336152674630284, 0.001720171538181603, 0.002437298884615302, 0.006104703061282635, 0.0023436055053025484, 0.0022995290346443653, 0.00460868701338768, 0.003843588288873434, 0.01821921579539776, 0.01645439676940441, 0.020224599167704582, 0.020271968096494675, 0.022613925859332085, 0.015400179661810398, 0.010335410945117474, 0.0, 0.0, 0.0], [0.6928762197494507, 0.00975019484758377, 0.0008156337426044047, 0.0011106813326478004, 0.002300370018929243, 0.0034133533481508493, 0.010070300661027431, 0.004843002650886774, 0.009426813572645187, 0.0594002902507782, 0.07141228020191193, 0.007366578094661236, 0.008738684467971325, 0.0073620653711259365, 0.030716391280293465, 0.07242056727409363, 0.007976622320711613, 0.0, 0.0], [0.33006441593170166, 0.004659163765609264, 0.0016192178009077907, 0.0018575696740299463, 0.0075299437157809734, 0.0021914837416261435, 0.031679488718509674, 0.07920822501182556, 0.0034500411711633205, 0.006184253375977278, 0.04901788383722305, 0.01918359287083149, 0.026160618290305138, 0.051543936133384705, 0.017133021727204323, 0.23688022792339325, 0.1226581260561943, 0.008978810161352158, 0.0], [0.3441146910190582, 0.055335551500320435, 0.0035556494258344173, 0.004065774846822023, 0.010835600085556507, 0.016743909567594528, 0.05111236125230789, 0.06460125744342804, 0.012334178201854229, 0.049522824585437775, 0.11904434859752655, 0.030642226338386536, 0.028592607006430626, 0.01851039193570614, 0.0773138478398323, 0.06817082315683365, 0.02443033829331398, 0.014856966212391853, 0.0062165698036551476]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9838355779647827, 0.016164449974894524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8913935422897339, 0.07082028687000275, 0.03778618574142456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8295106291770935, 0.044330015778541565, 0.04831397533416748, 0.07784534990787506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7849868535995483, 0.026271963492035866, 0.04763757809996605, 0.11329450458288193, 0.02780901826918125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7642473578453064, 0.04177848994731903, 0.03268517553806305, 0.06975236535072327, 0.060170259326696396, 0.03136638179421425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9109405875205994, 0.021143469959497452, 0.004461295902729034, 0.005631748586893082, 0.004461583215743303, 0.04206075146794319, 0.011300498619675636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6627746820449829, 0.023781120777130127, 0.019452059641480446, 0.02455976977944374, 0.00840415246784687, 0.10616051405668259, 0.13096201419830322, 0.023905621841549873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6438416838645935, 0.02076840028166771, 0.03280661255121231, 0.05218316242098808, 0.03789234906435013, 0.014905117452144623, 0.09678474068641663, 0.0954098179936409, 0.005408113822340965, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6042081117630005, 0.04420120641589165, 0.010910479351878166, 0.012609950266778469, 0.02033001370728016, 0.08794905245304108, 0.049843091517686844, 0.048002276569604874, 0.041593197733163834, 0.08035258203744888, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5596746206283569, 0.029684802517294884, 0.017495419830083847, 0.022717319428920746, 0.022430354729294777, 0.050663843750953674, 0.05873749777674675, 0.05675099045038223, 0.0256687980145216, 0.13278760015964508, 0.023388832807540894, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7687680125236511, 0.01807347685098648, 0.003777572652325034, 0.010218392126262188, 0.005004408303648233, 0.03448817506432533, 0.009200272150337696, 0.007636384107172489, 0.04882103204727173, 0.054819632321596146, 0.031000759452581406, 0.00819185096770525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6741282939910889, 0.01014076080173254, 0.006173792760819197, 0.01031408365815878, 0.00998406670987606, 0.05558301508426666, 0.016897052526474, 0.026880092918872833, 0.07313649356365204, 0.06543846428394318, 0.017505399882793427, 0.018990857526659966, 0.014827625826001167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.786801278591156, 0.0063613704405725, 0.008471294306218624, 0.02534012869000435, 0.005241601262241602, 0.028198685497045517, 0.012447846122086048, 0.0034070799592882395, 0.027223143726587296, 0.011041471734642982, 0.017564404755830765, 0.03130222484469414, 0.03064660355448723, 0.005952821113169193, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7320671677589417, 0.027054162696003914, 0.014505266211926937, 0.044602714478969574, 0.021589402109384537, 0.01165673229843378, 0.03271879628300667, 0.014200663194060326, 0.0071093435399234295, 0.012162717990577221, 0.029204081743955612, 0.013870906084775925, 0.019641997292637825, 0.01489355880767107, 0.004722644574940205, 0.0, 0.0, 0.0, 0.0], [0.7754060626029968, 0.011681870557367802, 0.005307743325829506, 0.007130637299269438, 0.007797853089869022, 0.033972423523664474, 0.005583719350397587, 0.01965569518506527, 0.04278235137462616, 0.020134158432483673, 0.010847465135157108, 0.011783669702708721, 0.007120766211301088, 0.010213127359747887, 0.02420172654092312, 0.006380743347108364, 0.0, 0.0, 0.0], [0.5632801651954651, 0.01638280600309372, 0.02534305676817894, 0.027160443365573883, 0.006753993686288595, 0.05453713238239288, 0.04360101372003555, 0.008937857113778591, 0.02695276029407978, 0.04829591512680054, 0.02506106160581112, 0.059701625257730484, 0.02394801191985607, 0.0033674982842057943, 0.034036893397569656, 0.02654092013835907, 0.006098836660385132, 0.0, 0.0], [0.7335182428359985, 0.011013790965080261, 0.007218087092041969, 0.017483152449131012, 0.009704992175102234, 0.0052353935316205025, 0.030944032594561577, 0.02805379405617714, 0.002531331731006503, 0.02878211811184883, 0.017041737213730812, 0.014729334972798824, 0.018546588718891144, 0.009843915700912476, 0.0037925317883491516, 0.0394846573472023, 0.019757715985178947, 0.00231855153106153, 0.0], [0.4317794144153595, 0.07735656946897507, 0.006162636447697878, 0.01357985194772482, 0.008913084864616394, 0.030096467584371567, 0.02875194512307644, 0.04243312031030655, 0.01833091862499714, 0.061946652829647064, 0.09261099994182587, 0.013728511519730091, 0.013308020308613777, 0.007781136315315962, 0.025604000315070152, 0.03233081102371216, 0.02892312780022621, 0.013544670306146145, 0.05281810462474823]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9844651818275452, 0.015534800477325916, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9857293367385864, 0.009274343028664589, 0.0049962690100073814, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9477081894874573, 0.004847089760005474, 0.004398169927299023, 0.04304651543498039, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9400169849395752, 0.0035262806341052055, 0.003407504176720977, 0.022074133157730103, 0.030975131317973137, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8393450975418091, 0.005345892161130905, 0.006760416552424431, 0.023675639182329178, 0.04299561679363251, 0.08187733590602875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.887768566608429, 0.001560993492603302, 0.004177851602435112, 0.01714727282524109, 0.02244417928159237, 0.0540628544986248, 0.012838246300816536, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8912408947944641, 0.001755156321451068, 0.003131891367956996, 0.014929774217307568, 0.01357510406523943, 0.06013253331184387, 0.008873979561030865, 0.006360757630318403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9302092790603638, 0.0025287093594670296, 0.002516103209927678, 0.007882711477577686, 0.010103895328938961, 0.017165351659059525, 0.009997769258916378, 0.0036407597362995148, 0.015955345705151558, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7606710195541382, 0.004270655568689108, 0.008511330932378769, 0.028511835262179375, 0.02565864659845829, 0.054307229816913605, 0.017092090100049973, 0.015606451779603958, 0.01906597800552845, 0.0663047581911087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5885013937950134, 0.0033646828960627317, 0.021727994084358215, 0.03320818021893501, 0.04093119129538536, 0.05489550903439522, 0.02781156450510025, 0.029267022386193275, 0.057724397629499435, 0.13452884554862976, 0.008039211854338646, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7451996803283691, 0.006402432452887297, 0.004591306671500206, 0.017323361709713936, 0.018701408058404922, 0.060487259179353714, 0.014622122049331665, 0.020515184849500656, 0.03016975149512291, 0.03855986148118973, 0.015253937803208828, 0.028173619881272316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7827643752098083, 0.007593927904963493, 0.0030801226384937763, 0.006825572345405817, 0.012514766305685043, 0.03371168673038483, 0.01044137217104435, 0.015118119306862354, 0.018020058050751686, 0.02716064266860485, 0.02171102538704872, 0.028742358088493347, 0.03231597691774368, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5407602190971375, 0.011131045408546925, 0.006035274360328913, 0.0077613829635083675, 0.006490322761237621, 0.07120885699987411, 0.011018161661922932, 0.007221042178571224, 0.06584127247333527, 0.016344889998435974, 0.020438427105545998, 0.07068128883838654, 0.06230214983224869, 0.10276564955711365, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5180252194404602, 0.012477324344217777, 0.009730258025228977, 0.006471345201134682, 0.013605955056846142, 0.016729697585105896, 0.017214123159646988, 0.00851681362837553, 0.01245946530252695, 0.015717318281531334, 0.01525372639298439, 0.07271727174520493, 0.04457686096429825, 0.09514400362968445, 0.1413605958223343, 0.0, 0.0, 0.0, 0.0], [0.6593721508979797, 0.009667245671153069, 0.007450403645634651, 0.006640507373958826, 0.005143551621586084, 0.013431885279715061, 0.00682354811578989, 0.02212924137711525, 0.0210728757083416, 0.020375339314341545, 0.017964225262403488, 0.05005534365773201, 0.029380928725004196, 0.02624044008553028, 0.052552737295627594, 0.05169950798153877, 0.0, 0.0, 0.0], [0.38869550824165344, 0.008652335964143276, 0.006894771475344896, 0.006032906472682953, 0.003885739017277956, 0.01908770203590393, 0.006162111647427082, 0.004282787907868624, 0.04982627183198929, 0.010656997561454773, 0.016056153923273087, 0.0666736513376236, 0.046982720494270325, 0.041473109275102615, 0.15985643863677979, 0.11703173071146011, 0.047748927026987076, 0.0, 0.0], [0.697420597076416, 0.006776219233870506, 0.004216604866087437, 0.003051439765840769, 0.003992049023509026, 0.00585514772683382, 0.007245673332363367, 0.003426565323024988, 0.007310574408620596, 0.012829209677875042, 0.019082944840192795, 0.020007943734526634, 0.016048112884163857, 0.02794303372502327, 0.023083709180355072, 0.08086492121219635, 0.03957100585103035, 0.021274253726005554, 0.0], [0.15421530604362488, 0.017478641122579575, 0.012160713784396648, 0.010895861312747002, 0.0176907479763031, 0.021281680092215538, 0.013952315784990788, 0.006230476778000593, 0.008646221831440926, 0.01600346527993679, 0.06277924031019211, 0.13030125200748444, 0.07834729552268982, 0.10611999779939651, 0.08539951592683792, 0.142428457736969, 0.036635857075452805, 0.022252846509218216, 0.05718018859624863]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9916919469833374, 0.008308019489049911, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9721693396568298, 0.007908825762569904, 0.019921839237213135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.977790355682373, 0.0036751541774719954, 0.006145047955214977, 0.01238941214978695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9853358864784241, 0.0015464704483747482, 0.0033435537479817867, 0.004577441606670618, 0.005196580197662115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9777024984359741, 0.0017037265934050083, 0.002315572462975979, 0.0030555736739188433, 0.002991484012454748, 0.012231121771037579, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.985691487789154, 0.0007647672318853438, 0.0006273899343796074, 0.002120381221175194, 0.001390831428579986, 0.0033980694133788347, 0.006007102783769369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9709203243255615, 0.0003122086636722088, 0.0003154866863042116, 0.0008655157871544361, 0.0007122591487132013, 0.004034549463540316, 0.001217808574438095, 0.021621791645884514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9365503191947937, 0.0006914291298016906, 0.00102526496630162, 0.0019221061374992132, 0.0006317956722341478, 0.003287083236500621, 0.001570679945871234, 0.007309925742447376, 0.047011587768793106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8837003111839294, 0.0020347388926893473, 0.0027129915542900562, 0.009009122848510742, 0.014133406803011894, 0.028142357245087624, 0.012474168092012405, 0.03461374342441559, 0.005465581081807613, 0.0077135940082371235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9109503030776978, 0.002159097930416465, 0.003546432126313448, 0.007519240025430918, 0.005119227804243565, 0.011385461315512657, 0.012351001612842083, 0.02224472351372242, 0.0052938275039196014, 0.011703449301421642, 0.007727161515504122, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.45544883608818054, 0.0027147310320287943, 0.004539090674370527, 0.007113568484783173, 0.016314459964632988, 0.08475665748119354, 0.1338561475276947, 0.2028031349182129, 0.008075941354036331, 0.06847978383302689, 0.015050727874040604, 0.0008469880558550358, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.624350368976593, 0.0022452115081250668, 0.0021661873906850815, 0.0029385017696768045, 0.0047046346589922905, 0.05483575910329819, 0.124608114361763, 0.1265007108449936, 0.0046909567900002, 0.04025941342115402, 0.011297456920146942, 0.0005368515267036855, 0.0008658459410071373, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6887167096138, 0.0017265864880755544, 0.00481434678658843, 0.005040409974753857, 0.005620479583740234, 0.11728893965482712, 0.12532638013362885, 0.031390536576509476, 0.0018100648885592818, 0.011024506762623787, 0.0035240505822002888, 0.0011018046643584967, 0.0017237436259165406, 0.0008914784993976355, 0.0, 0.0, 0.0, 0.0, 0.0], [0.503660261631012, 0.004413307644426823, 0.007314050104469061, 0.005962268449366093, 0.006574489176273346, 0.031678054481744766, 0.2409280389547348, 0.1264788806438446, 0.007592853624373674, 0.024165933951735497, 0.023737682029604912, 0.0028017759323120117, 0.001455965917557478, 0.0007771367090754211, 0.012459141202270985, 0.0, 0.0, 0.0, 0.0], [0.47348394989967346, 0.0011839412618428469, 0.001263324054889381, 0.0023406685795634985, 0.0014853596221655607, 0.005575400311499834, 0.0134788379073143, 0.1605747491121292, 0.022568166255950928, 0.2756996750831604, 0.03424683213233948, 0.0011474468046799302, 0.0009557215380482376, 0.0002533744554966688, 0.001182848704047501, 0.004559677559882402, 0.0, 0.0, 0.0], [0.4923296570777893, 0.0012883078306913376, 0.0008852080209180713, 0.0015817724633961916, 0.001180319581180811, 0.003396946471184492, 0.004368869587779045, 0.011895423755049706, 0.0626758486032486, 0.40276849269866943, 0.014510655775666237, 0.0001872855209512636, 0.0002487805613782257, 0.00013460857735481113, 0.00048053855425678194, 0.0012194423470646143, 0.0008479166426695883, 0.0, 0.0], [0.5177610516548157, 0.00391708267852664, 0.00270076678134501, 0.002707585459575057, 0.0010610314784571528, 0.004451805260032415, 0.007097477093338966, 0.04678187891840935, 0.08316629379987717, 0.15244100987911224, 0.1391390860080719, 0.0012914284598082304, 0.0006662479136139154, 0.00044427288230508566, 0.00101628084667027, 0.0037573359441012144, 0.017662163823843002, 0.013937116600573063, 0.0], [0.11340796202421188, 0.009106103330850601, 0.032926127314567566, 0.0406777486205101, 0.02956731803715229, 0.012048489414155483, 0.06662096828222275, 0.043130986392498016, 0.0017588883638381958, 0.00516206631436944, 0.01649835705757141, 0.24050740897655487, 0.20534472167491913, 0.019520577043294907, 0.023860519751906395, 0.12131886184215546, 0.017467983067035675, 0.0004676616517826915, 0.0006072251708246768]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.992693305015564, 0.007306681480258703, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9277474284172058, 0.030179785564541817, 0.04207270219922066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8337011933326721, 0.033086493611335754, 0.058676499873399734, 0.0745357945561409, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8362598419189453, 0.06664466112852097, 0.011655046604573727, 0.06166916340589523, 0.023771239444613457, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3576313853263855, 0.019448846578598022, 0.09360873699188232, 0.3452967703342438, 0.16572919487953186, 0.01828499510884285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4601496458053589, 0.011133410036563873, 0.09136790037155151, 0.2664906978607178, 0.08355928957462311, 0.060288555920124054, 0.027010619640350342, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.48713433742523193, 0.011050106957554817, 0.03228256478905678, 0.1969524621963501, 0.10120192170143127, 0.04266546666622162, 0.08176106214523315, 0.046952102333307266, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8076351284980774, 0.008232791908085346, 0.01643454097211361, 0.04179723933339119, 0.03760696202516556, 0.00975197833031416, 0.013433609157800674, 0.03867168724536896, 0.026435870677232742, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.44568371772766113, 0.02851622737944126, 0.06508838385343552, 0.10498709231615067, 0.049402933567762375, 0.037439778447151184, 0.019435545429587364, 0.03852812573313713, 0.20536388456821442, 0.005554200150072575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3479395806789398, 0.003447584342211485, 0.031595852226018906, 0.04448786750435829, 0.027388429269194603, 0.04877061769366264, 0.027555475011467934, 0.019418692216277122, 0.296986848115921, 0.12537024915218353, 0.027038834989070892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6718448996543884, 0.02346552349627018, 0.0048601883463561535, 0.011274205520749092, 0.011123373173177242, 0.004058949649333954, 0.0027705093380063772, 0.008361496031284332, 0.03154318779706955, 0.0026410995051264763, 0.13785555958747864, 0.09020093083381653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4811433255672455, 0.024681396782398224, 0.011985082179307938, 0.011800890788435936, 0.00948453601449728, 0.0020441189408302307, 0.0014215211849659681, 0.012244462966918945, 0.014913762919604778, 0.005744169000536203, 0.20297591388225555, 0.169202983379364, 0.052357785403728485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17888131737709045, 0.02905786596238613, 0.0020152723882347345, 0.009667622856795788, 0.0003944564377889037, 0.0013693073997274041, 0.0008121327846311033, 0.0026305285282433033, 0.009782080538570881, 0.013043644838035107, 0.5299530029296875, 0.06683342158794403, 0.14761225879192352, 0.007947058416903019, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11817464977502823, 0.02266569808125496, 0.008012381382286549, 0.025452693924307823, 0.003368866164237261, 0.000667888147290796, 0.00109317887108773, 0.002113203750923276, 0.0013018834870308638, 0.001897691865451634, 0.356311172246933, 0.15371133387088776, 0.2613706886768341, 0.0338229201734066, 0.010035726241767406, 0.0, 0.0, 0.0, 0.0], [0.04182244837284088, 0.004148789215832949, 0.007967726327478886, 0.015106042847037315, 0.001485653454437852, 0.002621633931994438, 0.0014263020129874349, 0.0024287912528961897, 0.0042068869806826115, 0.006966820918023586, 0.26730063557624817, 0.18918636441230774, 0.3005249798297882, 0.028363430872559547, 0.09261380136013031, 0.0338297002017498, 0.0, 0.0, 0.0], [0.09601517021656036, 0.005025504156947136, 0.007254583295434713, 0.02874835580587387, 0.00199655769392848, 0.012356518767774105, 0.00939914956688881, 0.001690241857431829, 0.03709134832024574, 0.016375306993722916, 0.14226211607456207, 0.11298508942127228, 0.26106104254722595, 0.01335030049085617, 0.14199386537075043, 0.09997466951608658, 0.012420148588716984, 0.0, 0.0], [0.6174789667129517, 0.011868919245898724, 0.005776131525635719, 0.010775834321975708, 0.0023747114464640617, 0.001251031062565744, 0.0018365123542025685, 0.0037621993105858564, 0.005938460119068623, 0.007027966435998678, 0.1065806970000267, 0.10508004575967789, 0.07124105840921402, 0.009152399376034737, 0.005521611776202917, 0.00856209360063076, 0.013565500266849995, 0.012205908074975014, 0.0], [0.37122243642807007, 0.0323377400636673, 0.010080401785671711, 0.011669446714222431, 0.00160732411313802, 0.010943681001663208, 0.008429311215877533, 0.005496432073414326, 0.05933045223355293, 0.007444264367222786, 0.14202065765857697, 0.07069699466228485, 0.053767129778862, 0.001998315565288067, 0.03551597148180008, 0.016138790175318718, 0.013010717928409576, 0.130137637257576, 0.018152225762605667]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9759529232978821, 0.024047061800956726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9055547118186951, 0.06851321458816528, 0.02593212202191353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8507479429244995, 0.11806639283895493, 0.01928926445543766, 0.011896448209881783, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9069643020629883, 0.038405902683734894, 0.017659783363342285, 0.01788322627544403, 0.019086813554167747, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8876373767852783, 0.07824023067951202, 0.010552656836807728, 0.005015239585191011, 0.010204948484897614, 0.00834958627820015, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8548833727836609, 0.09000599384307861, 0.011659656651318073, 0.005370438564568758, 0.0025684621650725603, 0.013589969836175442, 0.021922068670392036, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8858677744865417, 0.05158891901373863, 0.006163186859339476, 0.00641405675560236, 0.00178525410592556, 0.016250774264335632, 0.019917858764529228, 0.01201225258409977, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9304301142692566, 0.015178087167441845, 0.0037506043445318937, 0.0032526899594813585, 0.0011103582801297307, 0.0018608174286782742, 0.01720527559518814, 0.023010220378637314, 0.004201855510473251, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8112565279006958, 0.03936255723237991, 0.01851775124669075, 0.016089236363768578, 0.002850863616913557, 0.02261725626885891, 0.020730750635266304, 0.014176035299897194, 0.010831819847226143, 0.04356734827160835, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5664587020874023, 0.007334225811064243, 0.03714964538812637, 0.039888665080070496, 0.0069323754869401455, 0.013228596188127995, 0.017829028889536858, 0.01253906823694706, 0.006967214867472649, 0.1767960786819458, 0.11487631499767303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5373415946960449, 0.0075917416252195835, 0.005765301175415516, 0.007789601571857929, 0.0022912975400686264, 0.008494834415614605, 0.0175308994948864, 0.005054150242358446, 0.00267016445286572, 0.1310359090566635, 0.146758571267128, 0.1276758909225464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5549607276916504, 0.007594490423798561, 0.003069112775847316, 0.0017587627517059445, 0.0015474397223442793, 0.010827631689608097, 0.009076131507754326, 0.0049432432278990746, 0.005989430006593466, 0.14053569734096527, 0.18785622715950012, 0.05818939954042435, 0.013651801273226738, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.37542158365249634, 0.0020196617115288973, 0.0030459461268037558, 0.0011753790313377976, 0.0006265292759053409, 0.09474369138479233, 0.008138425648212433, 0.003057122463360429, 0.051334306597709656, 0.12458448857069016, 0.16771049797534943, 0.14551955461502075, 0.013461606577038765, 0.009161179885268211, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5060486197471619, 0.006129802204668522, 0.0023778683971613646, 0.0009000151767395437, 0.0004391046823002398, 0.002458038507029414, 0.010398542508482933, 0.008428056724369526, 0.003214176744222641, 0.11663305759429932, 0.20334164798259735, 0.07454819977283478, 0.016195928677916527, 0.008752219378948212, 0.04013479873538017, 0.0, 0.0, 0.0, 0.0], [0.6736326813697815, 0.005456156563013792, 0.0014672215329483151, 0.0006964478525333107, 0.0001949994039023295, 0.005324950907379389, 0.0015214822487905622, 0.003478648141026497, 0.015136316418647766, 0.04602140933275223, 0.08290299028158188, 0.032297685742378235, 0.011093801818788052, 0.004380617756396532, 0.09420426189899445, 0.022190406918525696, 0.0, 0.0, 0.0], [0.5837268829345703, 0.0046133785508573055, 0.0006003261660225689, 0.00030097237322479486, 6.681485683657229e-05, 0.005733763333410025, 0.0011150528443977237, 0.0007787345675751567, 0.04064778983592987, 0.10951865464448929, 0.11873200535774231, 0.012375936843454838, 0.0030125125776976347, 0.0007587686413899064, 0.09244532138109207, 0.013568892143666744, 0.0120041873306036, 0.0, 0.0], [0.7426260709762573, 0.0030927867628633976, 0.0007904730155132711, 0.0009706048876978457, 7.669063052162528e-05, 0.0006079094018787146, 0.003221646649762988, 0.0032567810267210007, 0.0012656841427087784, 0.050451092422008514, 0.09924206137657166, 0.011625751852989197, 0.007341394200921059, 0.0012151255505159497, 0.005369475111365318, 0.03424868360161781, 0.026034507900476456, 0.008563226088881493, 0.0], [0.8638198375701904, 0.004343715962022543, 0.0016231652116402984, 0.0006546938675455749, 5.095302185509354e-05, 0.0048120212741196156, 0.0009603788494132459, 0.0006047060014680028, 0.005449461750686169, 0.004741876386106014, 0.042140305042266846, 0.015875255689024925, 0.0022947301622480154, 0.0001483614614699036, 0.021141286939382553, 0.007482013665139675, 0.0031786549370735884, 0.010900051333010197, 0.00977843813598156]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9980756044387817, 0.0019243244314566255, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9981271624565125, 0.00033238172181881964, 0.0015405303565785289, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9843994379043579, 0.0003932786057703197, 0.0004640583647415042, 0.014743370935320854, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9990705847740173, 0.00025784445460885763, 0.00018213738803751767, 0.00031633939943276346, 0.00017312706040684134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9972221851348877, 0.0008684717467986047, 0.00011913351772818714, 0.00014345049567054957, 0.00036858656676486135, 0.0012780404649674892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9916746020317078, 0.001142252585850656, 0.0005319511983543634, 0.00028926454251632094, 0.00041115761268883944, 0.002172166248783469, 0.0037786783650517464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9766552448272705, 0.0014118481194600463, 0.0007640239782631397, 9.522057371214032e-05, 0.00015044280735310167, 0.0035197159741073847, 0.0014028127770870924, 0.01600070856511593, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9903864860534668, 0.0008815229521133006, 0.0004887430113740265, 0.00010247238969895989, 0.0005629070801660419, 0.00112732476554811, 0.0007659286493435502, 0.0021908299531787634, 0.003493872005492449, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9223426580429077, 0.0033448548056185246, 0.003865206614136696, 0.0011173977982252836, 0.001860549207776785, 0.014713319949805737, 0.0006249104044400156, 0.029151733964681625, 0.015965059399604797, 0.007014233153313398, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8114156126976013, 0.0027914871461689472, 0.12187132984399796, 0.004706588573753834, 0.0020285833161324263, 0.007787260692566633, 0.001976610394194722, 0.0032913440372794867, 0.009127236902713776, 0.0312336552888155, 0.003770062467083335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18555423617362976, 0.00044645529123954475, 0.0026181729044765234, 0.7782878279685974, 0.022026369348168373, 0.002055991906672716, 0.0026195792015641928, 0.004384223837405443, 0.0002532135113142431, 0.001339927432127297, 0.00036848109448328614, 4.553057442535646e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.43380895256996155, 0.0022091541904956102, 0.0021022669970989227, 0.026887424290180206, 0.36582741141319275, 0.03768390044569969, 0.013169820420444012, 0.08097313344478607, 0.0031087780371308327, 0.01319305133074522, 0.003257912350818515, 9.272390161640942e-05, 0.01768544502556324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0907757505774498, 0.0032616311218589544, 0.00665293401107192, 0.0014485185965895653, 0.007470706012099981, 0.7429171800613403, 0.00843979325145483, 0.04418971389532089, 0.05756525695323944, 0.023648081347346306, 0.011149056255817413, 0.001021400443278253, 0.00024254443997051567, 0.001217403681948781, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23230528831481934, 0.03522731736302376, 0.008932312950491905, 0.003520325757563114, 0.053717195987701416, 0.06579684466123581, 0.21403741836547852, 0.09053606539964676, 0.05295661464333534, 0.12318864464759827, 0.10448876023292542, 0.003585327183827758, 0.0013814246049150825, 0.0038011358119547367, 0.0065253195352852345, 0.0, 0.0, 0.0, 0.0], [0.017101401463150978, 0.0012096328428015113, 0.0028043880593031645, 0.00028147155535407364, 0.0009967240039259195, 0.006252261344343424, 0.010008656419813633, 0.9161884784698486, 0.010311726480722427, 0.019849615171551704, 0.008972707204520702, 0.0013369484804570675, 0.00011088459723396227, 0.00025186064885929227, 0.0014328774996101856, 0.002890330972149968, 0.0, 0.0, 0.0], [0.19890296459197998, 0.023078177124261856, 0.007464895490556955, 0.0001526745909359306, 0.0012415280798450112, 0.019901515915989876, 0.006286968942731619, 0.12176758795976639, 0.4365607500076294, 0.09489922225475311, 0.05649929493665695, 0.005029001738876104, 8.104481821646914e-05, 0.00026334822177886963, 0.0025027564261108637, 0.0014301686314865947, 0.023938007652759552, 0.0, 0.0], [0.2711745500564575, 0.008688805624842644, 0.0021493814419955015, 0.0005849858280271292, 0.012305070646107197, 0.006738397292792797, 0.006732568144798279, 0.04159074276685715, 0.01662248745560646, 0.5162593126296997, 0.07696418464183807, 0.0012098707957193255, 0.00045180151937529445, 0.0023488630540668964, 0.0003745016292668879, 0.0018969363300129771, 0.029632164165377617, 0.004275364335626364, 0.0], [0.1304706484079361, 0.06796805560588837, 0.02794206701219082, 0.0016744117019698024, 0.005621299613267183, 0.04978887364268303, 0.004220736213028431, 0.03190944343805313, 0.18819217383861542, 0.016685595735907555, 0.3914163410663605, 0.03468402847647667, 0.0013909341068938375, 0.0014894655905663967, 0.010173247195780277, 0.0016488415421918035, 0.007349047344177961, 0.024874573573470116, 0.0025001573376357555]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9946979284286499, 0.005302093457430601, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.98580002784729, 0.0020140171982347965, 0.0121860196813941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9834845662117004, 0.001314075430855155, 0.002196052111685276, 0.013005409389734268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9909797310829163, 0.0008285403018817306, 0.00035003278753720224, 0.0018045686883851886, 0.0060369838029146194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9823090434074402, 0.000751176499761641, 0.000326845096424222, 0.0006428922642953694, 0.007350106257945299, 0.008619869127869606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9885873794555664, 0.0006201111827977002, 6.0533915529958904e-05, 9.578225581208244e-05, 0.0008360630017705262, 0.002802313072606921, 0.006997703108936548, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9376182556152344, 0.0005464295390993357, 0.00019547922420315444, 0.00024910469073802233, 0.0006815637461841106, 0.006647015921771526, 0.003181978827342391, 0.050880059599876404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.983992874622345, 0.0001258245756616816, 0.00012538782902993262, 0.0005161984590813518, 0.0006346940062940121, 0.001544842729344964, 0.0047926330007612705, 0.004473579581826925, 0.003793749725446105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9651673436164856, 0.004145716782659292, 0.0022296870592981577, 0.0032631156500428915, 0.0027789315208792686, 0.004577770363539457, 0.0030192947015166283, 0.009100189432501793, 0.0027748688589781523, 0.0029430228751152754, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9242902398109436, 0.0015441298019140959, 0.0375945121049881, 0.00568235432729125, 0.0019242012640461326, 0.003557554678991437, 0.0015364576829597354, 0.007961266674101353, 0.005923292133957148, 0.0014875548658892512, 0.008498422801494598, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9148377776145935, 0.0004821106558665633, 0.0023871648591011763, 0.0238084327429533, 0.010833182372152805, 0.012840666808187962, 0.00777754420414567, 0.0178156029433012, 0.003988218959420919, 0.0007181697874329984, 0.004131893161684275, 0.00037918423186056316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9393443465232849, 0.0003257252392359078, 0.00023632730881217867, 0.0016439438331872225, 0.016261128708720207, 0.011176910251379013, 0.009008035063743591, 0.011662362143397331, 0.002861995482817292, 0.0004463868390303105, 0.006116739474236965, 4.2136703996220604e-05, 0.0008740179473534226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.950455367565155, 0.00037135995808057487, 5.821597369504161e-05, 0.00020560791017487645, 0.00025133127928711474, 0.03234023228287697, 0.0020836025942116976, 0.0036955815739929676, 0.0024217814207077026, 4.3965181248495355e-05, 0.007291088346391916, 3.442146771703847e-05, 6.284270784817636e-05, 0.0006845637690275908, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8811835050582886, 0.00043603460653685033, 5.451745892059989e-05, 9.915502596413717e-05, 0.0007860878249630332, 0.002880552550777793, 0.04891522601246834, 0.01761198416352272, 0.0019055056618526578, 0.002337883925065398, 0.04092954471707344, 1.3904237675887998e-05, 3.225330146960914e-05, 0.0003562855417840183, 0.0024575977586209774, 0.0, 0.0, 0.0, 0.0], [0.9408670663833618, 0.00046344983275048435, 1.4637638741987757e-05, 1.836867886595428e-05, 4.013052603113465e-05, 0.0010316702537238598, 0.0008349618292413652, 0.029074033722281456, 0.0014518991811200976, 7.136839849408716e-05, 0.020221462473273277, 1.0519102033867966e-05, 6.087089332140749e-06, 3.0219513064366765e-05, 0.003995527978986502, 0.0018684546230360866, 0.0, 0.0, 0.0], [0.9018123745918274, 0.0006545590586028993, 3.931289029424079e-05, 3.044361073989421e-05, 3.0430084734689444e-05, 0.0031101324129849672, 0.0018017042893916368, 0.012851168401539326, 0.029925281181931496, 0.00014977040700614452, 0.01416129432618618, 1.8574344721855596e-05, 5.936739853495965e-06, 2.7150646928930655e-05, 0.01557088177651167, 0.004706204868853092, 0.015104790218174458, 0.0, 0.0], [0.9299853444099426, 0.00013567553833127022, 3.723818372236565e-05, 0.00015308419824577868, 8.882905240170658e-05, 0.0013508350821211934, 0.003918481059372425, 0.0023103950079530478, 0.003389408579096198, 0.021374687552452087, 0.02203879877924919, 3.3932279620785266e-05, 4.4571504986379296e-05, 0.00017674091213848442, 0.0008301232592202723, 0.00851883552968502, 0.00277873151935637, 0.0028343209996819496, 0.0], [0.7106435894966125, 0.007039703894406557, 0.0003156668972223997, 0.0005015455535613, 0.00013679970288649201, 0.0030240740161389112, 0.003002651734277606, 0.0022713434882462025, 0.0026232311502099037, 0.0007318210555240512, 0.20778702199459076, 0.0013322184095159173, 0.0009040145087055862, 0.0006323967827484012, 0.013386362232267857, 0.023037750273942947, 0.00554580707103014, 0.004053282085806131, 0.013030708767473698]]]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x1b6190ea720>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis_attn_patterns(model, repeated_prompt, [5, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa8e571",
   "metadata": {},
   "source": [
    "We can see that the attention heads that correspond to the stronger induction scores have distinct attention patterns. They all have a clearly indicated diagonal, offset from the center by half sequence length. Hence, these attention heads are active when a sequence repeats itself. We would also see this if we were to rerun the code with another repeated sequence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08f7e89",
   "metadata": {},
   "source": [
    "### Activation patching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a64e068",
   "metadata": {},
   "source": [
    "We now want to demonstrate the activation patching technique on a small problem. We will first run a forward pass on the clean prompt and cache the activations. Then, we will run a forward pass on the corrupted run and at each layer and position exchange the corrupted activations with the clean activations from the cache. To do this, we use the run_with_hooks method from TransformerLens and make a suitable hook function, activation_patching_hook. We make an activation_patching function that returns the results, as well as an activation_patching_mult function to use if the answer has more than a single token. In the latter case, we need to run through the model multiple separate times, one for each token in the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec0fffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_patching_hook(resid_pre, hook, position, clean_cache):\n",
    "    clean_activation = clean_cache[hook.name]\n",
    "    resid_pre[:, position, :] = clean_activation[:, position, :]\n",
    "    return resid_pre\n",
    "\n",
    "def activation_patching(model, clean_prompt, corrupted_prompt, clean_answer, corrupted_answer):\n",
    "    '''\n",
    "    Performs activation patching of the clean prompt onto the corrupted prompt. The prompts must have the same number of tokens.\n",
    "\n",
    "    Parameters:\n",
    "    model: The transformer lens model\n",
    "    clean_prompt (str): The clean prompt we will patch from\n",
    "    corrupted_prompt (str): The corrupted prompt we will patch onto\n",
    "    clean_answer (str): The answer (or next prediction) of the clean prompt\n",
    "    corrupted_answer (str): The answer (or next prediction) of the corrupted prompt\n",
    "\n",
    "    Returns: \n",
    "    patching_results (list[tensor[layers, positions]]): The logit difference after patching\n",
    "    patched_logits (list[tensor[num_tokens, logits]]): The logits of the tokens after patching\n",
    "    '''\n",
    "    \n",
    "    clean_logits, clean_cache = model.run_with_cache(clean_prompt)\n",
    "    corrupted_logits = model(corrupted_prompt)\n",
    "    print(\"Clean answer:\",clean_answer)\n",
    "    print(\"Corrupted answer:\", corrupted_answer)\n",
    "    clean_index = model.to_single_token(clean_answer)\n",
    "    corrupted_index = model.to_single_token(corrupted_answer)\n",
    "\n",
    "    clean_diff = clean_logits[0, -1, clean_index] - clean_logits[0, -1, corrupted_index]\n",
    "    corrupted_diff = corrupted_logits[0, -1, clean_index] - corrupted_logits[0, -1, corrupted_index]\n",
    "\n",
    "    clean_tokens = model.to_tokens(clean_prompt)\n",
    "    corrupted_tokens= model.to_tokens(corrupted_prompt)\n",
    "    num_positions = len(model.to_tokens(clean_prompt)[0])\n",
    "\n",
    "    assert len(clean_tokens[0]) == len(corrupted_tokens[0]), \"The prompts must have the same number of tokens.\"\n",
    "\n",
    "   \n",
    "    patching_result = torch.zeros((model.cfg.n_layers, num_positions), device=model.cfg.device)\n",
    "    for layer in tqdm.tqdm(range(model.cfg.n_layers)):\n",
    "        for position in range(num_positions):\n",
    "            # We use a temporary hook with functool.partial to patch at each position\n",
    "            temp_hook = partial(activation_patching_hook, position=position, clean_cache=clean_cache)\n",
    "            # We then run the model with hooks as usual\n",
    "            patched_logits = model.run_with_hooks(corrupted_tokens, \n",
    "                                                  fwd_hooks=[(utils.get_act_name(\"resid_pre\", layer), temp_hook)])\n",
    "            \n",
    "            # We then calculate the logit difference\n",
    "            patched_diff = (patched_logits[0, -1, clean_index] - patched_logits[0, -1, corrupted_index]).detach()\n",
    "            # We then store the result in the patching_result tensor, normalizing it\n",
    "            if abs(clean_diff-corrupted_diff) < 1e-16:\n",
    "                patching_result[layer, position] = 0\n",
    "            else:\n",
    "                patching_result[layer, position] = abs((patched_diff - corrupted_diff) / (clean_diff - corrupted_diff))\n",
    "    print(patched_logits.shape)\n",
    "    return patching_result, patched_logits\n",
    "\n",
    "def activation_patching_mult(model, clean_prompt, corrupted_prompt, clean_answer, corrupted_answer):\n",
    "    ''' \n",
    "    Performs activation patching on prompts with multi-word answers by using separate run-throughs.\n",
    "    The answers must have the same number of tokens\n",
    "    '''\n",
    "    patching_result = []\n",
    "    patched_logits = []\n",
    "    clean_answers_tokens = model.to_str_tokens(clean_answer)[1:]\n",
    "    corrupted_answers_tokens = model.to_str_tokens(corrupted_answer)[1:]\n",
    "    print(\"Number of run throughs:\", len(clean_answers_tokens))\n",
    "    for i in range(len(clean_answers_tokens)):\n",
    "        p_result, p_logits = activation_patching(model, clean_prompt, corrupted_prompt, \n",
    "                                                 clean_answers_tokens[0], corrupted_answers_tokens[0])\n",
    "        patching_result.append(p_result)\n",
    "        patched_logits.append(p_logits)\n",
    "        clean_prompt += clean_answers_tokens[0]\n",
    "        clean_answers_tokens = clean_answers_tokens[1:]\n",
    "        corrupted_prompt += corrupted_answers_tokens[0]\n",
    "        corrupted_answers_tokens = corrupted_answers_tokens[1:]\n",
    "\n",
    "    return patching_result, patched_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2adeec",
   "metadata": {},
   "source": [
    "Following from the previous examples, our clean prompt is the same as earlier. We choose the corrupted prompt very similarly, with only one key difference, and make sure that they have the same number of tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15878051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<|endoftext|>', 'The', ' capital', ' city', ' of', ' France', ' is', ' called'], ['<|endoftext|>', ' Paris']]\n",
      "[['<|endoftext|>', 'The', ' capital', ' city', ' of', ' Italy', ' is', ' called'], ['<|endoftext|>', ' Rome']]\n"
     ]
    }
   ],
   "source": [
    "clean_prompt = \"The capital city of France is called\"\n",
    "clean_answer = \" Paris\"\n",
    "corrupted_prompt = \"The capital city of Italy is called\"\n",
    "corrupted_answer = \" Rome\"\n",
    "\n",
    "# To determine the function used, we print the tokens\n",
    "print(model.to_str_tokens([clean_prompt, clean_answer]))\n",
    "print(model.to_str_tokens([corrupted_prompt, corrupted_answer]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc4613a",
   "metadata": {},
   "source": [
    "We see that the answers to both prompts are a single token. Hence, we use the function corresponding to single-token answers.\n",
    "\n",
    "We then check if the model can, in fact, predict the correct answers to the prompt. We use the same function as in the preliminary section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d67f183b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', 'The', ' capital', ' city', ' of', ' France', ' is', ' called']\n",
      "Tokenized answer: [' Paris']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.32</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.26</span><span style=\"font-weight: bold\">% Token: | Paris|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m14.32\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m8.26\u001b[0m\u001b[1m% Token: | Paris|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 14.32 Prob:  8.26% Token: | Paris|\n",
      "Top 1th token. Logit: 13.79 Prob:  4.86% Token: | Marse|\n",
      "Top 2th token. Logit: 13.78 Prob:  4.81% Token: | the|\n",
      "Top 3th token. Logit: 13.71 Prob:  4.49% Token: | \"|\n",
      "Top 4th token. Logit: 12.99 Prob:  2.17% Token: | La|\n",
      "Top 5th token. Logit: 12.68 Prob:  1.61% Token: | '|\n",
      "Top 6th token. Logit: 12.66 Prob:  1.57% Token: | Mont|\n",
      "Top 7th token. Logit: 12.60 Prob:  1.48% Token: | St|\n",
      "Top 8th token. Logit: 12.59 Prob:  1.46% Token: | Saint|\n",
      "Top 9th token. Logit: 12.30 Prob:  1.09% Token: | V|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Paris'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' Paris'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', 'The', ' capital', ' city', ' of', ' Italy', ' is', ' called']\n",
      "Tokenized answer: [' Rome']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.02</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.08</span><span style=\"font-weight: bold\">% Token: | Rome|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m14.02\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m6.08\u001b[0m\u001b[1m% Token: | Rome|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 14.02 Prob:  6.08% Token: | Rome|\n",
      "Top 1th token. Logit: 13.98 Prob:  5.81% Token: | the|\n",
      "Top 2th token. Logit: 13.42 Prob:  3.32% Token: | Milan|\n",
      "Top 3th token. Logit: 13.28 Prob:  2.89% Token: | \"|\n",
      "Top 4th token. Logit: 12.80 Prob:  1.79% Token: | Florence|\n",
      "Top 5th token. Logit: 12.59 Prob:  1.45% Token: | Naples|\n",
      "Top 6th token. Logit: 12.56 Prob:  1.40% Token: | '|\n",
      "Top 7th token. Logit: 12.47 Prob:  1.28% Token: | T|\n",
      "Top 8th token. Logit: 12.45 Prob:  1.26% Token: | Pal|\n",
      "Top 9th token. Logit: 12.43 Prob:  1.24% Token: | St|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Rome'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' Rome'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.test_prompt(clean_prompt, clean_answer, model)\n",
    "utils.test_prompt(corrupted_prompt, corrupted_answer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88296715",
   "metadata": {},
   "source": [
    "As the predictions are correct for both prompts, we can continue in our example. We do, however, note that the probabilities are still quite low for both answers, which could influence the results somewhat.\n",
    "\n",
    "Continuing, we then perform activation patching on the two prompts using the functions defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99327ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean answer:  Paris\n",
      "Corrupted answer:  Rome\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324c012a6aae4785b08e20c6245addb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 50257])\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Position: %{x}<br>Layer: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "x": [
          "<|endoftext|>_0",
          "The_1",
          " capital_2",
          " city_3",
          " of_4",
          " Italy_5",
          " is_6",
          " called_7"
         ],
         "xaxis": "x",
         "yaxis": "y",
         "z": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAIA/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANjYfj9OwBs6zYuzOgAAAAAAAAAAAAAAAAAAAAAAAAAAq65+P4+hQDq5+tE6AAAAAAAAAAAAAAAAAAAAAAAAAADQWX4/CXOGOvgxNDsAAAAAAAAAAAAAAAAAAAAAAAAAAIllfT/KefY5wg09OwAAAAAAAAAAAAAAAAAAAAAAAAAA3DZ+PyMAdTi+yDY7AAAAAAAAAAAAAAAAAAAAAAAAAAB8UH4/7soMOYE/0zoAAAAAAAAAAAAAAAAAAAAAAAAAAM2bej8ORu45cPOGOwAAAAAAAAAAAAAAAAAAAAAAAAAAp/R5P5zb3jrLhdA7AAAAAAAAAAAAAAAAAAAAAAAAAADfZVc/tsIeOr+WqD0AAAAAAAAAAAAAAAAAAAAAAAAAABHDAT8x3pA7HVsEPwAAAAAAAAAAAAAAAAAAAAAAAAAA882YPekOjTs3gXY/",
          "dtype": "f4",
          "shape": "12, 8"
         }
        }
       ],
       "layout": {
        "coloraxis": {
         "cmid": 0,
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Patching Results"
        },
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "title": {
          "text": "Position"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Layer"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "patching_results = activation_patching(model, clean_prompt, corrupted_prompt, clean_answer, corrupted_answer)\n",
    "imshow_patching_result(model, patching_results, corrupted_prompt, corrupted_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9d1155",
   "metadata": {},
   "source": [
    "We can clearly see a change in the logit difference depending on which layer and token we patch. We also see that at layer 9 and 10 (0-indexed), the information from the country token is communicated to the last token, not affecting the intermediate tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea63192",
   "metadata": {},
   "source": [
    "### Logit Lens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29044ab7",
   "metadata": {},
   "source": [
    "In this section we want to demonstrate Logit Lens, a technique used to see how a prediction changes throughout the model. TransformerLens has functionality for accessing the accumulated residual stack at each layer, which we will use to retrieve the logits. We will then apply a layer norm to these values to account for fact that this usually happens after the last layer. Lastly, we will compute the logit difference and find the top predicted token for each position at each layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b172ad42",
   "metadata": {},
   "source": [
    "We choose the same, repeating prompt as earlier, this time we let the last token be a separate object. We also run through the model again to make sure we cache the non-hooked activations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18edbf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18])\n",
      "tensor(13)\n",
      "torch.Size([1, 18, 50257])\n"
     ]
    }
   ],
   "source": [
    "repeated_tokens = model.to_tokens(repeated_prompt)\n",
    "rep_answer_token = repeated_tokens[0][-1]\n",
    "repeated_tokens = repeated_tokens[0][:-1]\n",
    "print(repeated_tokens.shape)\n",
    "print(rep_answer_token)\n",
    "\n",
    "logits, cache = model.run_with_cache(repeated_tokens)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23d66e6",
   "metadata": {},
   "source": [
    "We will now access the accumulated residual stack and apply a layer norm. Also, we must unembed the vectors by multiplying by the unembedding matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea9b950f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 1, 18, 768])\n",
      "torch.Size([13, 18, 50257])\n"
     ]
    }
   ],
   "source": [
    "acc_resid_stack = cache.accumulated_resid()\n",
    "scaled_resid_stack = cache.apply_ln_to_stack(acc_resid_stack)\n",
    "print(scaled_resid_stack.shape)\n",
    "\n",
    "unembedding_matrix = model.W_U\n",
    "logit_lens_final_logits = einops.einsum(scaled_resid_stack, unembedding_matrix,\n",
    "                                        \"n_layer ... pos n_dim, n_dim vocab -> n_layer pos vocab\")\n",
    "print(logit_lens_final_logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95a7b3c",
   "metadata": {},
   "source": [
    "We will now compute the logit difference between the intermediate logits and the final prediction logits, as well as convert them to their corresponding top token. Then, we will plot development of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "078e8fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Tokens: %{x}<br>Layers: %{y}<br>Logits: %{z}<extra></extra>",
         "name": "0",
         "text": [
          [
           "theless",
           " capital",
           " city",
           " destro",
           " France",
           " destro",
           " called",
           " Paris",
           " challeng",
           " destro",
           " capital",
           " city",
           " destro",
           " France",
           " destro",
           " called",
           " Paris"
          ],
          [
           "ories",
           " capital",
           "scape",
           " course",
           " Marse",
           " unlikely",
           " called",
           " Paris",
           " They",
           "resa",
           " capital",
           "scape",
           " course",
           " Marse",
           " unlikely",
           " called",
           " Paris"
          ],
          [
           "ories",
           " capital",
           "scape",
           " course",
           " Connection",
           " unlikely",
           " called",
           " Hilton",
           " They",
           "resa",
           " capital",
           "scape",
           " course",
           " Marse",
           " now",
           " called",
           " Hilton"
          ],
          [
           "ories",
           " capital",
           "scape",
           " course",
           " Telecom",
           " unlikely",
           " called",
           " Hilton",
           " However",
           "resa",
           " capital",
           "scape",
           " course",
           " Connection",
           " now",
           " called",
           " Hilton"
          ],
          [
           "resa",
           " capital",
           "wide",
           " Dam",
           " Alps",
           " now",
           " called",
           " Hilton",
           " Its",
           "resa",
           " capital",
           "scape",
           " course",
           " Alps",
           " currently",
           " Call",
           " Hilton"
          ],
          [
           "resa",
           " punishment",
           "scape",
           " Towns",
           " Alps",
           " now",
           " Call",
           " Hilton",
           " Its",
           "odore",
           " planner",
           "scape",
           " Towns",
           " Alps",
           " now",
           " Call",
           " Hilton"
          ],
          [
           "resa",
           " punishment",
           "scape",
           " Alb",
           " Alps",
           " now",
           " Met",
           " Hilton",
           " Its",
           "resa",
           " city",
           "scape",
           " Governors",
           "'s",
           " currently",
           " Met",
           " Hilton"
          ],
          [
           "resa",
           " city",
           " skyline",
           " Georgia",
           " Alps",
           " officially",
           " \"",
           " Hilton",
           " Its",
           "resa",
           " city",
           "scape",
           " Commerce",
           "'s",
           " located",
           " Rome",
           "gard"
          ],
          [
           "resa",
           " city",
           " skyline",
           " South",
           "'s",
           " officially",
           " upon",
           " Hilton",
           " Its",
           " latest",
           " city",
           "scape",
           " France",
           " is",
           " called",
           " Paris",
           "gard"
          ],
          [
           "resa",
           " city",
           " skyline",
           " China",
           "'s",
           " poised",
           " Geneva",
           " Hilton",
           " Its",
           " vast",
           " city",
           "scape",
           " France",
           " is",
           " called",
           " Paris",
           "gard"
          ],
          [
           "resa",
           " city",
           " skyline",
           " China",
           " celebrates",
           " poised",
           " Paris",
           " Hilton",
           " Its",
           " city",
           " city",
           " comprises",
           " France",
           " is",
           " called",
           " Paris",
           "."
          ],
          [
           "resa",
           " city",
           " of",
           " Istanbul",
           " has",
           " reeling",
           " Marse",
           " Hilton",
           " Its",
           " capital",
           " city",
           " boasts",
           " France",
           " is",
           " called",
           " Paris",
           "."
          ]
         ],
         "texttemplate": "%{text}",
         "type": "heatmap",
         "x": [
          " capital_1",
          " city_2",
          " of_3",
          " France_4",
          " is_5",
          " called_6",
          " Paris_7",
          "._8",
          "The_9",
          " capital_10",
          " city_11",
          " of_12",
          " France_13",
          " is_14",
          " called_15",
          " Paris_16",
          "._17"
         ],
         "xaxis": "x",
         "yaxis": "y",
         "z": {
          "bdata": "AAAAgAJH2z8AAADAiAPxPwAAAKDA3OM/AAAAQIVx1j8AAACg3Y7pPwAAAABNd9g/AAAAYC103z8AAACA0KjvPwAAAIAtWdc/AAAAwOk63D8AAACgqOjqPwAAAAAQVuA/AAAAIKuc1z8AAADAjOHjPwAAAIBFJNw/AAAAAABS3z8AAAAgcj3oPwAAAMBMwfc/AAAA4EAdDkAAAAAAWfkDQAAAAAAGi/g/AAAAQPmRBUAAAADAnlb4PwAAAICSOvs/AAAAwFxwDEAAAADAfG33PwAAAICF+fk/AAAAoCKNBkAAAADg4QkBQAAAAGCnd/c/AAAAQKb/AkAAAAAgzA/6PwAAAAApjfk/AAAAgGa4BkAAAAAA9uH5PwAAAKAUPxFAAAAAYHjTBkAAAABAN/n6PwAAAKBVEwZAAAAAoLe8/D8AAADAZLj/PwAAAABoHhFAAAAAYNi/+j8AAABAPj0AQAAAAAB7ygdAAAAAgKUMA0AAAABANhf5PwAAAACheQBAAAAA4D8l/T8AAAAgxeD7PwAAACApaghAAAAAQOwC/j8AAAAATwYUQAAAAKAXiQpAAAAAIJYX/z8AAACA8oIIQAAAAOA2T/4/AAAA4N2tAUAAAAAAZPwTQAAAAOBGS/0/AAAAYGGBAEAAAABAIRwKQAAAAIAsqgZAAAAAoOqR/T8AAABgGdEBQAAAAIAiqP8/AAAAIMmo/j8AAADA10IMQAAAAMC0hwBAAAAAQF/kFEAAAADANC4NQAAAAMC4tAFAAAAA4DpNDEAAAADA5E4BQAAAACAmqAFAAAAAQMmiFUAAAAAATXQCQAAAAMA8FwRAAAAAoIcsCUAAAAAAecEGQAAAACCdhABAAAAA4NzBBEAAAADAUbgBQAAAAMAG+vw/AAAAQO/HDkAAAABADg0EQAAAAMCFDhJAAAAAoAJ9DUAAAABgPycEQAAAAEDJMg5AAAAA4M2KA0AAAAAA4RoDQAAAAEBqjhVAAAAAIFfzBUAAAABAtXYGQAAAAIB++wdAAAAAAKM1CUAAAAAAeA0CQAAAAADjdgVAAAAAwG+/AkAAAABAoLH/PwAAAOBDyQ5AAAAAoFtPCEAAAAAAY88SQAAAAEDuNRFAAAAAQH0IBUAAAABgUTsQQAAAAAAylQZAAAAAQFhbBUAAAADg0PYWQAAAAMCjfAxAAAAAgC7kCEAAAACAIz8PQAAAAKAlFQ1AAAAAgGvPAkAAAAAAmqgGQAAAAKARTAVAAAAAAJjQBEAAAADgrBsQQAAAAID2Ug1AAAAAwKESFkAAAAAA5/UVQAAAAEBrrQ5AAAAAwLsqEUAAAABAKaEKQAAAAMD+BQZAAAAAQEj2F0AAAACA1z4TQAAAACDVXwpAAAAAACsiE0AAAADgr9oPQAAAAAAoLglAAAAAgDIqCkAAAABgVkQLQAAAAKBC7AZAAAAAAC9aEkAAAABgG4wRQAAAAODtZhlAAAAAQP0IGUAAAADAGg0RQAAAAID1qBJAAAAAgDRwEEAAAADg1qcKQAAAAIBreBtAAAAAQI0NFkAAAAAAZn0MQAAAAGAZaxxAAAAAQNB2E0AAAABACs4VQAAAAACqLxNAAAAAgC5oFkAAAACABqoSQAAAAEDTORRAAAAAYLxcFEAAAADAu+kdQAAAACD58BtAAAAAAOneFkAAAAAgZ0QVQAAAAABelxVAAAAAQOciEkAAAAAgYuYhQAAAAACG7xtAAAAAYKPBEUAAAAAAE8ogQAAAAEDg6hVAAAAAoA5KGkAAAABgUWQaQAAAAIDk8iBAAAAAIHQgFEAAAACAnREaQAAAAACG6BhAAAAAwCfYIUAAAADAz5odQAAAAECgcSBAAAAAgDX2GUAAAADAzqQcQAAAAIAOGx9AAAAAoEtOJEAAAADA2ZwiQAAAAAAZNBtAAAAAIJdGJUAAAADA33ocQAAAAOBh1SVAAAAAoEvWIUAAAAAAyY0pQAAAAEDKniBAAAAAAL7HIEAAAACAV8ocQAAAAABGMiZAAAAAIMO5I0AAAADgroEmQAAAAGCPZSNAAAAAwJ4zI0AAAACggQcpQAAAACCk7yVAAAAAYCZoJ0AAAADA5kIjQAAAAEDmxilAAAAAoMyPI0AAAAAAGgYwQAAAAOAHRydAAAAAIGYNMEAAAADAMg0rQAAAACCTWSFA",
          "dtype": "f8",
          "shape": "12, 17"
         }
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Logits"
          }
         },
         "colorscale": [
          [
           0,
           "#0d0887"
          ],
          [
           0.1111111111111111,
           "#46039f"
          ],
          [
           0.2222222222222222,
           "#7201a8"
          ],
          [
           0.3333333333333333,
           "#9c179e"
          ],
          [
           0.4444444444444444,
           "#bd3786"
          ],
          [
           0.5555555555555556,
           "#d8576b"
          ],
          [
           0.6666666666666666,
           "#ed7953"
          ],
          [
           0.7777777777777778,
           "#fb9f3a"
          ],
          [
           0.8888888888888888,
           "#fdca26"
          ],
          [
           1,
           "#f0f921"
          ]
         ]
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Development of predicted next tokens",
         "x": 0.5
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Tokens"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Layers"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logits_final = []\n",
    "inter_tokens = []\n",
    "indices_all = []\n",
    "\n",
    "for layer in range(model.cfg.n_layers):\n",
    "    # Converting to probabilities\n",
    "    probs = logit_lens_final_logits[layer].softmax(dim=-1)\n",
    "    top_prob, indices = probs.topk(1)\n",
    "    \n",
    "    indices_all.append(indices)\n",
    "    logits_final.append([logit_lens_final_logits[layer, i, index].item() \n",
    "                         for i, index in enumerate(indices)])\n",
    "    top_tokens = [model.to_string(index.item()) for index in indices]\n",
    "    inter_tokens.append(top_tokens)\n",
    "\n",
    "logit_diff_results = torch.zeros(model.cfg.n_layers, len(repeated_tokens))\n",
    "answer_tokens = repeated_tokens.tolist()[1:] + [rep_answer_token]\n",
    "answers_str_tokens = [f'{model.to_string(answer)}_{ids}' for ids, answer in enumerate(answer_tokens)]\n",
    "\n",
    "for layer in range(model.cfg.n_layers):\n",
    "    for position in range(len(logit_lens_final_logits[0])):\n",
    "        logit_diff_results[layer][position] = logits[0, position, answer_tokens[position]] \n",
    "        - logit_lens_final_logits[layer, position, indices_all[layer][position][0]]\n",
    "logits_final = np.array(logits_final)\n",
    "answers_str_tokens = np.array(answers_str_tokens)\n",
    "\n",
    "fig = px.imshow(logits_final[:,1:], labels=dict(x='Tokens', y='Layers', color='Logits'), \n",
    "                x=answers_str_tokens[1:], aspect='auto')\n",
    "fig.update_traces(text=[tokens[1:] for tokens in inter_tokens], texttemplate='%{text}')\n",
    "fig.update_layout(title_text=\"Development of predicted next tokens\", title_x=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40efe6dc",
   "metadata": {},
   "source": [
    "We can see that although the model is quite small, it gives sensible predictions in most cases. We also see that for the second repeated sequence, it performs significantly better than the first half. The answers get much better after the fifth and seventh layer, consistent with the induction heads we found in an earlier section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cdb3d5",
   "metadata": {},
   "source": [
    "## Causal scrubbing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65210ba",
   "metadata": {},
   "source": [
    "In this last section, we will briefly go through our incomplete attempt at implementing causal scrubbing. The implementation follows the pseudocode provided by Redwood Research, found [here](https://www.lesswrong.com/posts/JvZhhzycHu2Yd57RN/causal-scrubbing-a-method-for-rigorously-testing). \n",
    "\n",
    "We define the following:\n",
    "- $G$, the computational graph of the model, that is, a set of nodes $n_G$ (heads in attention an MLP fx) and a set of the connections, ie computations, between them.\n",
    "- $D$, the dataset. This contains all data we want to test the hypothesis on, ie. the relevant sentences.\n",
    "- $h$, the hypothesis. This is a tuple $(G, I, c)$, where $I$ is the hypothesized important graph and $c:I\\to G$ is an injective correspondence function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6235a3d6",
   "metadata": {},
   "source": [
    "First, we need some additional imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5cda950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93380a0f",
   "metadata": {},
   "source": [
    "We then construct a Node class, representing the idea of a single node in our computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c98aad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    '''\n",
    "    A class to represent the idea of a node in the neural network. \n",
    "    '''\n",
    "    def __init__(self, layer: int, head: int, model):\n",
    "        self.layer = layer\n",
    "        self.head = head\n",
    "        self.model = model\n",
    "\n",
    "    def parents(self):\n",
    "        parent_list = []\n",
    "        for i in range(self.layer):\n",
    "            for j in range(self.head):\n",
    "                parent_list.append(Node(i, j, self.model))\n",
    "        return parent_list\n",
    "\n",
    "    def value_on(self, x: str) -> torch.tensor:\n",
    "        logits, _ = self.model.run_with_cache(x)\n",
    "        return logits[self.layer, self.head]\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.layer, self.head\n",
    "    \n",
    "    def value_from_inputs(self, inputs, text):\n",
    "        self.model.reset_hooks()\n",
    "        self.model.cfg.use_attn_result = True\n",
    "\n",
    "        def exchange_activations_attn(result, hook, inputs, layer, pos):\n",
    "            print(result.shape)\n",
    "            result[hook.name][...]\n",
    "            for position in range(self.head):\n",
    "                print(layer, \"---\", position)\n",
    "                result[layer, position, :] = inputs[layer, position]\n",
    "            return result\n",
    "        \n",
    "        tokens = self.model.to_tokens(text)\n",
    "        print(inputs)\n",
    "        for i in range(self.layer):\n",
    "            for j in range(self.head):\n",
    "                temp_hook = partial(exchange_activations_attn, inputs=inputs, layer=i, pos=j)\n",
    "                self.model.add_hook(f\"blocks.{i}.attn.hook_result\", temp_hook)\n",
    "        logits = self.model(tokens)\n",
    "        self.model.reset_hooks()\n",
    "        return [logits[0, -1, :]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db049883",
   "metadata": {},
   "source": [
    "We also need a class for the hypothesis we want to test. We then have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "704d55de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hypothesis:\n",
    "    def __init__(self, G: list[tuple[int]], I: list[tuple[int]], c: callable, model):\n",
    "        self.G = G\n",
    "        self.I = I \n",
    "        self.c = c\n",
    "        self.model = model\n",
    "\n",
    "    def set_domain(self, D: list[str]):\n",
    "        self.D = D\n",
    "\n",
    "    #def set_model(self, model):\n",
    "        #self.model = model\n",
    "\n",
    "    def c_image(self, set: list[Node]) -> list[Node]:\n",
    "        if isinstance(set, Node):\n",
    "            return self.c(set)\n",
    "    \n",
    "        image = list(map(self.c, set))\n",
    "        return image\n",
    "    \n",
    "    def c_preimage(self, set: Union[list[Node], Node]) -> list[Node]:\n",
    "        preimage = []\n",
    "        for node in self.I:\n",
    "            if isinstance(set, Node):\n",
    "                if self.c(node) == set:\n",
    "                    preimage.append(node)\n",
    "            else:\n",
    "                if self.c(node) in set:\n",
    "                    preimage.append(node)\n",
    "        return preimage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2547d2",
   "metadata": {},
   "source": [
    "We then want a function giving us a random sample that agrees on the given output. Note that we have no way to be sure if this actually exists. An approximate answer could be a good solution, but this is not included in our work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a955b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_agreeing_x(D: list[str], n_I: Node, ref_x: str) -> str:\n",
    "    '''Returns random sample input that agrees on the specified node.'''\n",
    "    D_agree = [x for x in D if n_I.value_on(ref_x) == n_I.value_on(x)]\n",
    "    return random.choice(D_agree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daef663f",
   "metadata": {},
   "source": [
    "The main idea of this method is the sscrubbing of a graph, which follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6ae181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scrub(h: Hypothesis, D: list[str], n_I: Union[Node, tuple[int]], ref_x: str):\n",
    "    '''\n",
    "    Return the output after a scrub changing all activation of unimportant nodes.\n",
    "\n",
    "    Param:\n",
    "    c (callable): The hypothesis correspondence\n",
    "    D (list[list]): A list of all possible inputs in the domain.\n",
    "    n_I (tuple[int]): The node in question\n",
    "    ref_x (list): The reference input\n",
    "    '''\n",
    "    model = h.model\n",
    "    h.set_domain(D)\n",
    "\n",
    "    if isinstance(n_I, tuple):\n",
    "        n_I = Node(*n_I, model)\n",
    "\n",
    "    # The corresponding main node\n",
    "    n_G = h.c(n_I)\n",
    "\n",
    "    if (n_G.layer, n_G.head) == (0,0):\n",
    "        return model(ref_x)[0, 0, -1]\n",
    "    \n",
    "    inputs_G = torch.zeros(model.cfg.n_layers, model.cfg.n_heads, model.cfg.d_vocab)\n",
    "    \n",
    "    # We pick a random sample to use as the exchange values for the unimportant nodes\n",
    "    random_x = random.choice(D)\n",
    "\n",
    "    # Get scrubbed activations for the inputs to n_G\n",
    "    for parent_G in n_G.parents():\n",
    "        # \"important\" parents\n",
    "        if parent_G in h.c_image(n_I.parents()):\n",
    "            parent_I = h.c_preimage(parent_G)\n",
    "\n",
    "            # Sample new input that agrees on the interpretation node\n",
    "            new_x = sample_agreeing_x(D, parent_I, ref_x)\n",
    "\n",
    "            # Get the scrubbed activations\n",
    "            inputs_G[*parent_G(), :] = run_scrub(h, D, parent_I, new_x)\n",
    "        \n",
    "        # \"unimportant\" parents\n",
    "        else:\n",
    "            # get activations on the random input value chosen\n",
    "            inputs_G[*parent_G(), :] = parent_G.value_on(random_x)\n",
    "    print(inputs_G, \"hei\")\n",
    "    # run n_G given the computed input activation\n",
    "    return n_G.value_from_inputs(inputs_G, ref_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892022e3",
   "metadata": {},
   "source": [
    "Lastly, we need a function to estimate the performance of the hypothesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e4e3a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function estimating the output from a scrubbed model\n",
    "def estimate(h: Hypothesis, D: list[str]):\n",
    "    _G, I, c = h.G, h.I, h.c\n",
    "    outs = []\n",
    "    for i in range(len(I)):\n",
    "        x = random.choice(D)\n",
    "        outs.append(run_scrub(h, D, I[i], x))\n",
    "    return torch.mean(torch.tensor(outs), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec849652",
   "metadata": {},
   "source": [
    "What follows is an example of what a hypothesis and method run-through might look like, but we keep in mind that this causes an error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98fba4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]]) hei\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "tensor([[[ 7.5261, 11.1214,  7.8919,  ..., -3.1299, -3.3873,  8.5934],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]) hei\n",
      "tensor([[[ 7.5261, 11.1214,  7.8919,  ..., -3.1299, -3.3873,  8.5934],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])\n",
      "torch.Size([1, 2, 12, 768])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 4",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m I = [(\u001b[32m1\u001b[39m,\u001b[32m0\u001b[39m), (\u001b[32m1\u001b[39m,\u001b[32m1\u001b[39m)]\n\u001b[32m      7\u001b[39m h = Hypothesis(G, I, \u001b[38;5;28;01mlambda\u001b[39;00m x: x, model)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m estimate(h, text)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mestimate\u001b[39m\u001b[34m(h, D)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(I)):\n\u001b[32m      6\u001b[39m     x = random.choice(D)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     outs.append(run_scrub(h, D, I[i], x))\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.mean(torch.tensor(outs), \u001b[32m1\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36mrun_scrub\u001b[39m\u001b[34m(h, D, n_I, ref_x)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28mprint\u001b[39m(inputs_G, \u001b[33m\"\u001b[39m\u001b[33mhei\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# run n_G given the computed input activation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m n_G.value_from_inputs(inputs_G, ref_x)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mNode.value_from_inputs\u001b[39m\u001b[34m(self, inputs, text)\u001b[39m\n\u001b[32m     40\u001b[39m         temp_hook = partial(exchange_activations_attn, inputs=inputs, layer=i, pos=j)\n\u001b[32m     41\u001b[39m         \u001b[38;5;28mself\u001b[39m.model.add_hook(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mblocks.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.attn.hook_result\u001b[39m\u001b[33m\"\u001b[39m, temp_hook)\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.model(tokens)\n\u001b[32m     43\u001b[39m \u001b[38;5;28mself\u001b[39m.model.reset_hooks()\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [logits[\u001b[32m0\u001b[39m, -\u001b[32m1\u001b[39m, :]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\transformer_lens\\HookedTransformer.py:612\u001b[39m, in \u001b[36mHookedTransformer.forward\u001b[39m\u001b[34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[39m\n\u001b[32m    607\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    608\u001b[39m         shortformer_pos_embed = shortformer_pos_embed.to(\n\u001b[32m    609\u001b[39m             devices.get_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m.cfg)\n\u001b[32m    610\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m612\u001b[39m     residual = block(\n\u001b[32m    613\u001b[39m         residual,\n\u001b[32m    614\u001b[39m         \u001b[38;5;66;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;00m\n\u001b[32m    615\u001b[39m         \u001b[38;5;66;03m# block\u001b[39;00m\n\u001b[32m    616\u001b[39m         past_kv_cache_entry=past_kv_cache[i] \u001b[38;5;28;01mif\u001b[39;00m past_kv_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    617\u001b[39m         shortformer_pos_embed=shortformer_pos_embed,\n\u001b[32m    618\u001b[39m         attention_mask=attention_mask,\n\u001b[32m    619\u001b[39m     )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    622\u001b[39m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m residual\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\transformer_lens\\components\\transformer_block.py:160\u001b[39m, in \u001b[36mTransformerBlock.forward\u001b[39m\u001b[34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[39m\n\u001b[32m    153\u001b[39m     key_input = attn_in\n\u001b[32m    154\u001b[39m     value_input = attn_in\n\u001b[32m    156\u001b[39m attn_out = (\n\u001b[32m    157\u001b[39m     \u001b[38;5;66;03m# hook the residual stream states that are used to calculate the\u001b[39;00m\n\u001b[32m    158\u001b[39m     \u001b[38;5;66;03m# queries, keys and values, independently.\u001b[39;00m\n\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     \u001b[38;5;28mself\u001b[39m.attn(\n\u001b[32m    161\u001b[39m         query_input=\u001b[38;5;28mself\u001b[39m.ln1(query_input)\n\u001b[32m    162\u001b[39m         + (\u001b[32m0.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m shortformer_pos_embed),\n\u001b[32m    163\u001b[39m         key_input=\u001b[38;5;28mself\u001b[39m.ln1(key_input)\n\u001b[32m    164\u001b[39m         + (\u001b[32m0.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m shortformer_pos_embed),\n\u001b[32m    165\u001b[39m         value_input=\u001b[38;5;28mself\u001b[39m.ln1(value_input),\n\u001b[32m    166\u001b[39m         past_kv_cache_entry=past_kv_cache_entry,\n\u001b[32m    167\u001b[39m         attention_mask=attention_mask,\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    169\u001b[39m )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cfg.use_normalization_before_and_after:\n\u001b[32m    171\u001b[39m     \u001b[38;5;66;03m# If we use LayerNorm both before and after, then apply the second LN after the layer\u001b[39;00m\n\u001b[32m    172\u001b[39m     \u001b[38;5;66;03m# and before the hook. We do it before the hook so hook_attn_out captures \"that which\u001b[39;00m\n\u001b[32m    173\u001b[39m     \u001b[38;5;66;03m# is added to the residual stream\"\u001b[39;00m\n\u001b[32m    174\u001b[39m     attn_out = \u001b[38;5;28mself\u001b[39m.ln1_post(attn_out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\transformer_lens\\components\\abstract_attention.py:318\u001b[39m, in \u001b[36mAbstractAttention.forward\u001b[39m\u001b[34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask, attention_mask, position_bias)\u001b[39m\n\u001b[32m    315\u001b[39m         \u001b[38;5;66;03m# Multiply the z tensor by the W_O tensor, summing over the d_head dimension\u001b[39;00m\n\u001b[32m    316\u001b[39m         unhooked_result = (z * w).sum(-\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m         result = \u001b[38;5;28mself\u001b[39m.hook_result(unhooked_result)  \u001b[38;5;66;03m# [batch, pos, head_index, d_model]\u001b[39;00m\n\u001b[32m    319\u001b[39m     out = (\n\u001b[32m    320\u001b[39m         einops.reduce(result, \u001b[33m\"\u001b[39m\u001b[33mbatch position index model->batch position model\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msum\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    321\u001b[39m         + \u001b[38;5;28mself\u001b[39m.b_O\n\u001b[32m    322\u001b[39m     )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1857\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1854\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1856\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1857\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1859\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1860\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1861\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1862\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1818\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1816\u001b[39m     hook_result = hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[32m   1817\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1818\u001b[39m     hook_result = hook(\u001b[38;5;28mself\u001b[39m, args, result)\n\u001b[32m   1820\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1821\u001b[39m     result = hook_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\transformer_lens\\hook_points.py:109\u001b[39m, in \u001b[36mHookPoint.add_hook.<locals>.full_hook\u001b[39m\u001b[34m(module, module_input, module_output)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    106\u001b[39m     \u001b[38;5;28mdir\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33mbwd\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    107\u001b[39m ):  \u001b[38;5;66;03m# For a backwards hook, module_output is a tuple of (grad,) - I don't know why.\u001b[39;00m\n\u001b[32m    108\u001b[39m     module_output = module_output[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m hook(module_output, hook=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mNode.value_from_inputs.<locals>.exchange_activations_attn\u001b[39m\u001b[34m(result, hook, inputs, layer, pos)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexchange_activations_attn\u001b[39m(result, hook, inputs, layer, pos):\n\u001b[32m     29\u001b[39m     \u001b[38;5;28mprint\u001b[39m(result.shape)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     result[hook.name][...]\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m position \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.head):\n\u001b[32m     32\u001b[39m         \u001b[38;5;28mprint\u001b[39m(layer, \u001b[33m\"\u001b[39m\u001b[33m---\u001b[39m\u001b[33m\"\u001b[39m, position)\n",
      "\u001b[31mIndexError\u001b[39m: too many indices for tensor of dimension 4"
     ]
    }
   ],
   "source": [
    "text = [\"hello\", \"hei\", \"hallo\", \"hi\"]\n",
    "G = []\n",
    "for i in range(model.cfg.n_layers):\n",
    "    for j in range(model.cfg.n_heads):\n",
    "        G.append((i,j))\n",
    "I = [(1,0), (1,1)]\n",
    "h = Hypothesis(G, I, lambda x: x, model)\n",
    "\n",
    "estimate(h, text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
