{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f40587e",
   "metadata": {},
   "source": [
    "**This file contains i) overview of project desctiption, ii) general questions and thoughts, iii) a glossary of terms, iv) some of the resources/articles we consulted in the early phase of the work (which may not all have made it into the final report as citations).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a52941",
   "metadata": {},
   "source": [
    "## Overview\n",
    " - We are testing the waters; trying out methods, libraries and examples.\n",
    " - Recording our findings as we go, we aim to create an overview of some important methods in mechanistic interpretability. Hopefully, we can make some sort of lookup table or flow chart.\n",
    "\n",
    "\n",
    "## End product/deliverables\n",
    "3 main things (by mid/late August)\n",
    "1. Presentation of our results and process - 20min\n",
    "2. Write a rapport - do not underestimate the time this takes\n",
    "    - What is a circuit?\n",
    "    - How do we find a circuit? : First general (attr. patching), then zoom in (act. pt. and path pt.)\n",
    "    - How do we verify a circuit? : Still a very new field, but causal scrubbing best so far\n",
    "3. Computational essay - \"a guide\" = flow chart, we might (update: definitely) need separate sections\n",
    "    - One file which contains out functions, preferably gathered in classes wrt the different type of models or packages.\n",
    "    - A notebook with well-suited examples of the functions in action. In the same order/gen. structure as the rapport?\n",
    "\n",
    "## Who to ask\n",
    "Helene back 7th July, Ane leaves thursday afternoon and back 11th July, but be efficient\n",
    "\n",
    "\n",
    "## Questions\n",
    "\n",
    "- Jina AI (encoder-style transformers / non-causal) tilfredsstiller ikke antagelsene i TransformerLens (non-causal, post-layer norm, mm.), og det ser ikke ut som det er enkelt å lage en wrapper. Men Captum ser ut til å kunne gjøre noe (ihvertfall attribution) og circuitsvis ser veldig bra ut.\n",
    "\n",
    "- Interpretability er (antagelig) vanskeligere når outputtet ikke er human-interpretable - f.eks. fordi det ikke finnes noe \"riktig\" output (slik som \"The capitol of Norway is ...\", som lar oss enkelt lage corrupted prompts for activation patching i Gpt-style modeller; \"The capitol of Sweden is ...\" - kanksje må vi bruke causal tracing i stedet, det gir ca. samme info, men uten behov for corrupted prompt). \n",
    "\n",
    "- Når modellen gir kontinuerlig output i stedet for diskret blir det vel mye vanskeligere å separere ut enkle circuits - om vi endrer inputtet litt kan andre circuits forskyve output i rommet, og fordi vi ikke har en forståelse av hva forskyvningen betyr kan vi ikke isolere som i \"capitol of ...\"-eksempelet. (Dessuten vil hele tekster kanksje inneholde mye mer interferens, men enkle strukturer som \"er en vitenskapelig artikkel / har abstract/intro/metode...\" bøør vel være mulig)\n",
    "\n",
    "- Har vi dessuten en naturlig metrikk for å måle hvor mye outputtet har endret seg? Vi bør se på tapsfunksjonen for Jina AI for å finne noe rimelig (vi har altså ikke logits, med mindre vi trener og legger til noe alla et QA-lag ytterst)\n",
    "\n",
    "- Kanksje er 'universality' i mindre grad sant for disse modellene da de ikke har en tydelig fasit, og da blir det vanskelig å generalisere fra den konkrete modellen (spesielt vil treningsdata definere om modellen fokuserer på strukturer i teksten eller tema i teksten, etc., når den legger tekster nærme hverandre... \"some models might be topic-sensitive while others are structure-sensitive\")\n",
    "\n",
    "- Vil skrive kode som lar deg enkelt utføre: Ablation og activation patching på Jina AI. Vi må finne en god metrikk for encoder-only modeller, og vi må bruke modellens base-output som baseline. (Kanskje dette bare er å implementere causal scrubbing med \"expected loss recovered, ie “what fraction of the expected loss on the subproblem we’re studying does our scrubbed circuit recover, compared to the original model with no edits”\")\n",
    "\n",
    "- Har vi funnet noen circuits fra før i Jina AI som vi kan teste på? Det er ikke klart at de fra GPT-stil transformers også dukker opp her (hverken previous token heads, pga. ALiBi, eller induction heads, pga. non-causal), men kanksje vi finner andre... MLP-circuits er ikke nødvendig vis annerledes.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Ane\n",
    "\n",
    "\n",
    "Kan du si litt om hvordan du vil bruke notebooken? Eventuelt, prosjektbeskrivelse?\n",
    "\n",
    "Skal vi gjøre *circuit detection* eller *interventions på pre-etablerte circuits*?\n",
    "\n",
    "Hva bør input/output i notebooken være? \n",
    "\n",
    "Er det et spesifikt datasett vi bør analysere? En bestemt modell? \n",
    "\n",
    "Jina AI er encoder only / ikke kompatibel med tranformer_lens / naiv neuronpedia-implementering. Stemmer det at det er slike modeller du er interessert i? Har du noen ideer til metrikker (vi har jo ikke logits i slike modeller).\n",
    "\n",
    "-Er vi opptatt av embeddingene til tekstene i det semantiske rommet (og bruker sammenhengen mellom embeddingene til å si noe om kretsene?)\n",
    "\n",
    "-Attribution: man bruker en enkelt verdi (eg. classification)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1b0365",
   "metadata": {},
   "source": [
    "## Glossary\n",
    "\n",
    "**Transformers**\n",
    "- Causal/autoregressive: Uses only previous tokens for prediction, achieved by masking the attention pattern.\n",
    "- Logits: Output vector (length d_vocab) after unembedding but before softmax.\n",
    "- LayerNorm: After transformer block we translate by mean value and normalize (to get variance 1, NB - this is non-linear) adding robustness param $\\epsilon$, and then multiply by weights and add a bias, before passing on to next block.\n",
    "- Attend to: We say that position $k$ attends to position $q$ if the corresp. attention pattern value is large.\n",
    "- Residual stream: Main channel in transformer diagram, tracking the cumulative sum giving the updated embedding vector.\n",
    "\n",
    "- Transformer config:\n",
    "    * batch: input index in batch.\n",
    "    * position: token position.\n",
    "    * d_model: residual stream/embedding dimension\n",
    "    * d_vocab: vocab size\n",
    "    * n_ctx: context size\n",
    "    * d_head: dimension of key/query space in attention head\n",
    "    * d_mlp: mpl hidden layer size (4 x d_model)\n",
    "    * n_heads: number of attention heads (d_model/d_head)\n",
    "    * n_layers: number of layers\n",
    "- Transformer params:\n",
    "    * LayerNorm weights and biases\n",
    "    * $W_E$: Embedding matrix (d_vocab, d_model)\n",
    "    * $W_p$: Position embedding matrix, to give sequential information (n_ctx, d_model)\n",
    "    * $W_U$: Unembedding matrix (d_model, d_vocab) [we may include bias to allow folding in LayerNorm]\n",
    "\n",
    "    * W_{QK}: (product of two matrices - important for interpretability as the component-entries are entangled)\n",
    "        * $W_Q$: Query matrix, for each head in each layer (n_heads, d_model, d_head)¨\n",
    "        * $W_K$: Key matrix (n_heads, d_model, d_head)\n",
    "    * W_{VO}:\n",
    "        * $W_{V\\downarrow}$ and $W_{O\\uparrow}$: Value matrix (decomposed) (n_heads, d_model, d_head) and (n_heads, d_head, d_model)\n",
    "    * Attention biases\n",
    "\n",
    "    * MLP weights and biases (two layers / one hidden layer)\n",
    "\n",
    "**Mech Interp**\n",
    "\n",
    "*General hypotheses/concepts*\n",
    "- Linear representation hypothesis (LH): LLMs choose to use (only) linear representations: Features correspond to directions (Nodes are basis vectors (because of non-linear activations picking out these as a privileged direction), and directions are linear combinations of them)\n",
    "- Superposition: The model knows more concepts (features) than basis directions, hence each node encodes multiple concepts - we thus do not expect features to be represented by a single basis vector (challenge for interpretability). The number of almost orthogonal directions grows exponentially with dimension, so there is room for as many concepts as one would ever want in large models with minimal interference.\n",
    "    - Polysemanticity: A single neuron looks for several (completely unrelated) things (eg for a visual model: cat faces, car fronts and cat legs - we know they are independent by feature visualisation). [Speculative: We want to 'unfold' polysemanticity with SAEs, decomposing into interpretable features in a higher dim space?]\n",
    "- Universality (UH): Analagous features and circuits form across models and tasks (and even in biological brains). Mech Interp goal: 'Periodic table of features/circuits'. If untrue, Mech Interp will fail/should only focus on concrete models of high societal importance, but it seems mostly true.\n",
    "\n",
    "\n",
    "*Methods/keywords*\n",
    "- Activation patching: To identify important model activations, we define a performance metric and make a clean and a corrupted prompt, and pick a specific model activation. We run the model on the corrupted prompt, but intervene on the activation with the clean prompt values to see how much of original performance is restored by this activation.\n",
    "\n",
    "- Attribution: the process of determining which parts of a model (tokens, features, neurons) are responsible for a given output. \n",
    "- Intervention: the act of changing the internal components of a model (like features or activations) to see how output changes.\n",
    "- Hook point: Allows us to intervene/edit the corresp. activation. We apply a hook function which replaces the model activation with our desired intervention (the function output). We can extract an activation by returning nothing on the hook.\n",
    "- Ablation/knockout: 'deleting' one activation (zero/mean/random ablation are different approaches)\n",
    "- Toy model: Simple / very small model for easy interpretability.\n",
    "\n",
    "- TransformerLens: Nanda's library for Mech Interp on GPT2-style LMs, specifically accessing/editing hook points in models ([demo](https://colab.research.google.com/github/neelnanda-io/TransformerLens/blob/main/demos/Main_Demo.ipynb#scrollTo=Eo1vbABrq9Ba)).\n",
    "\n",
    "*Concepts*\n",
    "- Features: Directions in semantic space / idealised nodes - a basic concept the model has grasped.\n",
    "- Circuits: Connection of features by weights to grasp complex concepts (eg car = wheel + body + windows + doors etc.). Tightly linked features making a subgraph.\n",
    "    - Ex: curve detectors, consisting of mulitple units to span all orientations, can be viewed as one idealised node; a feature, whcich later feeds into circuits which do eg circle detection.\n",
    "- Feature visualisation: By using gradient descent with cost function maximizing the firing of a (known) feature/circuit, we can tweak the model input to maximally represent the feature (this uses LH, and gives a causal link).\n",
    "- Feature implementation: A known circuit can be reimplemented by hand - if the behaviour remains, it is an isolated algorithm, like we want.\n",
    "\n",
    "*Circuits* (sufficiently small subgraphs that one can make falsafiable predictions and reconstruct by hand)\n",
    "- Motifs: Recurring abstract patterns in circuits such as equivariance, superposition, unioning:\n",
    "\n",
    "    - Equivariant circuits: Exhibit a symmetry in the weights corresponding to a symmetry in the problem to be solved. For instance, a curve detector (orientation invariant) is composed of directed curve detectors, and these are essentially rotations of each other.\n",
    "\n",
    "    - Unioning over cases: Often a concept is the union of several cases, eg the concept curve/dog is orientation invariant. The network might separately detect either (inhibiting each other on the way, XOR-properties) and then unionize at the end to get at the general concept.\n",
    "\n",
    "    - Phenomenon superposition: A pure neuron is pushed forward to the output through superpositions to save on neurons (rather than keeping a separate 'trivial' stream encoding dog - dog - dog - ... until the output). Superposition is most useful when the concepts are mostly separate, so that the model can retrieve the correct concept without interference.\n",
    "\n",
    "- Induction circuits: Circuit to detect/continue repeated subsequences. Composed of two consecutive heads (previous token head + induction head, which attends to the next token after previous instance of current token). Work for arbitrary length patterns. Not to hard to find, since they attend to tokens with same spacing.\n",
    "\n",
    "-Advanced indexing: can use lists as indices in a tensor. \n",
    "\n",
    "\n",
    "**Jina AI** (BERT-style)\n",
    "- non-causal encoder-style with contrastive training using a mean pooling layer ([arXiv](https://arxiv.org/pdf/2310.19923))\n",
    "- NO positional embeddings, instead mirrored ALiBi (attention with linear bias)\n",
    "- GLU for the FFNN (elementwise sigmoid - not sure of the details of the diffenrence, but it is wider (less interpretable?) than the std mlp archit.)\n",
    "- post-layer normalization only\n",
    "- In GPT-style, you get predicitons for all \n",
    "\n",
    "- Next-token prediction er et diskret problem, mens encoding er kontinuerlig - vi finner ikke analoger til induction circuits, der neste token i et repetert mønster er heldeterminert av en enkel induksjonskrets. \n",
    "- Blir PAD-tokens relevant i non-causal attention?\n",
    "- Can we find few-shot learning heads?\n",
    "\n",
    "\n",
    "- polysemanticity = standard basis is non-interpretable\n",
    "- superposition = there is no interpretable basis (it is over-complete)\n",
    "- Neurons and heads are distinct - in the computation graph view (feature graph), they may both be included."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5577c5",
   "metadata": {},
   "source": [
    "## Articles/Resources\n",
    "\n",
    "- Arena tutorials: https://arena3-chapter1-transformer-interp.streamlit.app/[1.2]_Intro_to_Mech_Interp\n",
    "\n",
    "- Neel Nanda Quickstart Guide\n",
    "- Neel Nanda Reading List\n",
    "\n",
    "-Neel nanda glossary: https://www.neelnanda.io/mechanistic-interpretability/glossary\n",
    "\n",
    "\n",
    "Demos/tutorials for neuronpedia: \n",
    "\n",
    "\n",
    "- Artikkel: https://transformer-circuits.pub/2025/attribution-graphs/biology.html\n",
    "\n",
    "- Github: https://github.com/safety-research/circuit-tracer?tab=readme-ov-file\n",
    "\n",
    "- Intervention demo: https://github.com/safety-research/circuit-tracer/blob/main/demos/intervention_demo.ipynb\n",
    "- Attribution demo: https://github.com/safety-research/circuit-tracer/blob/main/demos/attribute_demo.ipynb\n",
    "- Circuit tracing tutorial: https://github.com/safety-research/circuit-tracer/blob/main/demos/circuit_tracing_tutorial.ipynb\n",
    "\n",
    "\n",
    "- Exploration demo: https://colab.research.google.com/github/neelnanda-io/TransformerLens/blob/main/demos/Exploratory_Analysis_Demo.ipynb\n",
    "\n",
    "-TransformerLens activation and path patching (Neel Nanda): https://arena3-chapter1-transformer-interp.streamlit.app/[1.4.1]_Indirect_Object_Identification\n",
    "\n",
    "-Logit lens: https://www.alignmentforum.org/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens\n",
    "\n",
    "\n",
    "-Activation patching: https://arxiv.org/pdf/2404.15255\n",
    "\n",
    "-Dataset: https://huggingface.co/datasets/cindermond/bento/blob/e45bde13c992895825817b84a4c47dd4c53b7152/agieval_reduced/aqua-rat/test.jsonl\n",
    "https://gitlab.info.uqam.ca/guite-vinet.julien/inf7470-project2/-/blob/master/src/data/AQuA-master/test.tok.json\n",
    "https://github.com/google-deepmind/AQuA/blob/master/test.tok.json\n",
    "\n",
    "\n",
    "-Source code, transformers.modeling_bert: \n",
    "https://huggingface.co/transformers/v2.1.1/_modules/transformers/modeling_bert.html?utm_source=chatgpt.com\n",
    "\n",
    "-Path patching: https://github.com/callummcdougall/SERIMATS_app/blob/main/path_patching.py\n",
    "https://github.com/callummcdougall/path_patching\n",
    "\n",
    "https://colab.research.google.com/drive/1yV6czsp9EWWGORRIeGrdQDdJJ8b7EI4n#scrollTo=Uejux10Bl6mW\n",
    "https://colab.research.google.com/drive/15CJ1WAf8AWm6emI3t2nVfnO85-hxwyJU#scrollTo=Zx2LqFhJXxhw\n",
    "Interpretability in the wild: https://arxiv.org/pdf/2211.00593\n",
    "\n",
    "-Semantic search: https://www.sbert.net/examples/sentence_transformer/applications/semantic-search/README.html\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-Mechanistic interpretability for AI safety: https://leonardbereska.github.io/blog/2024/mechinterpreview/\n",
    "\n",
    "-Attribution pathcing: https://www.neelnanda.io/mechanistic-interpretability/attribution-patching\n",
    "- Demo: https://colab.research.google.com/github/neelnanda-io/TransformerLens/blob/main/demos/Attribution_Patching_Demo.ipynb\n",
    "\n",
    "-Causal scrubbing: https://www.alignmentforum.org/posts/JvZhhzycHu2Yd57RN/causal-scrubbing-a-method-for-rigorously-testing\n",
    "\n",
    "-ACDC: https://arxiv.org/pdf/2304.14997\n",
    "\n",
    "TODO\n",
    "- pysvelte interactive visualisations / attention patterns\n",
    "- Neel Nanda reading list (2024, potentially outdated): https://www.alignmentforum.org/posts/NfFST5Mio7BCAQHPA/an-extremely-opinionated-annotated-list-of-my-favourite-1\n",
    "    - Sparse autoencoders\n",
    "    - Circuits\n",
    "  - Arena tutorials?\n",
    "  - Neel Nanda videos\n",
    "- Weekend: Start coding/implementing\n",
    "\n",
    "- Attribution: https://arxiv.org/pdf/1703.01365\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIbase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
