{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "144ce5e8",
   "metadata": {},
   "source": [
    "# Q&A example with TransformerLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbdbc421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import circuitsvis as cv\n",
    "\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, FactoredMatrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "import tqdm.auto as tqdm\n",
    "import plotly.express as px\n",
    "\n",
    "from jaxtyping import Float\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "618b204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
    "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
    "\n",
    "def line(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
    "    px.line(utils.to_numpy(tensor), labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
    "\n",
    "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
    "    x = utils.to_numpy(x)\n",
    "    y = utils.to_numpy(y)\n",
    "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27be1018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_attn_patterns(model, text, layers, compact=True):\n",
    "    str_tokens = model.to_str_tokens(text)\n",
    "    logits, cache = model.run_with_cache(text, remove_batch_dim=True)\n",
    "\n",
    "    if compact:\n",
    "        for layer in layers:\n",
    "            attention_pattern = cache[\"pattern\", layer]\n",
    "            display(cv.attention.attention_patterns(tokens=str_tokens, attention=attention_pattern))\n",
    "    \n",
    "    else:\n",
    "        for layer in layers:\n",
    "            attention_pattern = cache[\"pattern\", layer]\n",
    "            display(cv.attention.attention_heads(tokens=str_tokens, attention=attention_pattern))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c7c254",
   "metadata": {},
   "source": [
    "We set our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cdb20fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\"gpt2-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1449c1",
   "metadata": {},
   "source": [
    "We import and embed the example text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2c2de2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n",
      "['0+0=', '1+2=', '2+4=', '3+6=', '4+8=', '5+10=', '6+12=', '7+14=', '8+16=', '9+18=']\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "'''\n",
    "with open(\"Test.json\",\"r\") as infile: \n",
    "    infile.readline()\n",
    "    lines = infile.readlines()\n",
    "    '''\n",
    "\n",
    "with open(\"Test.json\", \"r\") as infile:\n",
    "    data = json.load(infile)\n",
    "\n",
    "#data = [json.loads(line.strip(\"\\n\").rstrip(',').rstrip(\"]\")) for line in lines]\n",
    "\n",
    "questions = [line[\"question\"] for line in data]\n",
    "answers = [line[\"rationale\"] for line in data]\n",
    "\n",
    "#Embedding the questions and answers\n",
    "question_embeds = model.to_tokens(questions)\n",
    "answer_embeds = model.to_tokens(answers)\n",
    "\n",
    "str_questions = model.to_str_tokens(questions)\n",
    "str_answers = model.to_str_tokens(answers)\n",
    "\n",
    "print(len(question_embeds), len(answer_embeds))\n",
    "print(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "829baee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-160e598c-811f\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-160e598c-811f\",\n",
       "      AttentionPatterns,\n",
       "      {\"tokens\": [\"<|endoftext|>\", \"0\", \"+\", \"0\", \"=\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0], [0.9891597628593445, 0.010840212926268578, 0.0, 0.0, 0.0], [0.8966480493545532, 0.0427163690328598, 0.06063550338149071, 0.0, 0.0], [0.8851548433303833, 0.025741858407855034, 0.0726809948682785, 0.016422390937805176, 0.0], [0.5714359283447266, 0.09132212400436401, 0.19835905730724335, 0.07240286469459534, 0.06648008525371552]], [[1.0, 0.0, 0.0, 0.0, 0.0], [0.0028671380132436752, 0.9971328973770142, 0.0, 0.0, 0.0], [0.0006681804079562426, 0.0006948129157535732, 0.9986370205879211, 0.0, 0.0], [0.0010404394706711173, 0.5419923067092896, 0.0012282029492780566, 0.4557391405105591, 0.0], [0.0008445467101410031, 0.0006854899111203849, 0.03564046695828438, 0.00021290591394063085, 0.9626166224479675]], [[1.0, 0.0, 0.0, 0.0, 0.0], [0.9730475544929504, 0.026952486485242844, 0.0, 0.0, 0.0], [0.8931781649589539, 0.061432916671037674, 0.04538885876536369, 0.0, 0.0], [0.7272925972938538, 0.06123005598783493, 0.17107561230659485, 0.040401674807071686, 0.0], [0.7210594415664673, 0.07204141467809677, 0.07926400005817413, 0.04949994757771492, 0.07813514024019241]], [[1.0, 0.0, 0.0, 0.0, 0.0], [0.18119114637374878, 0.8188088536262512, 0.0, 0.0, 0.0], [0.03745585307478905, 0.01766420342028141, 0.9448798894882202, 0.0, 0.0], [0.009712415747344494, 0.22267566621303558, 0.01947314478456974, 0.7481387853622437, 0.0], [0.0294822808355093, 0.023622211068868637, 0.046667344868183136, 0.09546057134866714, 0.8047676086425781]], [[1.0, 0.0, 0.0, 0.0, 0.0], [0.8976199626922607, 0.10237998515367508, 0.0, 0.0, 0.0], [0.5964090824127197, 0.08323649317026138, 0.32035449147224426, 0.0, 0.0], [0.31344544887542725, 0.20004408061504364, 0.2166450172662735, 0.269865483045578, 0.0], [0.49432826042175293, 0.06928491592407227, 0.1609697937965393, 0.07716358453035355, 0.19825342297554016]], [[1.0, 0.0, 0.0, 0.0, 0.0], [0.08274372667074203, 0.9172562956809998, 0.0, 0.0, 0.0], [0.12487166374921799, 0.003526201704517007, 0.8716021776199341, 0.0, 0.0], [0.01102330069988966, 0.574510931968689, 0.00028829489019699395, 0.41417741775512695, 0.0], [0.012569474056363106, 0.011247579008340836, 0.005851686932146549, 0.0048193782567977905, 0.9655119180679321]], [[1.0, 0.0, 0.0, 0.0, 0.0], [0.9638966917991638, 0.03610330447554588, 0.0, 0.0, 0.0], [0.8301544785499573, 0.0636177733540535, 0.10622770339250565, 0.0, 0.0], [0.5439756512641907, 0.09135548770427704, 0.29729515314102173, 0.06737374514341354, 0.0], [0.4876915514469147, 0.09923647344112396, 0.24315625429153442, 0.07081545889377594, 0.0991002693772316]], [[1.0, 0.0, 0.0, 0.0, 0.0], [0.9709039330482483, 0.029096119105815887, 0.0, 0.0, 0.0], [0.4836089313030243, 0.3254626989364624, 0.1909283995628357, 0.0, 0.0], [0.40509575605392456, 0.11874889582395554, 0.28481367230415344, 0.19134163856506348, 0.0], [0.30637040734291077, 0.09529449045658112, 0.17412970960140228, 0.27601006627082825, 0.14819535613059998]], [[1.0, 0.0, 0.0, 0.0, 0.0], [0.9422704577445984, 0.057729512453079224, 0.0, 0.0, 0.0], [0.8342065215110779, 0.04270046576857567, 0.12309300154447556, 0.0, 0.0], [0.6130539774894714, 0.09210546314716339, 0.22341088950634003, 0.07142971456050873, 0.0], [0.2795199453830719, 0.06695786863565445, 0.4311180114746094, 0.04898301884531975, 0.17342112958431244]], [[1.0, 0.0, 0.0, 0.0, 0.0], [0.8820385932922363, 0.1179613545536995, 0.0, 0.0, 0.0], [0.7555484175682068, 0.1569860875606537, 0.08746553957462311, 0.0, 0.0], [0.6106290817260742, 0.13170142471790314, 0.1528821885585785, 0.10478729009628296, 0.0], [0.5562772154808044, 0.13424058258533478, 0.12196172028779984, 0.1104963943362236, 0.07702414691448212]], [[1.0, 0.0, 0.0, 0.0, 0.0], [0.7978128790855408, 0.202187180519104, 0.0, 0.0, 0.0], [0.6486339569091797, 0.11512016505002975, 0.23624585568904877, 0.0, 0.0], [0.3924897611141205, 0.3342163860797882, 0.07724018394947052, 0.19605369865894318, 0.0], [0.46732157468795776, 0.14305149018764496, 0.10477343946695328, 0.07879626750946045, 0.20605729520320892]], [[1.0, 0.0, 0.0, 0.0, 0.0], [0.766453206539154, 0.23354680836200714, 0.0, 0.0, 0.0], [0.7728310227394104, 0.18068861961364746, 0.04648034647107124, 0.0, 0.0], [0.6621089577674866, 0.1401902586221695, 0.050517208874225616, 0.1471835970878601, 0.0], [0.5833333134651184, 0.14076516032218933, 0.061092063784599304, 0.15323396027088165, 0.061575502157211304]]]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x2b822224e60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-ef8654c2-10fd\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-ef8654c2-10fd\",\n",
       "      AttentionPatterns,\n",
       "      {\"tokens\": [\"<|endoftext|>\", \"1\", \"+\", \"2\", \"=\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0], [0.9872710108757019, 0.012728998437523842, 0.0, 0.0, 0.0], [0.9101009368896484, 0.02835373394191265, 0.06154525279998779, 0.0, 0.0], [0.829233705997467, 0.03240637108683586, 0.12042691558599472, 0.017933016642928123, 0.0], [0.5596994757652283, 0.09791040420532227, 0.1942850649356842, 0.08299046754837036, 0.06511468440294266]], [[1.0, 0.0, 0.0, 0.0, 0.0], [0.003795072203502059, 0.9962049126625061, 0.0, 0.0, 0.0], [0.0006679092184640467, 0.0011003856780007482, 0.9982317090034485, 0.0, 0.0], [0.0010826325742527843, 0.013598272576928139, 0.015629148110747337, 0.9696899056434631, 0.0], [0.0008440457750111818, 0.001226973021402955, 0.03561932593584061, 0.0002640008751768619, 0.9620456695556641]], [[1.0, 0.0, 0.0, 0.0, 0.0], [0.9445667862892151, 0.05543322488665581, 0.0, 0.0, 0.0], [0.8745049834251404, 0.08105504512786865, 0.04443993791937828, 0.0, 0.0], [0.5988194942474365, 0.17447686195373535, 0.09442896395921707, 0.13227476179599762, 0.0], [0.6942626237869263, 0.08551467955112457, 0.07631830126047134, 0.06867299973964691, 0.0752313956618309]], [[1.0, 0.0, 0.0, 0.0, 0.0], [0.2637639343738556, 0.7362360954284668, 0.0, 0.0, 0.0], [0.03745085000991821, 0.017795423045754433, 0.9447537064552307, 0.0, 0.0], [0.018399780616164207, 0.0670437142252922, 0.07592573761940002, 0.838630735874176, 0.0], [0.03187906742095947, 0.018793845549225807, 0.05046120285987854, 0.02867397479712963, 0.8701918721199036]], [[1.0, 0.0, 0.0, 0.0, 0.0], [0.9062865972518921, 0.09371338784694672, 0.0, 0.0, 0.0], [0.587710976600647, 0.09660667181015015, 0.31568241119384766, 0.0, 0.0], [0.3755447268486023, 0.17222115397453308, 0.19940818846225739, 0.25282591581344604, 0.0], [0.5077248811721802, 0.07143720984458923, 0.16533218324184418, 0.05187951773405075, 0.20362623035907745]], [[1.0, 0.0, 0.0, 0.0, 0.0], [0.22788019478321075, 0.7721198201179504, 0.0, 0.0, 0.0], [0.12504805624485016, 0.002118498319759965, 0.8728333711624146, 0.0, 0.0], [0.10868213325738907, 0.01135842502117157, 0.0014058664673939347, 0.878553569316864, 0.0], [0.012761140242218971, 0.0007352137472480536, 0.005940916948020458, 0.000328096270095557, 0.9802346229553223]], [[1.0, 0.0, 0.0, 0.0, 0.0], [0.9654070138931274, 0.03459296002984047, 0.0, 0.0, 0.0], [0.830137312412262, 0.06363720446825027, 0.10622550547122955, 0.0, 0.0], [0.5820505023002625, 0.11243720352649689, 0.21838906407356262, 0.08712323009967804, 0.0], [0.5263121128082275, 0.06775940954685211, 0.2624119222164154, 0.036568496376276016, 0.10694807022809982]], [[1.0, 0.0, 0.0, 0.0, 0.0], [0.9809218049049377, 0.019078122451901436, 0.0, 0.0, 0.0], [0.4804436266422272, 0.3298775851726532, 0.18967874348163605, 0.0, 0.0], [0.304563969373703, 0.15698330104351044, 0.3820182681083679, 0.15643438696861267, 0.0], [0.3039604723453522, 0.09384484589099884, 0.1727599948644638, 0.28240513801574707, 0.14702963829040527]], [[1.0, 0.0, 0.0, 0.0, 0.0], [0.8457146286964417, 0.15428532660007477, 0.0, 0.0, 0.0], [0.8102120757102966, 0.07023544609546661, 0.11955245584249496, 0.0, 0.0], [0.3850944936275482, 0.26235726475715637, 0.17991076409816742, 0.172637477517128, 0.0], [0.2427377849817276, 0.1395605057477951, 0.3743869960308075, 0.09271416813135147, 0.15060055255889893]], [[1.0, 0.0, 0.0, 0.0, 0.0], [0.8588211536407471, 0.14117877185344696, 0.0, 0.0, 0.0], [0.7464104890823364, 0.16718192398548126, 0.08640769124031067, 0.0, 0.0], [0.5860289931297302, 0.1644473671913147, 0.12605907022953033, 0.12346448749303818, 0.0], [0.5270518660545349, 0.16005991399288177, 0.11555416882038116, 0.12435651570558548, 0.07297749817371368]], [[1.0, 0.0, 0.0, 0.0, 0.0], [0.7837377190589905, 0.21626225113868713, 0.0, 0.0, 0.0], [0.6191799640655518, 0.15530194342136383, 0.2255181074142456, 0.0, 0.0], [0.4880222678184509, 0.1611311137676239, 0.10218155384063721, 0.24866507947444916, 0.0], [0.44818630814552307, 0.1676366627216339, 0.10048331320285797, 0.08607374876737595, 0.19761992990970612]], [[1.0, 0.0, 0.0, 0.0, 0.0], [0.7410699725151062, 0.2589300572872162, 0.0, 0.0, 0.0], [0.7646116018295288, 0.18940238654613495, 0.045986004173755646, 0.0, 0.0], [0.6684932708740234, 0.16126954555511475, 0.057166486978530884, 0.11307068914175034, 0.0], [0.5873878598213196, 0.16800878942012787, 0.061516694724559784, 0.12108318507671356, 0.062003493309020996]]]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x2b8239a3ec0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis_attn_patterns(model, questions[0], layers=[0])\n",
    "vis_attn_patterns(model, questions[1], layers=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc9d17c",
   "metadata": {},
   "source": [
    "Trying activation patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc528f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean answer logit difference: 3.1147\n",
      "Corrupted answer logit difference: -4.0909\n"
     ]
    }
   ],
   "source": [
    "clean_prompt = \"What is the capital of France?\"\n",
    "corrupted_prompt = \"What is the capital of England?\"\n",
    "\n",
    "clean_answer = \"Paris\"\n",
    "corrupted_answer = \"London\"\n",
    "\n",
    "clean_logits, clean_cache = model.run_with_cache(clean_prompt)\n",
    "corrupted_logits = model(corrupted_prompt)\n",
    "\n",
    "clean_index = model.to_single_token(clean_answer)\n",
    "corrupted_index = model.to_single_token(corrupted_answer)\n",
    "\n",
    "clean_diff = clean_logits[0, -1, clean_index] - clean_logits[0, -1, corrupted_index]\n",
    "print(f\"Clean answer logit difference: {clean_diff:.4f}\")\n",
    "\n",
    "corrupted_diff = corrupted_logits[0, -1, clean_index] - corrupted_logits[0, -1, corrupted_index]\n",
    "print(f\"Corrupted answer logit difference: {corrupted_diff:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0383d40d",
   "metadata": {},
   "source": [
    "Then we want to patch the clean prompt onto the corrupted prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54862200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_patching_hook(resid_pre, hook, position, clean_cache):\n",
    "    clean_activation = clean_cache[hook.name]\n",
    "    resid_pre[:, position, :] = clean_activation[:, position, :]\n",
    "    return resid_pre\n",
    "\n",
    "def model_data(model, prompt):\n",
    "    tokens = model.to_tokens(prompt)\n",
    "    logits, cache = model.run_with_cache(tokens)\n",
    "    return tokens, logits, cache\n",
    "\n",
    "#num_positions = len(model.to_tokens(clean_prompt)[0])\n",
    "#patching_result = torch.zeros((model.cfg.n_layers, num_positions), device=model.cfg.device)\n",
    "\n",
    "def activation_patching(model, clean_prompt, corrupted_prompt, clean_answer, corrupted_answer, store_corrupted_cache=False):\n",
    "    clean_logits, clean_cache = model.run_with_cache(clean_prompt)\n",
    "    if store_corrupted_cache:\n",
    "        corrupted_logits, corrupted_cache = model.run_with_cache(corrupted_prompt, remove_batch_dim=True)\n",
    "    else:\n",
    "        corrupted_logits = model(corrupted_prompt)\n",
    "\n",
    "    clean_index = model.to_single_token(clean_answer)\n",
    "    corrupted_index = model.to_single_token(corrupted_answer)\n",
    "\n",
    "    clean_diff = clean_logits[0, -1, clean_index] - clean_logits[0, -1, corrupted_index]\n",
    "    corrupted_diff = corrupted_logits[0, -1, clean_index] - corrupted_logits[0, -1, corrupted_index]\n",
    "\n",
    "    [corrupted_tokens, clean_tokens] = model.to_tokens([corrupted_prompt, clean_prompt])\n",
    "    num_positions = len(model.to_tokens(clean_prompt)[0])\n",
    "   \n",
    "    patching_result = torch.zeros((model.cfg.n_layers, num_positions), device=model.cfg.device)\n",
    "    for layer in tqdm.tqdm(range(model.cfg.n_layers)):\n",
    "        for position in range(num_positions):\n",
    "            # We use a temporary hook with functool.partial to patch at each position\n",
    "            temp_hook = partial(activation_patching_hook, position=position, clean_cache=clean_cache)\n",
    "            # We then run the model with hooks as usual\n",
    "            patched_logits = model.run_with_hooks(corrupted_tokens, \n",
    "                                                  fwd_hooks=[(utils.get_act_name(\"resid_pre\", layer), temp_hook)])\n",
    "            \n",
    "            # We then calculate the logit difference\n",
    "            patched_diff = (patched_logits[0, -1, clean_index] - patched_logits[0, -1, corrupted_index]).detach()\n",
    "            # We then store the result in the patching_result tensor, normalizing it\n",
    "            if patched_logits[0, -1, corrupted_index]==50256 or patched_logits[0,-1,clean_index]==50256:\n",
    "                patching_result[layer, position] = 0\n",
    "            else:\n",
    "                patching_result[layer, position] = (patched_diff - corrupted_diff) / (clean_diff - corrupted_diff)\n",
    "\n",
    "    if store_corrupted_cache:\n",
    "        return patching_result, patched_logits, corrupted_cache\n",
    "    else:\n",
    "        return patching_result, patched_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "53bd1c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.ln1.hook_scale', 'blocks.0.ln1.hook_normalized', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_z', 'blocks.0.hook_attn_out', 'blocks.0.hook_resid_mid', 'blocks.0.ln2.hook_scale', 'blocks.0.ln2.hook_normalized', 'blocks.0.mlp.hook_pre', 'blocks.0.mlp.hook_post', 'blocks.0.hook_mlp_out', 'blocks.0.hook_resid_post', 'blocks.1.hook_resid_pre', 'blocks.1.ln1.hook_scale', 'blocks.1.ln1.hook_normalized', 'blocks.1.attn.hook_q', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_v', 'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_pattern', 'blocks.1.attn.hook_z', 'blocks.1.hook_attn_out', 'blocks.1.hook_resid_mid', 'blocks.1.ln2.hook_scale', 'blocks.1.ln2.hook_normalized', 'blocks.1.mlp.hook_pre', 'blocks.1.mlp.hook_post', 'blocks.1.hook_mlp_out', 'blocks.1.hook_resid_post', 'blocks.2.hook_resid_pre', 'blocks.2.ln1.hook_scale', 'blocks.2.ln1.hook_normalized', 'blocks.2.attn.hook_q', 'blocks.2.attn.hook_k', 'blocks.2.attn.hook_v', 'blocks.2.attn.hook_attn_scores', 'blocks.2.attn.hook_pattern', 'blocks.2.attn.hook_z', 'blocks.2.hook_attn_out', 'blocks.2.hook_resid_mid', 'blocks.2.ln2.hook_scale', 'blocks.2.ln2.hook_normalized', 'blocks.2.mlp.hook_pre', 'blocks.2.mlp.hook_post', 'blocks.2.hook_mlp_out', 'blocks.2.hook_resid_post', 'blocks.3.hook_resid_pre', 'blocks.3.ln1.hook_scale', 'blocks.3.ln1.hook_normalized', 'blocks.3.attn.hook_q', 'blocks.3.attn.hook_k', 'blocks.3.attn.hook_v', 'blocks.3.attn.hook_attn_scores', 'blocks.3.attn.hook_pattern', 'blocks.3.attn.hook_z', 'blocks.3.hook_attn_out', 'blocks.3.hook_resid_mid', 'blocks.3.ln2.hook_scale', 'blocks.3.ln2.hook_normalized', 'blocks.3.mlp.hook_pre', 'blocks.3.mlp.hook_post', 'blocks.3.hook_mlp_out', 'blocks.3.hook_resid_post', 'blocks.4.hook_resid_pre', 'blocks.4.ln1.hook_scale', 'blocks.4.ln1.hook_normalized', 'blocks.4.attn.hook_q', 'blocks.4.attn.hook_k', 'blocks.4.attn.hook_v', 'blocks.4.attn.hook_attn_scores', 'blocks.4.attn.hook_pattern', 'blocks.4.attn.hook_z', 'blocks.4.hook_attn_out', 'blocks.4.hook_resid_mid', 'blocks.4.ln2.hook_scale', 'blocks.4.ln2.hook_normalized', 'blocks.4.mlp.hook_pre', 'blocks.4.mlp.hook_post', 'blocks.4.hook_mlp_out', 'blocks.4.hook_resid_post', 'blocks.5.hook_resid_pre', 'blocks.5.ln1.hook_scale', 'blocks.5.ln1.hook_normalized', 'blocks.5.attn.hook_q', 'blocks.5.attn.hook_k', 'blocks.5.attn.hook_v', 'blocks.5.attn.hook_attn_scores', 'blocks.5.attn.hook_pattern', 'blocks.5.attn.hook_z', 'blocks.5.hook_attn_out', 'blocks.5.hook_resid_mid', 'blocks.5.ln2.hook_scale', 'blocks.5.ln2.hook_normalized', 'blocks.5.mlp.hook_pre', 'blocks.5.mlp.hook_post', 'blocks.5.hook_mlp_out', 'blocks.5.hook_resid_post', 'blocks.6.hook_resid_pre', 'blocks.6.ln1.hook_scale', 'blocks.6.ln1.hook_normalized', 'blocks.6.attn.hook_q', 'blocks.6.attn.hook_k', 'blocks.6.attn.hook_v', 'blocks.6.attn.hook_attn_scores', 'blocks.6.attn.hook_pattern', 'blocks.6.attn.hook_z', 'blocks.6.hook_attn_out', 'blocks.6.hook_resid_mid', 'blocks.6.ln2.hook_scale', 'blocks.6.ln2.hook_normalized', 'blocks.6.mlp.hook_pre', 'blocks.6.mlp.hook_post', 'blocks.6.hook_mlp_out', 'blocks.6.hook_resid_post', 'blocks.7.hook_resid_pre', 'blocks.7.ln1.hook_scale', 'blocks.7.ln1.hook_normalized', 'blocks.7.attn.hook_q', 'blocks.7.attn.hook_k', 'blocks.7.attn.hook_v', 'blocks.7.attn.hook_attn_scores', 'blocks.7.attn.hook_pattern', 'blocks.7.attn.hook_z', 'blocks.7.hook_attn_out', 'blocks.7.hook_resid_mid', 'blocks.7.ln2.hook_scale', 'blocks.7.ln2.hook_normalized', 'blocks.7.mlp.hook_pre', 'blocks.7.mlp.hook_post', 'blocks.7.hook_mlp_out', 'blocks.7.hook_resid_post', 'blocks.8.hook_resid_pre', 'blocks.8.ln1.hook_scale', 'blocks.8.ln1.hook_normalized', 'blocks.8.attn.hook_q', 'blocks.8.attn.hook_k', 'blocks.8.attn.hook_v', 'blocks.8.attn.hook_attn_scores', 'blocks.8.attn.hook_pattern', 'blocks.8.attn.hook_z', 'blocks.8.hook_attn_out', 'blocks.8.hook_resid_mid', 'blocks.8.ln2.hook_scale', 'blocks.8.ln2.hook_normalized', 'blocks.8.mlp.hook_pre', 'blocks.8.mlp.hook_post', 'blocks.8.hook_mlp_out', 'blocks.8.hook_resid_post', 'blocks.9.hook_resid_pre', 'blocks.9.ln1.hook_scale', 'blocks.9.ln1.hook_normalized', 'blocks.9.attn.hook_q', 'blocks.9.attn.hook_k', 'blocks.9.attn.hook_v', 'blocks.9.attn.hook_attn_scores', 'blocks.9.attn.hook_pattern', 'blocks.9.attn.hook_z', 'blocks.9.hook_attn_out', 'blocks.9.hook_resid_mid', 'blocks.9.ln2.hook_scale', 'blocks.9.ln2.hook_normalized', 'blocks.9.mlp.hook_pre', 'blocks.9.mlp.hook_post', 'blocks.9.hook_mlp_out', 'blocks.9.hook_resid_post', 'blocks.10.hook_resid_pre', 'blocks.10.ln1.hook_scale', 'blocks.10.ln1.hook_normalized', 'blocks.10.attn.hook_q', 'blocks.10.attn.hook_k', 'blocks.10.attn.hook_v', 'blocks.10.attn.hook_attn_scores', 'blocks.10.attn.hook_pattern', 'blocks.10.attn.hook_z', 'blocks.10.hook_attn_out', 'blocks.10.hook_resid_mid', 'blocks.10.ln2.hook_scale', 'blocks.10.ln2.hook_normalized', 'blocks.10.mlp.hook_pre', 'blocks.10.mlp.hook_post', 'blocks.10.hook_mlp_out', 'blocks.10.hook_resid_post', 'blocks.11.hook_resid_pre', 'blocks.11.ln1.hook_scale', 'blocks.11.ln1.hook_normalized', 'blocks.11.attn.hook_q', 'blocks.11.attn.hook_k', 'blocks.11.attn.hook_v', 'blocks.11.attn.hook_attn_scores', 'blocks.11.attn.hook_pattern', 'blocks.11.attn.hook_z', 'blocks.11.hook_attn_out', 'blocks.11.hook_resid_mid', 'blocks.11.ln2.hook_scale', 'blocks.11.ln2.hook_normalized', 'blocks.11.mlp.hook_pre', 'blocks.11.mlp.hook_post', 'blocks.11.hook_mlp_out', 'blocks.11.hook_resid_post', 'ln_final.hook_scale', 'ln_final.hook_normalized']\n",
      "Looking for;  blocks.0.hook_activation\n",
      "Number of positions: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6981a2cc1b48459e726b1456d365c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0, Position 0\n",
      "Layer 0, Position 1\n",
      "Layer 0, Position 2\n",
      "Layer 0, Position 3\n",
      "Layer 0, Position 4\n",
      "Layer 0, Position 5\n",
      "Layer 0, Position 6\n",
      "Layer 0, Position 7\n",
      "Layer 1, Position 0\n",
      "Layer 1, Position 1\n",
      "Layer 1, Position 2\n",
      "Layer 1, Position 3\n",
      "Layer 1, Position 4\n",
      "Layer 1, Position 5\n",
      "Layer 1, Position 6\n",
      "Layer 1, Position 7\n",
      "Layer 2, Position 0\n",
      "Layer 2, Position 1\n",
      "Layer 2, Position 2\n",
      "Layer 2, Position 3\n",
      "Layer 2, Position 4\n",
      "Layer 2, Position 5\n",
      "Layer 2, Position 6\n",
      "Layer 2, Position 7\n",
      "Layer 3, Position 0\n",
      "Layer 3, Position 1\n",
      "Layer 3, Position 2\n",
      "Layer 3, Position 3\n",
      "Layer 3, Position 4\n",
      "Layer 3, Position 5\n",
      "Layer 3, Position 6\n",
      "Layer 3, Position 7\n",
      "Layer 4, Position 0\n",
      "Layer 4, Position 1\n",
      "Layer 4, Position 2\n",
      "Layer 4, Position 3\n",
      "Layer 4, Position 4\n",
      "Layer 4, Position 5\n",
      "Layer 4, Position 6\n",
      "Layer 4, Position 7\n",
      "Layer 5, Position 0\n",
      "Layer 5, Position 1\n",
      "Layer 5, Position 2\n",
      "Layer 5, Position 3\n",
      "Layer 5, Position 4\n",
      "Layer 5, Position 5\n",
      "Layer 5, Position 6\n",
      "Layer 5, Position 7\n",
      "Layer 6, Position 0\n",
      "Layer 6, Position 1\n",
      "Layer 6, Position 2\n",
      "Layer 6, Position 3\n",
      "Layer 6, Position 4\n",
      "Layer 6, Position 5\n",
      "Layer 6, Position 6\n",
      "Layer 6, Position 7\n",
      "Layer 7, Position 0\n",
      "Layer 7, Position 1\n",
      "Layer 7, Position 2\n",
      "Layer 7, Position 3\n",
      "Layer 7, Position 4\n",
      "Layer 7, Position 5\n",
      "Layer 7, Position 6\n",
      "Layer 7, Position 7\n",
      "Layer 8, Position 0\n",
      "Layer 8, Position 1\n",
      "Layer 8, Position 2\n",
      "Layer 8, Position 3\n",
      "Layer 8, Position 4\n",
      "Layer 8, Position 5\n",
      "Layer 8, Position 6\n",
      "Layer 8, Position 7\n",
      "Layer 9, Position 0\n",
      "Layer 9, Position 1\n",
      "Layer 9, Position 2\n",
      "Layer 9, Position 3\n",
      "Layer 9, Position 4\n",
      "Layer 9, Position 5\n",
      "Layer 9, Position 6\n",
      "Layer 9, Position 7\n",
      "Layer 10, Position 0\n",
      "Layer 10, Position 1\n",
      "Layer 10, Position 2\n",
      "Layer 10, Position 3\n",
      "Layer 10, Position 4\n",
      "Layer 10, Position 5\n",
      "Layer 10, Position 6\n",
      "Layer 10, Position 7\n",
      "Layer 11, Position 0\n",
      "Layer 11, Position 1\n",
      "Layer 11, Position 2\n",
      "Layer 11, Position 3\n",
      "Layer 11, Position 4\n",
      "Layer 11, Position 5\n",
      "Layer 11, Position 6\n",
      "Layer 11, Position 7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(list(clean_cache.keys()))\n",
    "print(\"Looking for; \", utils.get_act_name(\"activation\", 0))\n",
    "patching_result = activation_patching(model, clean_prompt, model.to_tokens(corrupted_prompt))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df74147f",
   "metadata": {},
   "source": [
    "We then visualize our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25c46c5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'patching_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m token_labels = [\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoken\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m index, token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(model.to_str_tokens(clean_prompt))]\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m imshow(patching_result, x=token_labels, xaxis=\u001b[33m\"\u001b[39m\u001b[33mPosition\u001b[39m\u001b[33m\"\u001b[39m, yaxis=\u001b[33m\"\u001b[39m\u001b[33mLayer\u001b[39m\u001b[33m\"\u001b[39m, title=\u001b[33m\"\u001b[39m\u001b[33mPatching Result\u001b[39m\u001b[33m\"\u001b[39m,)\n",
      "\u001b[31mNameError\u001b[39m: name 'patching_result' is not defined"
     ]
    }
   ],
   "source": [
    "token_labels = [f'{token}_{index}' for index, token in enumerate(model.to_str_tokens(clean_prompt))]\n",
    "imshow(patching_result, x=token_labels, xaxis=\"Position\", yaxis=\"Layer\", title=\"Patching Result\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b75333f",
   "metadata": {},
   "source": [
    "When patching the clean results onto the corrupted results, the change is first very localized, but is then brought to the end in the last few layers. \n",
    "We now want to try with a more complicated example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89cd6fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_physics_prompt = \"The action of adding numbers is called the\"\n",
    "corrupted_physics_prompt = \"The action of multiplying numbers is called\"\n",
    "clean_answer = \" addition\"\n",
    "corrupted_answer = \" multiplication\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87dc8351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f1f0f3fa3a459dbdee23c00dde0204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', 'The', ' number', ' of', ' seconds', ' in', ' a', ' minute', ' is']\n",
      "Tokenized answer: [' 60']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span><span style=\"font-weight: bold\">      Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.13</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.08</span><span style=\"font-weight: bold\">% Token: | </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m172\u001b[0m\u001b[1m      Logit: \u001b[0m\u001b[1;36m10.13\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.08\u001b[0m\u001b[1m% Token: | \u001b[0m\u001b[1;36m60\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 14.87 Prob:  8.67% Token: | the|\n",
      "Top 1th token. Logit: 14.85 Prob:  8.51% Token: | a|\n",
      "Top 2th token. Logit: 14.00 Prob:  3.64% Token: | one|\n",
      "Top 3th token. Logit: 13.76 Prob:  2.87% Token: | called|\n",
      "Top 4th token. Logit: 13.67 Prob:  2.61% Token: | determined|\n",
      "Top 5th token. Logit: 13.66 Prob:  2.58% Token: | an|\n",
      "Top 6th token. Logit: 13.61 Prob:  2.45% Token: | measured|\n",
      "Top 7th token. Logit: 13.55 Prob:  2.32% Token: | defined|\n",
      "Top 8th token. Logit: 13.34 Prob:  1.88% Token: | equal|\n",
      "Top 9th token. Logit: 13.33 Prob:  1.85% Token: | based|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' 60'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' 60'\u001b[0m, \u001b[1;36m172\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.generate(clean_physics_prompt, max_new_tokens=10, temperature=0.0, top_p=1.0, do_sample=False)\n",
    "utils.test_prompt(clean_physics_prompt, clean_answer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28764a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_patching_result(model, patching_results, clean_prompt, corrupted_prompt):\n",
    "    tokens = model.to_tokens([clean_prompt, corrupted_prompt], padding_side=\"left\")\n",
    "    tokens = model.to_str_tokens(list(tokens))\n",
    "    labels = [f'{token}_{index}' for index, token in enumerate(tokens[1])]\n",
    "    px.imshow(patching_results[0].detach(), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", x=labels, labels={\"x\": \"Position\", \"y\": \"Layer\"}, title=\"Patching Results\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "027c66ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113cc38211eb41ceaa83bad8ea1584ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 7.5261, 11.1214,  7.8919,  ..., -3.1299, -3.3873,  8.5934],\n",
      "         [-0.7078,  1.4936, -0.0422,  ..., -0.3339, -3.6979,  1.6328],\n",
      "         [ 7.2213,  5.8883,  2.3895,  ..., -3.6560,  1.7539,  5.9068],\n",
      "         ...,\n",
      "         [ 5.8745,  5.5437, -1.0836,  ..., -1.5069,  1.5748,  3.5940],\n",
      "         [ 4.1309,  5.9170,  0.8626,  ..., -1.5245, -1.8976,  4.8975],\n",
      "         [ 0.7206,  3.8844,  0.2918,  ..., -0.5576, -2.4410,  2.2923]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[1.5681, 1.5681, 1.5681, 1.5681, 1.6118, 1.5681, 1.5681, 1.5681, 0.3817],\n",
      "        [1.5681, 1.5681, 1.5681, 1.5681, 1.6014, 1.5708, 1.5682, 1.5679, 0.3727],\n",
      "        [1.5681, 1.5681, 1.5681, 1.5681, 1.5977, 1.5686, 1.5682, 1.5679, 0.3526],\n",
      "        [1.5681, 1.5681, 1.5681, 1.5681, 1.6021, 1.5616, 1.5680, 1.5667, 0.3291],\n",
      "        [1.5681, 1.5681, 1.5681, 1.5681, 1.6082, 1.5537, 1.5671, 1.5655, 0.3205],\n",
      "        [1.5681, 1.5681, 1.5681, 1.5681, 1.6026, 1.5551, 1.5669, 1.5651, 0.3074],\n",
      "        [1.5681, 1.5681, 1.5681, 1.5681, 1.6051, 1.5666, 1.5688, 1.5657, 0.3070],\n",
      "        [1.5681, 1.5681, 1.5681, 1.5681, 1.6035, 1.5662, 1.5698, 1.5707, 0.3233],\n",
      "        [1.5681, 1.5681, 1.5681, 1.5681, 1.6002, 1.5657, 1.5694, 1.5714, 0.3570],\n",
      "        [1.5681, 1.5681, 1.5681, 1.5681, 1.5977, 1.5668, 1.5713, 1.5701, 0.4100],\n",
      "        [1.5681, 1.5681, 1.5681, 1.5681, 1.5977, 1.5694, 1.5701, 1.5688, 0.4456],\n",
      "        [1.5681, 1.5681, 1.5681, 1.5681, 1.5912, 1.5702, 1.5698, 1.5692, 0.6321]],\n",
      "       grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "patching_result_physics = activation_patching(model, clean_physics_prompt, corrupted_physics_prompt, clean_answer, corrupted_answer, store_corrupted_cache=True)\n",
    "#print(\"Patching result shape:\", patching_result_physics[1].shape)\n",
    "#token_labels = [f'{token}_{index}' for index, token in enumerate(model.to_str_tokens([corrupted_physics_prompt, clean_physics_prompt])[0])]\n",
    "#imshow_patching_result(patching_result_physics[0], x=token_labels, xaxis=\"Position\", yaxis=\"Layer\", title=\"Patching Result\",)\n",
    "print(patching_result_physics[1])\n",
    "print(patching_result_physics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a0bfe9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5681, 1.5681, 1.5681, 1.5681, 1.6118, 1.5681, 1.5681, 1.5681, 0.3817],\n",
      "        [1.5681, 1.5681, 1.5681, 1.5681, 1.6014, 1.5708, 1.5682, 1.5679, 0.3727],\n",
      "        [1.5681, 1.5681, 1.5681, 1.5681, 1.5977, 1.5686, 1.5682, 1.5679, 0.3526],\n",
      "        [1.5681, 1.5681, 1.5681, 1.5681, 1.6021, 1.5616, 1.5680, 1.5667, 0.3291],\n",
      "        [1.5681, 1.5681, 1.5681, 1.5681, 1.6082, 1.5537, 1.5671, 1.5655, 0.3205],\n",
      "        [1.5681, 1.5681, 1.5681, 1.5681, 1.6026, 1.5551, 1.5669, 1.5651, 0.3074],\n",
      "        [1.5681, 1.5681, 1.5681, 1.5681, 1.6051, 1.5666, 1.5688, 1.5657, 0.3070],\n",
      "        [1.5681, 1.5681, 1.5681, 1.5681, 1.6035, 1.5662, 1.5698, 1.5707, 0.3233],\n",
      "        [1.5681, 1.5681, 1.5681, 1.5681, 1.6002, 1.5657, 1.5694, 1.5714, 0.3570],\n",
      "        [1.5681, 1.5681, 1.5681, 1.5681, 1.5977, 1.5668, 1.5713, 1.5701, 0.4100],\n",
      "        [1.5681, 1.5681, 1.5681, 1.5681, 1.5977, 1.5694, 1.5701, 1.5688, 0.4456],\n",
      "        [1.5681, 1.5681, 1.5681, 1.5681, 1.5912, 1.5702, 1.5698, 1.5692, 0.6321]])\n",
      "[['<|endoftext|>', 'The', ' action', ' of', ' adding', ' numbers', ' is', ' called', ' the'], ['<|endoftext|>', '<|endoftext|>', 'The', ' action', ' of', ' multiplying', ' numbers', ' is', ' called']]\n",
      "['<|endoftext|>_0', '<|endoftext|>_1', 'The_2', ' action_3', ' of_4', ' multiplying_5', ' numbers_6', ' is_7', ' called_8']\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Position: %{x}<br>Layer: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "x": [
          "<|endoftext|>_0",
          "<|endoftext|>_1",
          "The_2",
          " action_3",
          " of_4",
          " multiplying_5",
          " numbers_6",
          " is_7",
          " called_8"
         ],
         "xaxis": "x",
         "yaxis": "y",
         "z": {
          "bdata": "PrjIPz64yD8+uMg/PrjIP7FPzj8+uMg/PrjIPz64yD8EasM+PrjIPz64yD8+uMg/PrjIP2v6zD+UEck/Z7rIPwqxyD8Yz74+PrjIPz64yD8+uMg/PrjIP/KCzD9txsg/+brIP0WwyD8ni7Q+PrjIPz64yD8+uMg/PrjIPw8QzT9i48c/LrTIP/uKyD92eqg+PrjIPz64yD8+uMg/PrjIPy/YzT/s38Y/MJXIP9lgyD9FHqQ+PrjIPz64yD8+uMg/PrjIPx8jzT/pDsc/ppDIP55WyD/uZ50+PrjIPz64yD8+uMg/PrjIP+N0zT9qhcg/1c/IP1hnyD+9LZ0+PrjIPz64yD8+uMg/PrjIPxM+zT/necg/uO3IPxQLyT8GjKU+PrjIPz64yD8+uMg/PrjIPxrSzD8Yasg/t+LIP9EiyT+5xrY+PrjIPz64yD8+uMg/PrjIP/aBzD95jcg/gh/JP3D3yD/x6tE+PrjIPz64yD8+uMg/PrjIP+l/zD8048g/A/nIP13NyD8yJ+Q+PrjIPz64yD8+uMg/PrjIPxKtyz8n/cg/9O7IP8jayD9C0SE/",
          "dtype": "f4",
          "shape": "12, 9"
         }
        }
       ],
       "layout": {
        "coloraxis": {
         "cmid": 0,
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Patching Results"
        },
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "title": {
          "text": "Position"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Layer"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow_patching_result(model, patching_result_physics, clean_physics_prompt, corrupted_physics_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c83eeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache keys: dict_keys(['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.ln1.hook_scale', 'blocks.0.ln1.hook_normalized', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_z', 'blocks.0.hook_attn_out', 'blocks.0.hook_resid_mid', 'blocks.0.ln2.hook_scale', 'blocks.0.ln2.hook_normalized', 'blocks.0.mlp.hook_pre', 'blocks.0.mlp.hook_post', 'blocks.0.hook_mlp_out', 'blocks.0.hook_resid_post', 'blocks.1.hook_resid_pre', 'blocks.1.ln1.hook_scale', 'blocks.1.ln1.hook_normalized', 'blocks.1.attn.hook_q', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_v', 'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_pattern', 'blocks.1.attn.hook_z', 'blocks.1.hook_attn_out', 'blocks.1.hook_resid_mid', 'blocks.1.ln2.hook_scale', 'blocks.1.ln2.hook_normalized', 'blocks.1.mlp.hook_pre', 'blocks.1.mlp.hook_post', 'blocks.1.hook_mlp_out', 'blocks.1.hook_resid_post', 'blocks.2.hook_resid_pre', 'blocks.2.ln1.hook_scale', 'blocks.2.ln1.hook_normalized', 'blocks.2.attn.hook_q', 'blocks.2.attn.hook_k', 'blocks.2.attn.hook_v', 'blocks.2.attn.hook_attn_scores', 'blocks.2.attn.hook_pattern', 'blocks.2.attn.hook_z', 'blocks.2.hook_attn_out', 'blocks.2.hook_resid_mid', 'blocks.2.ln2.hook_scale', 'blocks.2.ln2.hook_normalized', 'blocks.2.mlp.hook_pre', 'blocks.2.mlp.hook_post', 'blocks.2.hook_mlp_out', 'blocks.2.hook_resid_post', 'blocks.3.hook_resid_pre', 'blocks.3.ln1.hook_scale', 'blocks.3.ln1.hook_normalized', 'blocks.3.attn.hook_q', 'blocks.3.attn.hook_k', 'blocks.3.attn.hook_v', 'blocks.3.attn.hook_attn_scores', 'blocks.3.attn.hook_pattern', 'blocks.3.attn.hook_z', 'blocks.3.hook_attn_out', 'blocks.3.hook_resid_mid', 'blocks.3.ln2.hook_scale', 'blocks.3.ln2.hook_normalized', 'blocks.3.mlp.hook_pre', 'blocks.3.mlp.hook_post', 'blocks.3.hook_mlp_out', 'blocks.3.hook_resid_post', 'blocks.4.hook_resid_pre', 'blocks.4.ln1.hook_scale', 'blocks.4.ln1.hook_normalized', 'blocks.4.attn.hook_q', 'blocks.4.attn.hook_k', 'blocks.4.attn.hook_v', 'blocks.4.attn.hook_attn_scores', 'blocks.4.attn.hook_pattern', 'blocks.4.attn.hook_z', 'blocks.4.hook_attn_out', 'blocks.4.hook_resid_mid', 'blocks.4.ln2.hook_scale', 'blocks.4.ln2.hook_normalized', 'blocks.4.mlp.hook_pre', 'blocks.4.mlp.hook_post', 'blocks.4.hook_mlp_out', 'blocks.4.hook_resid_post', 'blocks.5.hook_resid_pre', 'blocks.5.ln1.hook_scale', 'blocks.5.ln1.hook_normalized', 'blocks.5.attn.hook_q', 'blocks.5.attn.hook_k', 'blocks.5.attn.hook_v', 'blocks.5.attn.hook_attn_scores', 'blocks.5.attn.hook_pattern', 'blocks.5.attn.hook_z', 'blocks.5.hook_attn_out', 'blocks.5.hook_resid_mid', 'blocks.5.ln2.hook_scale', 'blocks.5.ln2.hook_normalized', 'blocks.5.mlp.hook_pre', 'blocks.5.mlp.hook_post', 'blocks.5.hook_mlp_out', 'blocks.5.hook_resid_post', 'blocks.6.hook_resid_pre', 'blocks.6.ln1.hook_scale', 'blocks.6.ln1.hook_normalized', 'blocks.6.attn.hook_q', 'blocks.6.attn.hook_k', 'blocks.6.attn.hook_v', 'blocks.6.attn.hook_attn_scores', 'blocks.6.attn.hook_pattern', 'blocks.6.attn.hook_z', 'blocks.6.hook_attn_out', 'blocks.6.hook_resid_mid', 'blocks.6.ln2.hook_scale', 'blocks.6.ln2.hook_normalized', 'blocks.6.mlp.hook_pre', 'blocks.6.mlp.hook_post', 'blocks.6.hook_mlp_out', 'blocks.6.hook_resid_post', 'blocks.7.hook_resid_pre', 'blocks.7.ln1.hook_scale', 'blocks.7.ln1.hook_normalized', 'blocks.7.attn.hook_q', 'blocks.7.attn.hook_k', 'blocks.7.attn.hook_v', 'blocks.7.attn.hook_attn_scores', 'blocks.7.attn.hook_pattern', 'blocks.7.attn.hook_z', 'blocks.7.hook_attn_out', 'blocks.7.hook_resid_mid', 'blocks.7.ln2.hook_scale', 'blocks.7.ln2.hook_normalized', 'blocks.7.mlp.hook_pre', 'blocks.7.mlp.hook_post', 'blocks.7.hook_mlp_out', 'blocks.7.hook_resid_post', 'blocks.8.hook_resid_pre', 'blocks.8.ln1.hook_scale', 'blocks.8.ln1.hook_normalized', 'blocks.8.attn.hook_q', 'blocks.8.attn.hook_k', 'blocks.8.attn.hook_v', 'blocks.8.attn.hook_attn_scores', 'blocks.8.attn.hook_pattern', 'blocks.8.attn.hook_z', 'blocks.8.hook_attn_out', 'blocks.8.hook_resid_mid', 'blocks.8.ln2.hook_scale', 'blocks.8.ln2.hook_normalized', 'blocks.8.mlp.hook_pre', 'blocks.8.mlp.hook_post', 'blocks.8.hook_mlp_out', 'blocks.8.hook_resid_post', 'blocks.9.hook_resid_pre', 'blocks.9.ln1.hook_scale', 'blocks.9.ln1.hook_normalized', 'blocks.9.attn.hook_q', 'blocks.9.attn.hook_k', 'blocks.9.attn.hook_v', 'blocks.9.attn.hook_attn_scores', 'blocks.9.attn.hook_pattern', 'blocks.9.attn.hook_z', 'blocks.9.hook_attn_out', 'blocks.9.hook_resid_mid', 'blocks.9.ln2.hook_scale', 'blocks.9.ln2.hook_normalized', 'blocks.9.mlp.hook_pre', 'blocks.9.mlp.hook_post', 'blocks.9.hook_mlp_out', 'blocks.9.hook_resid_post', 'blocks.10.hook_resid_pre', 'blocks.10.ln1.hook_scale', 'blocks.10.ln1.hook_normalized', 'blocks.10.attn.hook_q', 'blocks.10.attn.hook_k', 'blocks.10.attn.hook_v', 'blocks.10.attn.hook_attn_scores', 'blocks.10.attn.hook_pattern', 'blocks.10.attn.hook_z', 'blocks.10.hook_attn_out', 'blocks.10.hook_resid_mid', 'blocks.10.ln2.hook_scale', 'blocks.10.ln2.hook_normalized', 'blocks.10.mlp.hook_pre', 'blocks.10.mlp.hook_post', 'blocks.10.hook_mlp_out', 'blocks.10.hook_resid_post', 'blocks.11.hook_resid_pre', 'blocks.11.ln1.hook_scale', 'blocks.11.ln1.hook_normalized', 'blocks.11.attn.hook_q', 'blocks.11.attn.hook_k', 'blocks.11.attn.hook_v', 'blocks.11.attn.hook_attn_scores', 'blocks.11.attn.hook_pattern', 'blocks.11.attn.hook_z', 'blocks.11.hook_attn_out', 'blocks.11.hook_resid_mid', 'blocks.11.ln2.hook_scale', 'blocks.11.ln2.hook_normalized', 'blocks.11.mlp.hook_pre', 'blocks.11.mlp.hook_post', 'blocks.11.hook_mlp_out', 'blocks.11.hook_resid_post', 'ln_final.hook_scale', 'ln_final.hook_normalized'])\n",
      "Attention pattern shape: torch.Size([12, 8, 8])\n",
      "ActivationCache with keys ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.ln1.hook_scale', 'blocks.0.ln1.hook_normalized', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_z', 'blocks.0.hook_attn_out', 'blocks.0.hook_resid_mid', 'blocks.0.ln2.hook_scale', 'blocks.0.ln2.hook_normalized', 'blocks.0.mlp.hook_pre', 'blocks.0.mlp.hook_post', 'blocks.0.hook_mlp_out', 'blocks.0.hook_resid_post', 'blocks.1.hook_resid_pre', 'blocks.1.ln1.hook_scale', 'blocks.1.ln1.hook_normalized', 'blocks.1.attn.hook_q', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_v', 'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_pattern', 'blocks.1.attn.hook_z', 'blocks.1.hook_attn_out', 'blocks.1.hook_resid_mid', 'blocks.1.ln2.hook_scale', 'blocks.1.ln2.hook_normalized', 'blocks.1.mlp.hook_pre', 'blocks.1.mlp.hook_post', 'blocks.1.hook_mlp_out', 'blocks.1.hook_resid_post', 'blocks.2.hook_resid_pre', 'blocks.2.ln1.hook_scale', 'blocks.2.ln1.hook_normalized', 'blocks.2.attn.hook_q', 'blocks.2.attn.hook_k', 'blocks.2.attn.hook_v', 'blocks.2.attn.hook_attn_scores', 'blocks.2.attn.hook_pattern', 'blocks.2.attn.hook_z', 'blocks.2.hook_attn_out', 'blocks.2.hook_resid_mid', 'blocks.2.ln2.hook_scale', 'blocks.2.ln2.hook_normalized', 'blocks.2.mlp.hook_pre', 'blocks.2.mlp.hook_post', 'blocks.2.hook_mlp_out', 'blocks.2.hook_resid_post', 'blocks.3.hook_resid_pre', 'blocks.3.ln1.hook_scale', 'blocks.3.ln1.hook_normalized', 'blocks.3.attn.hook_q', 'blocks.3.attn.hook_k', 'blocks.3.attn.hook_v', 'blocks.3.attn.hook_attn_scores', 'blocks.3.attn.hook_pattern', 'blocks.3.attn.hook_z', 'blocks.3.hook_attn_out', 'blocks.3.hook_resid_mid', 'blocks.3.ln2.hook_scale', 'blocks.3.ln2.hook_normalized', 'blocks.3.mlp.hook_pre', 'blocks.3.mlp.hook_post', 'blocks.3.hook_mlp_out', 'blocks.3.hook_resid_post', 'blocks.4.hook_resid_pre', 'blocks.4.ln1.hook_scale', 'blocks.4.ln1.hook_normalized', 'blocks.4.attn.hook_q', 'blocks.4.attn.hook_k', 'blocks.4.attn.hook_v', 'blocks.4.attn.hook_attn_scores', 'blocks.4.attn.hook_pattern', 'blocks.4.attn.hook_z', 'blocks.4.hook_attn_out', 'blocks.4.hook_resid_mid', 'blocks.4.ln2.hook_scale', 'blocks.4.ln2.hook_normalized', 'blocks.4.mlp.hook_pre', 'blocks.4.mlp.hook_post', 'blocks.4.hook_mlp_out', 'blocks.4.hook_resid_post', 'blocks.5.hook_resid_pre', 'blocks.5.ln1.hook_scale', 'blocks.5.ln1.hook_normalized', 'blocks.5.attn.hook_q', 'blocks.5.attn.hook_k', 'blocks.5.attn.hook_v', 'blocks.5.attn.hook_attn_scores', 'blocks.5.attn.hook_pattern', 'blocks.5.attn.hook_z', 'blocks.5.hook_attn_out', 'blocks.5.hook_resid_mid', 'blocks.5.ln2.hook_scale', 'blocks.5.ln2.hook_normalized', 'blocks.5.mlp.hook_pre', 'blocks.5.mlp.hook_post', 'blocks.5.hook_mlp_out', 'blocks.5.hook_resid_post', 'blocks.6.hook_resid_pre', 'blocks.6.ln1.hook_scale', 'blocks.6.ln1.hook_normalized', 'blocks.6.attn.hook_q', 'blocks.6.attn.hook_k', 'blocks.6.attn.hook_v', 'blocks.6.attn.hook_attn_scores', 'blocks.6.attn.hook_pattern', 'blocks.6.attn.hook_z', 'blocks.6.hook_attn_out', 'blocks.6.hook_resid_mid', 'blocks.6.ln2.hook_scale', 'blocks.6.ln2.hook_normalized', 'blocks.6.mlp.hook_pre', 'blocks.6.mlp.hook_post', 'blocks.6.hook_mlp_out', 'blocks.6.hook_resid_post', 'blocks.7.hook_resid_pre', 'blocks.7.ln1.hook_scale', 'blocks.7.ln1.hook_normalized', 'blocks.7.attn.hook_q', 'blocks.7.attn.hook_k', 'blocks.7.attn.hook_v', 'blocks.7.attn.hook_attn_scores', 'blocks.7.attn.hook_pattern', 'blocks.7.attn.hook_z', 'blocks.7.hook_attn_out', 'blocks.7.hook_resid_mid', 'blocks.7.ln2.hook_scale', 'blocks.7.ln2.hook_normalized', 'blocks.7.mlp.hook_pre', 'blocks.7.mlp.hook_post', 'blocks.7.hook_mlp_out', 'blocks.7.hook_resid_post', 'blocks.8.hook_resid_pre', 'blocks.8.ln1.hook_scale', 'blocks.8.ln1.hook_normalized', 'blocks.8.attn.hook_q', 'blocks.8.attn.hook_k', 'blocks.8.attn.hook_v', 'blocks.8.attn.hook_attn_scores', 'blocks.8.attn.hook_pattern', 'blocks.8.attn.hook_z', 'blocks.8.hook_attn_out', 'blocks.8.hook_resid_mid', 'blocks.8.ln2.hook_scale', 'blocks.8.ln2.hook_normalized', 'blocks.8.mlp.hook_pre', 'blocks.8.mlp.hook_post', 'blocks.8.hook_mlp_out', 'blocks.8.hook_resid_post', 'blocks.9.hook_resid_pre', 'blocks.9.ln1.hook_scale', 'blocks.9.ln1.hook_normalized', 'blocks.9.attn.hook_q', 'blocks.9.attn.hook_k', 'blocks.9.attn.hook_v', 'blocks.9.attn.hook_attn_scores', 'blocks.9.attn.hook_pattern', 'blocks.9.attn.hook_z', 'blocks.9.hook_attn_out', 'blocks.9.hook_resid_mid', 'blocks.9.ln2.hook_scale', 'blocks.9.ln2.hook_normalized', 'blocks.9.mlp.hook_pre', 'blocks.9.mlp.hook_post', 'blocks.9.hook_mlp_out', 'blocks.9.hook_resid_post', 'blocks.10.hook_resid_pre', 'blocks.10.ln1.hook_scale', 'blocks.10.ln1.hook_normalized', 'blocks.10.attn.hook_q', 'blocks.10.attn.hook_k', 'blocks.10.attn.hook_v', 'blocks.10.attn.hook_attn_scores', 'blocks.10.attn.hook_pattern', 'blocks.10.attn.hook_z', 'blocks.10.hook_attn_out', 'blocks.10.hook_resid_mid', 'blocks.10.ln2.hook_scale', 'blocks.10.ln2.hook_normalized', 'blocks.10.mlp.hook_pre', 'blocks.10.mlp.hook_post', 'blocks.10.hook_mlp_out', 'blocks.10.hook_resid_post', 'blocks.11.hook_resid_pre', 'blocks.11.ln1.hook_scale', 'blocks.11.ln1.hook_normalized', 'blocks.11.attn.hook_q', 'blocks.11.attn.hook_k', 'blocks.11.attn.hook_v', 'blocks.11.attn.hook_attn_scores', 'blocks.11.attn.hook_pattern', 'blocks.11.attn.hook_z', 'blocks.11.hook_attn_out', 'blocks.11.hook_resid_mid', 'blocks.11.ln2.hook_scale', 'blocks.11.ln2.hook_normalized', 'blocks.11.mlp.hook_pre', 'blocks.11.mlp.hook_post', 'blocks.11.hook_mlp_out', 'blocks.11.hook_resid_post', 'ln_final.hook_scale', 'ln_final.hook_normalized']\n",
      "min: 0.0 max: 1.0 mean: 0.125\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type HookedTransformer is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m attn = patching_result_physics[-\u001b[32m1\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mpattern\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0\u001b[39m]\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mmin:\u001b[39m\u001b[33m\"\u001b[39m, attn.min().item(), \u001b[33m\"\u001b[39m\u001b[33mmax:\u001b[39m\u001b[33m\"\u001b[39m, attn.max().item(), \u001b[33m\"\u001b[39m\u001b[33mmean:\u001b[39m\u001b[33m\"\u001b[39m, attn.mean().item())\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m cv.attention.attention_patterns(model, patching_result_physics[-\u001b[32m1\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\circuitsvis\\attention.py:83\u001b[39m, in \u001b[36mattention_patterns\u001b[39m\u001b[34m(tokens, attention)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mattention_patterns\u001b[39m(\n\u001b[32m     66\u001b[39m     tokens: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m     67\u001b[39m     attention: Union[\u001b[38;5;28mlist\u001b[39m, np.ndarray, torch.Tensor],\n\u001b[32m     68\u001b[39m ) -> RenderedHTML:\n\u001b[32m     69\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Attention Patterns\u001b[39;00m\n\u001b[32m     70\u001b[39m \n\u001b[32m     71\u001b[39m \u001b[33;03m    Visualization of attention head patterns.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     81\u001b[39m \u001b[33;03m        Html: Attention patterns visualization\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m render(\n\u001b[32m     84\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttentionPatterns\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     85\u001b[39m         tokens=tokens,\n\u001b[32m     86\u001b[39m         attention=attention,\n\u001b[32m     87\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\circuitsvis\\utils\\render.py:214\u001b[39m, in \u001b[36mrender\u001b[39m\u001b[34m(react_element_name, **kwargs)\u001b[39m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrender\u001b[39m(\n\u001b[32m    199\u001b[39m     react_element_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    200\u001b[39m     **kwargs: PythonProperty\n\u001b[32m    201\u001b[39m ) -> RenderedHTML:\n\u001b[32m    202\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Render a visualization to HTML\u001b[39;00m\n\u001b[32m    203\u001b[39m \n\u001b[32m    204\u001b[39m \u001b[33;03m    This will show the visualization in Jupyter Lab/Colab by default, and show a\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    212\u001b[39m \u001b[33;03m        Html: HTML for the visualization\u001b[39;00m\n\u001b[32m    213\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     local_src = render_local(react_element_name, **kwargs)\n\u001b[32m    215\u001b[39m     cdn_src = render_cdn(react_element_name, **kwargs)\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m RenderedHTML(local_src, cdn_src)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\circuitsvis\\utils\\render.py:140\u001b[39m, in \u001b[36mrender_local\u001b[39m\u001b[34m(react_element_name, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m uuid = \u001b[33m\"\u001b[39m\u001b[33mcircuits-vis-\u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(uuid4())[:\u001b[32m13\u001b[39m]\n\u001b[32m    139\u001b[39m \u001b[38;5;66;03m# Stringify keyword args\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m props = convert_props(kwargs)\n\u001b[32m    142\u001b[39m \u001b[38;5;66;03m# Build if in dev mode\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_in_dev_mode():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\circuitsvis\\utils\\convert_props.py:62\u001b[39m, in \u001b[36mconvert_props\u001b[39m\u001b[34m(props)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Convert a set of properties to a JavaScript safe string\u001b[39;00m\n\u001b[32m     53\u001b[39m \n\u001b[32m     54\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     58\u001b[39m \u001b[33;03m    str: JavaScript safe properties\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     60\u001b[39m props_with_values = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m props.items() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m json.dumps({k: convert_prop_type(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m props_with_values.items()})\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\json\\__init__.py:231\u001b[39m, in \u001b[36mdumps\u001b[39m\u001b[34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    226\u001b[39m \u001b[38;5;66;03m# cached encoder\u001b[39;00m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m skipkeys \u001b[38;5;129;01mand\u001b[39;00m ensure_ascii \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    228\u001b[39m     check_circular \u001b[38;5;129;01mand\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m separators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    230\u001b[39m     default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort_keys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_encoder.encode(obj)\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONEncoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\json\\encoder.py:200\u001b[39m, in \u001b[36mJSONEncoder.encode\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m chunks = \u001b[38;5;28mself\u001b[39m.iterencode(o, _one_shot=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m    202\u001b[39m     chunks = \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\json\\encoder.py:258\u001b[39m, in \u001b[36mJSONEncoder.iterencode\u001b[39m\u001b[34m(self, o, _one_shot)\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    254\u001b[39m     _iterencode = _make_iterencode(\n\u001b[32m    255\u001b[39m         markers, \u001b[38;5;28mself\u001b[39m.default, _encoder, \u001b[38;5;28mself\u001b[39m.indent, floatstr,\n\u001b[32m    256\u001b[39m         \u001b[38;5;28mself\u001b[39m.key_separator, \u001b[38;5;28mself\u001b[39m.item_separator, \u001b[38;5;28mself\u001b[39m.sort_keys,\n\u001b[32m    257\u001b[39m         \u001b[38;5;28mself\u001b[39m.skipkeys, _one_shot)\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _iterencode(o, \u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\json\\encoder.py:180\u001b[39m, in \u001b[36mJSONEncoder.default\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[32m    162\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m \n\u001b[32m    179\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis not JSON serializable\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Object of type HookedTransformer is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# Want to visualize the attention patterns in the first layerprint(\"Cache keys:\", patching_result_physics[-1].keys())\n",
    "print(\"Cache keys:\", patching_result_physics[-1].keys())\n",
    "print(\"Attention pattern shape:\", patching_result_physics[-1][\"pattern\", 0].shape)\n",
    "print(patching_result_physics[-1])\n",
    "attn = patching_result_physics[-1][\"pattern\", 0]\n",
    "print(\"min:\", attn.min().item(), \"max:\", attn.max().item(), \"mean:\", attn.mean().item())\n",
    "\n",
    "vis_attn_patterns(model, clean_physics_prompt, [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6795e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' \"': 0.1507\n",
      "' the': 0.1075\n",
      "' a': 0.0541\n",
      "\" '\": 0.0192\n",
      "' an': 0.0184\n",
      "' for': 0.0094\n",
      "' as': 0.0065\n",
      "' adding': 0.0062\n",
      "' counting': 0.0060\n",
      "' by': 0.0057\n"
     ]
    }
   ],
   "source": [
    "# What about the probability distribution now?\n",
    "\n",
    "patching_logits = patching_result_physics[1][0, -1, :]\n",
    "# Get the logits for the last position\n",
    "logits = patching_result_physics[1][0, -1, :]  # shape: (vocab_size,)\n",
    "\n",
    "# Convert logits to probabilities\n",
    "probs = logits.softmax(dim=-1)\n",
    "\n",
    "# Get the top 10 token indices and their probabilities\n",
    "top_probs, top_indices = probs.topk(10)\n",
    "\n",
    "# Decode the tokens to strings\n",
    "top_tokens = [model.to_string([idx.item()]) for idx in top_indices]\n",
    "\n",
    "# Print the results\n",
    "for token, prob in zip(top_tokens, top_probs):\n",
    "    print(f\"{token!r}: {prob.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d409d45",
   "metadata": {},
   "source": [
    "This seems to work!!!\n",
    "\n",
    "But can we make a function that does not require the questions to be the same length? And where the answers can be multiple words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37add702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the questions do not have the same length\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4838706e",
   "metadata": {},
   "source": [
    "# Induction heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dca7933a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0+0=\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(question)\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Run with hooks (this is where we write to the `induction_score_store` tensor`)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m model.run_with_hooks(question_token, \n\u001b[32m     35\u001b[39m     return_type=\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m# For efficiency, we don't need to calculate the logits\u001b[39;00m\n\u001b[32m     36\u001b[39m     fwd_hooks=[(\n\u001b[32m     37\u001b[39m         pattern_hook_names_filter,\n\u001b[32m     38\u001b[39m         induction_score_hook\n\u001b[32m     39\u001b[39m     )]\n\u001b[32m     40\u001b[39m )\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m#print(induction_score_store)\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Get the global max value and its flat index\u001b[39;00m\n\u001b[32m     43\u001b[39m max_value = np.max(induction_score_store)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\transformer_lens\\hook_points.py:456\u001b[39m, in \u001b[36mHookedRootModule.run_with_hooks\u001b[39m\u001b[34m(self, fwd_hooks, bwd_hooks, reset_hooks_end, clear_contexts, *model_args, **model_kwargs)\u001b[39m\n\u001b[32m    451\u001b[39m     logging.warning(\n\u001b[32m    452\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWARNING: Hooks will be reset at the end of run_with_hooks. This removes the backward hooks before a backward pass can occur.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    453\u001b[39m     )\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.hooks(fwd_hooks, bwd_hooks, reset_hooks_end, clear_contexts) \u001b[38;5;28;01mas\u001b[39;00m hooked_model:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m hooked_model.forward(*model_args, **model_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\transformer_lens\\HookedTransformer.py:612\u001b[39m, in \u001b[36mHookedTransformer.forward\u001b[39m\u001b[34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[39m\n\u001b[32m    607\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    608\u001b[39m         shortformer_pos_embed = shortformer_pos_embed.to(\n\u001b[32m    609\u001b[39m             devices.get_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m.cfg)\n\u001b[32m    610\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m612\u001b[39m     residual = block(\n\u001b[32m    613\u001b[39m         residual,\n\u001b[32m    614\u001b[39m         \u001b[38;5;66;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;00m\n\u001b[32m    615\u001b[39m         \u001b[38;5;66;03m# block\u001b[39;00m\n\u001b[32m    616\u001b[39m         past_kv_cache_entry=past_kv_cache[i] \u001b[38;5;28;01mif\u001b[39;00m past_kv_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    617\u001b[39m         shortformer_pos_embed=shortformer_pos_embed,\n\u001b[32m    618\u001b[39m         attention_mask=attention_mask,\n\u001b[32m    619\u001b[39m     )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    622\u001b[39m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m residual\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\transformer_lens\\components\\transformer_block.py:160\u001b[39m, in \u001b[36mTransformerBlock.forward\u001b[39m\u001b[34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[39m\n\u001b[32m    153\u001b[39m     key_input = attn_in\n\u001b[32m    154\u001b[39m     value_input = attn_in\n\u001b[32m    156\u001b[39m attn_out = (\n\u001b[32m    157\u001b[39m     \u001b[38;5;66;03m# hook the residual stream states that are used to calculate the\u001b[39;00m\n\u001b[32m    158\u001b[39m     \u001b[38;5;66;03m# queries, keys and values, independently.\u001b[39;00m\n\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     \u001b[38;5;28mself\u001b[39m.attn(\n\u001b[32m    161\u001b[39m         query_input=\u001b[38;5;28mself\u001b[39m.ln1(query_input)\n\u001b[32m    162\u001b[39m         + (\u001b[32m0.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m shortformer_pos_embed),\n\u001b[32m    163\u001b[39m         key_input=\u001b[38;5;28mself\u001b[39m.ln1(key_input)\n\u001b[32m    164\u001b[39m         + (\u001b[32m0.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m shortformer_pos_embed),\n\u001b[32m    165\u001b[39m         value_input=\u001b[38;5;28mself\u001b[39m.ln1(value_input),\n\u001b[32m    166\u001b[39m         past_kv_cache_entry=past_kv_cache_entry,\n\u001b[32m    167\u001b[39m         attention_mask=attention_mask,\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    169\u001b[39m )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cfg.use_normalization_before_and_after:\n\u001b[32m    171\u001b[39m     \u001b[38;5;66;03m# If we use LayerNorm both before and after, then apply the second LN after the layer\u001b[39;00m\n\u001b[32m    172\u001b[39m     \u001b[38;5;66;03m# and before the hook. We do it before the hook so hook_attn_out captures \"that which\u001b[39;00m\n\u001b[32m    173\u001b[39m     \u001b[38;5;66;03m# is added to the residual stream\"\u001b[39;00m\n\u001b[32m    174\u001b[39m     attn_out = \u001b[38;5;28mself\u001b[39m.ln1_post(attn_out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\transformer_lens\\components\\abstract_attention.py:261\u001b[39m, in \u001b[36mAbstractAttention.forward\u001b[39m\u001b[34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask, attention_mask, position_bias)\u001b[39m\n\u001b[32m    259\u001b[39m pattern = F.softmax(attn_scores, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m    260\u001b[39m pattern = torch.where(torch.isnan(pattern), torch.zeros_like(pattern), pattern)\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m pattern = \u001b[38;5;28mself\u001b[39m.hook_pattern(pattern)  \u001b[38;5;66;03m# [batch, head_index, query_pos, key_pos]\u001b[39;00m\n\u001b[32m    262\u001b[39m pattern = pattern.to(\u001b[38;5;28mself\u001b[39m.cfg.dtype)\n\u001b[32m    263\u001b[39m pattern = pattern.to(v.device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1857\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1854\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1856\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1857\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1859\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1860\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1861\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1862\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1818\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1816\u001b[39m     hook_result = hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[32m   1817\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1818\u001b[39m     hook_result = hook(\u001b[38;5;28mself\u001b[39m, args, result)\n\u001b[32m   1820\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1821\u001b[39m     result = hook_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\transformer_lens\\hook_points.py:109\u001b[39m, in \u001b[36mHookPoint.add_hook.<locals>.full_hook\u001b[39m\u001b[34m(module, module_input, module_output)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    106\u001b[39m     \u001b[38;5;28mdir\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33mbwd\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    107\u001b[39m ):  \u001b[38;5;66;03m# For a backwards hook, module_output is a tuple of (grad,) - I don't know why.\u001b[39;00m\n\u001b[32m    108\u001b[39m     module_output = module_output[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m hook(module_output, hook=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36minduction_score_hook\u001b[39m\u001b[34m(activation_pattern, hook)\u001b[39m\n\u001b[32m     26\u001b[39m induction_score = einops.reduce(induction_stripe, \u001b[33m\"\u001b[39m\u001b[33mbatch head_index position -> head_index\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Store the result.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m induction_score_store[hook.layer(), :] = induction_score\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Klara\\anaconda3\\envs\\embed\\Lib\\site-packages\\torch\\_tensor.py:1227\u001b[39m, in \u001b[36mTensor.__array__\u001b[39m\u001b[34m(self, dtype)\u001b[39m\n\u001b[32m   1225\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.numpy()\n\u001b[32m   1226\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1227\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.numpy().astype(dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "induction = []\n",
    "dict_questions = {}\n",
    "for question, question_token in zip(questions, question_embeds):\n",
    "    length = len(question_token)\n",
    "    \n",
    "    induction_score_store = np.zeros((model.cfg.n_layers, model.cfg.n_heads))\n",
    "\n",
    "    # A function for the average induction score\n",
    "    def induction_score_hook(activation_pattern, hook):\n",
    "        \"\"\"\n",
    "        Computes the average induction score for a given activation pattern.\n",
    "        \n",
    "        Args:\n",
    "            activation_pattern (torch.Tensor): The activation pattern to compute the induction score for.\n",
    "            hook (HookPoint): The hook point that triggered this function.\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: The average induction score.\n",
    "        \"\"\"\n",
    "        # We take the diagonal of attention paid from each destination position to source positions seq_len-1 tokens back\n",
    "        # (This only has entries for tokens with index>=seq_len)\n",
    "        induction_stripe = activation_pattern.diagonal(dim1=-2, dim2=-1, offset=1-length//2)\n",
    "        # Get an average score per head\n",
    "        induction_score = einops.reduce(induction_stripe, \"batch head_index position -> head_index\", \"mean\")\n",
    "        # Store the result.\n",
    "        induction_score_store[hook.layer(), :] = induction_score\n",
    "\n",
    "    # We make a boolean filter on activation names, that's true only on attention pattern names.\n",
    "    pattern_hook_names_filter = lambda name: name.endswith(\"pattern\")\n",
    "    print(question)\n",
    "    # Run with hooks (this is where we write to the `induction_score_store` tensor`)\n",
    "    model.run_with_hooks(question_token, \n",
    "        return_type=None, # For efficiency, we don't need to calculate the logits\n",
    "        fwd_hooks=[(\n",
    "            pattern_hook_names_filter,\n",
    "            induction_score_hook\n",
    "        )]\n",
    "    )\n",
    "    #print(induction_score_store)\n",
    "    # Get the global max value and its flat index\n",
    "    max_value = np.max(induction_score_store)\n",
    "    max_index = np.argmax(induction_score_store)\n",
    "\n",
    "    # Convert flat index to (layer, head) coordinates\n",
    "    #max_index = np.unravel_index(max_index_flat.cpu().numpy(), induction_score_store.shape)\n",
    "    #print(\"Question:\", question)\n",
    "    #print(\"Max value:\", max_value.item())\n",
    "    #print(\"Max index (layer, head):\", max_index)\n",
    "    '''\n",
    "    if (max_index[0], max_index[1]) not in dict_questions:\n",
    "        dict_questions[(max_index[0], max_index[1])] = [question]\n",
    "    else:\n",
    "        dict_questions[(max_index[0], max_index[1])].append(question)\n",
    "    '''\n",
    "    print(max_index[0])\n",
    "    x.append(max_index[0])\n",
    "    y.append(max_index[1])\n",
    "    print(x)\n",
    "    induction.append(induction_score_store)\n",
    " \n",
    "print(x, y)\n",
    "df = pd.DataFrame({\n",
    "    \"Layer\": x,\n",
    "    \"Head\": y,\n",
    "    \"Question\": questions[:len(x)]\n",
    "})\n",
    "#print(dict_questions[(int(x[0]), int(y[0]))])\n",
    "px.scatter(\n",
    "    data_frame=df,\n",
    "    x=\"Layer\",\n",
    "    y=\"Head\",\n",
    "    hover_data=[\"Question\"],\n",
    "    title=\"Induction Scores for Questions\"\n",
    ").show()\n",
    "#px.scatter(x=np.array(x), y=np.array(y), labels={\"x\": \"Layer\", \"y\": \"Head\"},  title=\"Induction Scores for Questions\", hover_data=[\"question\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019595b5",
   "metadata": {},
   "source": [
    "The problem here is that many of the questions have the same max index. Therefore, it might not be the best method to visualize the inuction heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6197ac6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmanifold\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TSNE\n\u001b[32m      3\u001b[39m tsne = TSNE(n_components=\u001b[32m2\u001b[39m, perplexity=\u001b[32m30\u001b[39m, random_state=\u001b[32m42\u001b[39m, learning_rate=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m, early_exaggeration=\u001b[32m5.0\u001b[39m, n_iter=\u001b[32m5000\u001b[39m, init=\u001b[33m\"\u001b[39m\u001b[33mpca\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m induction_embeds = tsne.fit_transform(np.array(induction))\n",
      "\u001b[31mNameError\u001b[39m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42, learning_rate=\"auto\", early_exaggeration=5.0, n_iter=5000, init=\"pca\")\n",
    "induction_embeds = tsne.fit_transform(np.array(induction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e04b4380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50256]])\n"
     ]
    }
   ],
   "source": [
    "print(model.to_tokens(\"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
